\documentclass{article}[10pt]

\usepackage[cm]{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{morefloats}

\newtheorem{ax}{Axiom}[section]
\newtheorem{mydef}{Definition}[section]
\def\ci{\perp\!\!\!\perp}

\title{Exploratory Causal Analysis in Bivariate Time Series Data}
\author{James M.\ McCracken}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
Many scientific disciplines rely on observational data of systems for which it is difficult (or impossible) to implement controlled experiments. For example, there is no current technology that can control the interaction between the solar wind and the magnetic field measured at the surface of Earth, so space weather studies rely on data collected without performing controlled experiments.  Causal inference with data sets from such systems is difficult.   The need to identify potential causal relationships with time series data has lead to the development of several different time series causality tools, including transfer entropy, pairwise asymmetric inference, causal leaning, and Granger causality statistics.  This work introduces the concept of exploratory causal analysis, and explores the use of time series causality tools in performing this analysis.  Given a pair of time series, can any statements be made about one potentially driving the other (for some notion of ``driving'')? 
\end{abstract}
\tableofcontents

\section{Introduction} 
Data analysis is a fundamental part of physics.  The theory-experiment cycle common to most sciences \cite{Godfrey2009} invariably involves an analyst trying to draw conclusions from a collection of data points.  Van Belle outlines data analysis as four questions in what he calls the ``Four Questions Rule of Thumb'' \cite{Van2011} (distilled from Fisher \cite{Fisher1960}),  ``Any statistical treatment must address the following questions:
\begin{enumerate}
\item What is the question?
\item Can it be measured?
\item Where, when, and how will you get the data?
\item What do you think the data are telling you?''
\end{enumerate}
These items are each addressed by one of the three primary components of data analysis, the question (i.e., what is the purpose of the data analysis?; van Belle item \# 1), the data (i.e., what measurements are available to address the question?; van Belle items \# 2 and 3), and the tools (i.e., what methods, techniques, or approaches can be used on the data to address the question?; van Belle item \# 4).  This work focuses on the tools (the third component) given data in a specific form (the second component) and a distinct, limited question (the first component).  The concern of this work is data analysis to answer the question ``Does a given pair of time series data potentially contain some causal structure?''.  In physics, this question is common when an analyst has collected data over time (i.e., time series data) in an experiment that was not intentionally designed to verify some existing theory, e.g., recording daily precipitation and temperature at a specific location for many years.  The physicist's preliminary analysis of such data would be {\em exploratory} \cite{Tukey1977}, and a part of that exploratory analysis may involve investigations of potential causal structure.  The word ``potential'' is important to the analysis, as confirmation of any causal structure in the system would require further analysis, possibly including the collection of more data and/or the design on new experiments to collect new data.  Such analysis would be {\em confirmatory} and one of the main purposes of the exploratory analysis is to guide the confirmatory analysis \cite{Tukey1977}.

Causal inference as a part of data analysis (referred to in this work as {\em data causality}, See Section \ref{sec:studies}) is a topic of debate among many researchers and has been for many years (see \cite{Illari2014} for an introduction).  In 1980, Clive Granger stated ``Attitudes towards causality differ widely, from the defeatist one that it is impossible to define causality, let alone test for it, to the populist viewpoint that everyone has their own personal definition and so it is unlikely that a generally acceptable definition exists. It is clearly a topic in which individual tastes predominate, and it would be improper to try to force research workers to accept a definition with which they feel uneasy. My own experience is that, unlike art, causality is a concept whose definition people know what they do not like but few know what they do like.'' \cite{Granger1980}  Granger was referring to the attitudes of statisticians, economists, and philosophers of the time who often repeated the platitude ``correlation is not causation'' \cite{Granger2003} and declared statements of causality were only possible in experiments with randomized trials, as described by Fisher \cite{Fisher1934,Fisher1960}.  General statements of causality in modern social science data analysis often still require Fisher randomization in the experimental design \cite{Imbens2015,Morgan2014}.  It has come to be recognized, however, that randomized trails can be prohibitively difficult (e.g., too expensive) or impossible to conduct in practice (e.g., subjecting one subject to multiple treatments simultaneously) \cite{Morgan2014,Imbens2015}.  Techniques have been developed for causal inference when Fisher randomization is unavailable.  It has been argued that, in principle, Fisher randomization is not possible in any social science\footnote{``Social science'' is used here to mean any field of study with subjects that are sufficiently complex, including sociology, psychology, economics, and the medical sciences.} experiment and thus modern data causality techniques are required for rigorous causal inference of such data sets \cite{Illari2011b}.

Physics has a long history of studying causality, often more closely related to philosophical considerations rather than specific data sets of physical systems (see, e.g., \cite{Bohm1971}).  Physics applies the scientific tradition of a prediction-experiment-repeat cycle \cite{Godfrey2009} to fundamental systems, such as billiard balls and particle interactions, where randomization of hidden variables is usually not much of a concern.  Some physicists consider statements of causality to be impossible without direct intervention into the system dynamics \cite{Bunge1979}.  Modern data collection techniques, however, include measurements of system dynamics for which interventions are not technologically feasible.  One such data set discussed in this work in is NASA/GSFC's Space Physics Data Facility's OMNIWeb (or CDAWeb or ftp) service, and OMNI data \cite{King2005}.  Causality studies of such systems require data causality tools rather than traditional experiments (i.e., interventions into the system dynamics).  

\subsection{Notation and Language}
Notation and language in causality studies can be contentious (see, e.g., \cite{Illari2014,Pearl2000,Holland1986}).  This work tries to be specific and direct with causal language.  This issue is discussed in detail in Sections \ref{sec:whatis} and \ref{sec:whatisECA}.  The notational shorthand ``$\rightarrow$'' and ``$\leftarrow$'' are used to replace causal verbs such ``cause'' or ``drive'', e.g, $A\leftarrow B$ means $B$ drives $A$.  This shorthand is convenient but should not be conflated with causal language outside the scope of such language used in this work, i.e., $A\rightarrow B$ means $A$ causes $B$ using the definition of ``cause'' outlined in Sections \ref{sec:whatis} and \ref{sec:whatisECA}.  The word ``tool'' is also used extensively throughout this work to mean a technique, method, approach, or specific mathematical calculation (or any collection of such things) used as part of a data analysis.  This language is, again, used for convenience.  Causality studies has an extensive history and is broadly interdisciplinary.  The use of nondescript, overarching terms like ``tool'' and notations such as ``$\rightarrow$'' help to prevent the discussion from getting lost in the details of nomenclature.  The hope is that the notation and language used in this work does not cloud any underlying concepts or ideas.  Such issues will be discussed whenever there may be confusion.

\subsection{What is ``time series causality''?}
\label{sec:whatis}
Time series causality is causal inference made using only time series data.  It is a term that may be applied to a wide array of different methods and techniques, as discussed in Section \ref{sec:tools}.  It may be considered a subset of data causality, which is causal inference based on data of some kind.  The specific type of data used in time series causality, i.e., time series, is the defining feature.  A rough taxonomy of causality studies is presented in Section \ref{sec:studies}.

There is some debate in the literature about whether or not time series causality techniques should be considered {\em causal} rather than simply {\em statistical} \cite{Chen2013,Pearl2000,Bollen2013}.  Most of the arguments against identifying such tools as causal are equivalent to one of the three following truisms (or platitudes, depending on the author's point of view), 
\begin{enumerate}
\item Correlation is not causation
\item Confounding needs to be addressed
\item {\em Proving} causation requires intervention into the system dynamics (i.e., experiments or ``manipulation'' \cite{Holland1986}).
\end{enumerate}
The first point may be argued as the motivation for some time series causality tools (see, e.g., \cite{Granger2003}) but is often pointed out as a limitation of others (see, e.g, \cite{Rogosa1980}).  Points 2 and 3, however, have been argued as the primary reason times series causality tools should not be considered causal at all.  

For example, Pearl \cite{Pearl2000} defines a {\em statistical parameter} as ``any quantity that is defined in terms of a joint probability distribution of observed variables, making no assumption whatsoever regarding the existence or nonexistence of unobserved variables'' and a {\em causal parameter} as ``any quantity that is defined in terms of a causal model$\ldots$and is not a statistical parameter''.  He goes on to say ``Temporal precedence among variables may furnish some information about$\ldots$ causal relationships$\ldots$[and] may therefore be regarded as borderline cases between statistical and causal models.  We shall nevertheless classify those models as statistical because the great majority of policy-related questions {\em cannot} be discerned from such distributions, given our commitment to making no assumption regarding the presence or absence of unmeasured variables.  Consequently,$\ldots$`Granger causality' and `strong exogeneity' will be classified as statistical rather than causal.'' (emphasis in original).  Most times series causality tools rely on the temporal structure of the data sets for causal inference, and most draw conclusions only from the available data. Thus, following Pearl's definitions, most times series causality tools are statistical tools, not causal tools.

Holland \cite{Holland1986} argues that any method or technique that does not involve intervention into the system dynamics may only be considered associational, not causal.  Holland does not restrict the concept of interventions to experimenters conducting carefully designed experiments; he considers, e.g., the possibility of drawing causal inferences from observational data.  He does, however, restrict the notion of an intervention by restricting the notion of a cause, which may not be an attribute of system (e.g., race or gender in social studies) and must be applicable equally to all units within the system.  See \cite{Holland1986} for a full discussion of these ideas.  Most time series causality tools, as mentioned previously, draw causal inference from the data alone.  There is usually no effort made to determine if one time series fits any specific definition of ``cause'' with respect to the other time series being analyzed.  Thus, following Holland's arguments, such tools are associational tools, not causal.

Time series causality tools are used in this work for {\em exploratory causal analysis}, which is explained in more detail in Section \ref{sec:whatisECA}.  Labeling the causal inference as ``exploratory'' may, cynically, be seen as escamotage meant to avoid issues such as those raised by Pearl and Holland.  It may be argued, however, that the three points listed above, along with issues of labeling and taxonomy, are of little importance to the task at hand.  There are situations in which an analyst will have nothing but a set of times series.  Should the analyst refuse to make any causal inference at all?  Doing so would ignore previous scenarios in which analysts have successfully applied techniques, such as times series causality tools, to draw causal inferences that were later confirmed either by collecting more data and applying other data causality tools (such as those advocated by Pearl \cite{Pearl2000}) or by conducting experiments.  The modifier {\em exploratory} applied to these causal inferences implies the need for further investigation and/or theory to fully understand the causal structure of the system.  An analyst need not limit their data analysis toolbox by ignoring time series causality tools simply because such tools may only be ``associational'' or ``statistical''.  Indeed, the inferences drawn with such tools may not be causal, but they could be, so they should not be ignored during a search for causal inference.    

\subsection{What is ``exploratory causal analysis''?}
\label{sec:whatisECA}
Exploratory causal analysis uses the term {\em exploratory} similar to the way it is used by Tukey in his approach to exploratory data analysis \cite{Tukey1977}.  The preface of Tukey's original work provides general themes to both the exploratory data analysis he was advocating and exploratory causal analysis, including emphasis that the main idea is ``$\ldots$about looking at the data to see what it seems to say.'' and the primary concern is ``$\ldots$with appearance, not with confirmation.'' \cite{Tukey1977}.  Exploratory analysis is not confirmatory analysis, and this point must be especially clear to a causal inference analyst.  Tukey makes this idea clear with a bullet point in the Preface, ``leave most interpretations of results to those who are experts in the subject-matter field involved.'' \cite{Tukey1977}.  Times series causality tools are statistical tools, and statistical tools are necessarily only associational \cite{Illari2014}.  The relationships found with such tools can only be deemed ``causal'' with the application of outside theories or assumptions \cite{Illari2014}, which requires an analyst seeking to make such general causal statements to be well-versed in any such theories involving the analyzed data.  Often the analyst is seeking to {\em confirm} a given causal theory.  Statistical tools, such as time series causality tools, can certainly be used for such a task but not in the manner they are applied in this work.  Such analysis would be {\em confirmatory causal analysis}, and this work is about {\em exploratory causal analysis}.  

The distinction between exploration and confirmation in causal analysis is important because the analysis can (and should) be approached differently.  Analysis meant to confirm some existing causal theory will be attempting to find specific patterns within the data.  Presumably, there will be known (or assumed) models (or sets of models) to which the data will be fit.  In such analysis, a primary goal might be understanding the residuals from the fits and special attention may be given to the sampling procedure to ensure the causal inferences are applicable to the desired populations.  Exploratory causal analysis is not concerned with specific models\footnote{This is not meant to imply that exploratory causal analysis does not use models, only that such models are not assumed to reveal any underlying truths about the system dynamics or populations from which the data has been sampled.  See Section \ref{sec:GC} for a discussion of data models in exploratory causal inference.} or the applicability of causal inferences beyond the data being analyzed.  Exploratory causal analysis is characterized by a myopic goal to determine which data series from a given set of series might be seen as the primary driver.  The exploratory causal inference is never assumed to apply to any data other than that being analyzed and is meant to guide the confirmatory causal analysis, especially in situations where existing outside theories or assumptions about the data are incomplete.  The results of exploratory causal analysis may guide the design of new experiments, i.e., the collection of new data sets, from which new exploratory causal inferences may be drawn.  The results may also guide the creation of new theoretical models or the development of new assumptions, which would become part of the confirmatory causal analysis.  In short, exploratory causal analysis is meant to be the first step of causal inference.  It is meant to draw as much potentially causal information as possible from the given data.

Another important reason for the distinction between exploration and confirmation in causal analysis is philosophical.  Exploratory causal inference is intended to determine if (and what) causal structure may be present in a time series pair but is not intended to {\em prove} such structure.  There are scenarios in which any time series causality tool may incorrectly assign causal structure or may incorrectly not assign causal structure \cite{Illari2014}.  Furthermore, proof of causal relationships is often considered impossible with data alone \cite{Pearl2000,Illari2014,Imbens2015}.  Care must be taken to ensure that causal language used during exploratory causal analysis such as ``driving'', ``cause'', ``effect'' and even ``causality'' is not conflated with other definitions of those terms.  If, in an exploratory causal analysis of a given set of data series, one is identified as the ``cause'' of another, then this identification should not be construed as a statement that the former is a {\em true} cause of the latter, in any (empirical, physical, metaphysical, philosophical, etc.) sense of the word ``true''.  The identification of a ``cause'' among a given set of data series during exploratory data analysis is a statement that, assuming one of the data series may be interpreted as driving the others, the ``cause'' series is driving the ``effect'' series, where the technical meaning of ``driving'' depends on the specific causal inference tools being used but, in general, implies some data or data structure (i.e., the ``cause'') in the past of one series predicts, or raises the probability of, some data or data structure (i.e., the ``effect'') in the present or future of another series.  For example, if a cause is identified as $\mathbf{A}$ in a pair of series $(\mathbf{A},\mathbf{B})$ using transfer entropy\footnote{See Section \ref{sec:TE}.}, then the exploratory causal statement $\mathbf{A}$ causes (or drives) $\mathbf{B}$ (written as $\mathbf{A}\rightarrow\mathbf{B}$) is the statement that the information flow\footnote{``Information flow'' is defined in Section \ref{sec:TE}.} from $\mathbf{A}$ to $\mathbf{B}$ is greater than the information flow from $\mathbf{B}$ to $\mathbf{A}$.  It is a statement about a comparison of magnitudes of specific calculations conducted on the data series.  The only causal interpretation given to the statement is that which the tool itself possesses (which, in this case, is one of ``information flow'' being indicative of causal relationships).  No attempts are made to relate the causal interpretations of the tools used during exploratory causal analysis to more general notions of causality, e.g., in physics and philosophy.  Such tasks would be part of any confirmatory causal inferences made with these tools.

Exploratory causal analysis is defined more by an approach to the analysis than the use of any specific set of tools or assumptions.  As Tukey notes, exploratory analysis is ``detective in character''\footnote{``Confirmatory data analysis is judicial or quasi-judicial in character.'' \cite{Tukey1977}} \cite{Tukey1977}.  However, the specific exploratory causal analysis techniques used in this work rely on time series causality tools, which, in turn, rely on two important assumptions.  The first is that the cause must precede the effect.  This assumption has been argued among philosophers for a long time (see, e.g., \cite{Russell1912,Russell1948,Salmon1984,Reichenbach2001,Illari2014,Pearl2000}) and has also been questioned among physicists \cite{Bohm1971,Bunge1979}.  The second assumption is that a driver may be present in the set of data series being analyzed.  This assumption makes the exploratory causal inference susceptible to confounding \cite{Illari2014,Pearl2000}; i.e., exploratory causal analysis is not intended to detect potential driving from sources outside of the data series set being analyzed.  For example, the exploratory causal inference may be $\mathbf{A}\rightarrow\mathbf{B}$ when, in fact, there is some unknown data series $\mathbf{C}$ which may be more appropriately labeled the driver of both, i.e., $\mathbf{C}\rightarrow\mathbf{A}$ and $\mathbf{C}\rightarrow\mathbf{B}$.  Any data-driven causal inferences are susceptible to confounding \cite{Illari2014}.  However, exploratory causal analysis, as it is done in this work, may be seen as particularly vulnerable given the desire to draw conclusions from only the time series data under consideration.  Neither of these assumptions will be defended beyond noting that the agreements between intuitive causal ``truths'' and exploratory causal inferences shown in Section \ref{sec:ECA} imply these assumptions are valid in at least some circumstances.

Another topic that must be considered carefully during exploratory causal analysis is hypothesis testing.  Hypothesis (also called statistical or significance) testing is a standard part of modern Granger causality studies\footnote{See Section \ref{sec:GC}.}.  The early work of Granger was concerned with developing a ``testable'' definition of causality (see, e.g., \cite{Granger1963,Granger1969}), and by the late 1970s, hypothesis testing was a standard part of Granger causality studies (see, e.g., \cite{Pierce1977}).  The same time period also saw many authors argue against the use of such testing in causality studies (see, e.g., \cite{Schwert1979,Jacobs1979}).  Statistical tests may or may not be useful for causal inference with time series causality tools, but the results of such tests should be not be interpreted beyond {\em exploratory} causal inference; i.e., the use of a hypothesis test does not imply a given causal inference is confirmatory rather than exploratory.  For example, suppose a set of leanings\footnote{See Section \ref{sec:lean}.} is created as part of the exploratory causal analysis.  This set must be distilled somehow into a single causal inference.  Suppose a null hypothesis $N_0$ is defined as ``the mean of this set of leanings is negative'' or $\langle \lambda_m \rangle < 0$.  Let $N_0$ represent the causal inference $\mathbf{B}\rightarrow\mathbf{A}$ in a time series pair $(\mathbf{A},\mathbf{B})$.  If $N_0$ is rejected at significance level $\alpha$, then the interpretation is that the causal inference $\mathbf{B}\rightarrow\mathbf{A}$ is rejected at significance level $\alpha$, not that the causal inference $\mathbf{A}\rightarrow\mathbf{B}$ is ``accepted'' with confidence $1-\alpha$.  Furthermore, the test focuses on the rejection of a specific null hypothesis, and that null hypothesis is a statement about a specific calculation.  The rejection of a given causal inference comes only from the causal interpretation of the calculation around which the null hypothesis was constructed.  These points may seem pedantic but significance testing has led to confusion in the literature whereby the rejection of a given null hypothesis at a very low significance level is conflated with a high ``confidence'' in some causal interpretation \cite{Schwert1979,Jacobs1979}.  The statistical test is about a specific calculation on the data sets, and the analyst's confidence in a causal inference depends on concerns that usually are not addressed by such tests, including the assumptions used when performing the calculation (e.g., linear forecast models in a Granger causality calculation) and the validity and/or applicability of a given causal interpretation of that calculation. 

\section{Causality studies} 
\label{sec:studies}
Studies of causality are as old as science itself\footnote{Aristotle is often credited with both the first theory of causality \cite{Falcon2008,Evans1959} and an early version of the scientific method \cite{Bolduan1945} (along with other ancient Greek philosophers \cite{Popper1998}).  Aristotle's death was in 322 BCE \cite{During1957}.}.  An overview of such studies is far beyond the scope of this work and would probably fill several volumes.  As Holland says ``So much has been written about causality by philosophers that it is impossible to give an adequate coverage of the ideas that they have expressed in a short article.'' \cite{Holland1986}.  Physicists, economists (and econometricians), mathematicians, statisticians, computer scientists, and scientists from a wide array of other fields (including medicine, psychology, and sociology) have also contributed greatly to the vast body of literature on causality.  

This section is not meant to provide an overview of these studies.  Rather, this section is meant to provide a loose taxonomy of these studies.  Authors often discuss causality with little attention given to the specific definitions of their causal language or the specific goals they are hoping to achieve with their work (see, e.g., \cite{Holland1986,Granger1980} for a discussion of such issues).  This taxonomy is meant to explain where exploratory causal analysis, as it is explained in Section \ref{sec:whatisECA}, relates to other causality studies.  This taxonomy will not be complete, nor will the boundaries be clean.  Several authors, particularly in theoretical physics, blur boundaries, e.g., between data studies and philosophy (see, e.g., \cite{Bunge1979}).

Holland outlines four primary focuses for authors studying causality, the ultimate meaningfulness of the notion of causality, the details of causal mechanisms, the causes of a given effect, and the effects of a given cause \cite{Holland1986}.  The first two goals in this list will fall into a category called {\em foundational causality}, and the last two will fall into a category called {\em data causality}.  It is assumed that all causality studies can be placed into one of these two categories, but the categories are not considered disjoint.  Data causality studies are characterized by the use of data (empirical or synthetic) in discussion of causality, and foundational causality studies are characterized as not being data causality studies\footnote{These two notions may seem at odds.  If $s$ is a causality study, then, given the description, it may belong to either the set of foundational studies, $\mathbb{F}$, or the set of data studies, $\mathbb{D}$; i.e., $s\in\mathbb{F}$ or $s\in\mathbb{D}$.  If $\mathbb{F}\cap\mathbb{D}\neq\emptyset$, then $\exists s$ such that $s\in\mathbb{F}$ and $s\in\mathbb{D}$.  If $\mathbb{F}=\mathbb{D}^c$, where $\mathbb{D}^c$ is the complement of $\mathbb{D}$, i.e., foundational studies are those studies that are not data studies, then $\exists s$ such that $s\in\mathbb{D}^c$ and $s\in\mathbb{D}$.  This notion may seem nonsensical when presented in this set notation, but is common in practice due to the large variety of things that may be described as $s$.  For example, a single study $s$ may include the introduction a completely new definition of ``causality'' and present several examples using empirical data to motivate the veracity of the definition.  See the work of Illari et al.\ for an exploration of these ideas \cite{Illari2014,Illari2011b}.}.  Many authors have argued that foundational causality should not be studied independently of data causality (see, e.g., \cite{Holland1986,Granger2003,Plotnitsky2011,Zellner2007,Zellner1979,Zellner1988,Bohm1971}).  Data causality studies often bemoan the lack of academic consensus among foundational studies while recognizing the need for operational notions of causality in data analysis (see, e.g., \cite{Shugan2007,Granger1980,Zheng2010,Pearl2000,Druzdzel1993}).  Time series causality is considered a subset of data causality, and, therefore, data causality will be explored in more detail than foundational causality.  Interesting introductions and discussions of foundational causality studies can be found in \cite{Pearl2000,Illari2014,Kleinberg2012,Bunge1979,Bohm1971,Imbens2015}.  

\subsection{Foundational causality}
Do causes always precede effects?  Is a cause required to precede an effect?  How are causes and effects related in space-time?  Is relativistic causality different from quantum causality and classical causality?  What is quantum causality?  Is causality a law of Nature?  Is causality a principle used by practicing scientists?  How are cause and effect perceived?  Can there be differences in such perceptions without changing the underlying notion of causality?  These questions are examples of foundational causality studies.  Foundational causality, like all causality studies, is broadly inter-disciplinary.  Three of the most prominent subfields are philosophical studies, natural science studies, and psychological studies.  Legal causality (i.e., who is legally responsible for a given event) is often considered a part of the philosophical study of causality, albeit with a more practical, goal-oriented outlook (see, e.g., \cite{Honore2010,Young2007}).  A detailed introduction to legal causality can be found in \cite{Illari2014}.

\subsubsection{Philosophical studies} 
Aristotle developed a theory of causality that involved four types of causes, the material cause, the formal cause, the efficient cause, and the final cause \cite{Falcon2008,Evans1959,Holland1986,Zheng2010}.  These ideas were refined by many philosophers, including Locke \cite{Locke1700} and Decartes \cite{Descartes1830} in the 17$^{th}$ century and Kant \cite{Kant1855} and Hume \cite{Hume1888} in the 18$^{th}$ century.  Hume's contribution to the philosophical discussion of causality is often considered among the greatest \cite{Holland1986,Zheng2010,Pearl2000,Illari2014}, although disagreements with many of the fundamental postulates of Hume led to the relatively recent development of probabilistic causality by authors such as Suppes \cite{Suppes1970} and Good \cite{Good1984}.  The basic notions of probabilistic causality have found favor among many data causality authors (see, e.g., \cite{Zheng2010,Illari2014,Kleinberg2012}).  Mill is often credited with developing the philosophical groundwork for drawing causal inferences from experiments \cite{Mill1858} in the 19$^{th}$ century.  

A reoccurring theme in philosophical studies of causality is the question of whether or not causality is (or should be) a part of reality \cite{Zheng2010,Illari2014}.  Many philosophers argue against causality as something that can be comprehended by human minds, including Plato in approximately 360 BCE \cite{Plato2010}, Spinoza in the 17$^{th}$ century \cite{Spinoza1955}, and Pearson in the 19$^{th}$ century \cite{Pearson1903}.  Some philosophers have questioned the wisdom of making causality a requirement of reality, including Russel in the 20$^{th}$ century \cite{Russell1912,Russell1948}.  The wide variety of different philosophical thoughts on causality has led some authors to question whether such questions can have answers at all (see, e.g., \cite{Shugan2007,Illari2011b,Salmon1998}).

\subsubsection{Natural science studies} 
Causality, defined as cause must precede effect, is often considered a fundamental part of physics and other natural sciences \cite{Bohm1971,Bunge1979}.  Many studies of causality in physics seek answers to questions regarding this so-called law of causality, including can the law be violated?, can the law be derived from more fundamental notions of, e.g., information?, is the law universally applicable?, etc.  These ideas are often framed in discussions of specific concepts and theories, including quantum interpretations (see, e.g., \cite{Bohr1963,Bohr1937,Riggs2009}), quantum irreversibility (see, e.g., \cite{Bohm2013}), quantum information (see, e.g, \cite{Pawlowski2009,Kuzmich2001}), astrophysics (see, e.g., \cite{Smolin2006,Gibbons1999}), and relativity (see, e.g., \cite{Zeeman1964,Tipler1977,Liberati2002}).  Physicists in particular often study the relationship between causality and time (see, e.g., \cite{Ellis2005,Barbour1999,Schulman1997,Penrose1999}).

Foundational causality studies are an active part of modern physics.  Causal set theory, which relies on causality as a fundamental principle, has been proposed as a potentially fruitful approach to quantum gravity studies (see, e.g., \cite{Dowker2006,Bombelli1987}).  Closed timelike curves \cite{Thorne1993} have been used to make advances in quantum computational complexity \cite{Aaronson2009} and may potentially limit the applicability of causality as a law of Nature (see, e.g., \cite{Lobo2003,Korotaev2015}).  There are even proposed quantum experiments to test ``retrocausal'' signaling \cite{Cramer2014}.  However, some prominent physicists have argued, similar to Pearson's argument in statistics \cite{Pearson1903}, that causal notions should not be a part of physics nor a concern of physicists \cite{Mach1986}.

\subsubsection{Psychological (and other social science) studies} 
In an overview of causality in psychological studies, White states ``psychology is concerned with how people understand and perceive causation, make causal inferences and attributions, and so forth.'' \cite{White1990}.  Psychologists are often concerned with how humans\footnote{Causal reasoning has also been studied in other species (see, e.g., \cite{Sawa2009,Taylor2012})} reason causally (see, e.g., \cite{White1988,White1989,Shultz1982}).  Psychologists have developed theories, e.g., power PC theory, ``a causal power theory of the probabilistic contrast model'' \cite{Cheng1997}, to explain how a reasoner may become convinced that something causes something else\footnote{{\em Probabilistic contrast} (or {\em probability contrast}) is related to the causal penchant.  See Section \ref{sec:lean}.}.  Developmental psychology has sought to determine the minimum age at which a human may perceive causal relationships (see, e.g., \cite{Leslie1987,Oakes1990,Michotte1964}), and others have tried to determine if certain physiological illnesses, e.g., depression, may be linked to causal perceptions (see, e.g., \cite{Golin1981}).  There has also been work to determine if perceptions of causality are related to cultural backgrounds (see, e.g., \cite{Yan1994,Nguyen2004}).  A review of modern psychology studies of causal inference may be found in \cite{Sloman2015}.

\subsection{Data causality}
Data causality focuses on determining the effects of given causes, or the causes of given effects, using data that represents measurements (of some kind) on a given system of interest.  It is a fundamental part of science \cite{Godfrey2009}.  Rubin et al.\ have pointed out that most applications of statistics are concerned with questions of causality \cite{Imbens2015}, and Winship et al.\ have argued that causality concerns are the motivation of much of the research that is conducted in the social sciences \cite{Morgan2014}.  Data is primarily collected from one of two types of studies, experimental or observational \cite{Morgan2014}.  Experimental studies are those studies in which the researcher directly intervenes into the system dynamics to change some aspect of the system, and observational studies are those studies in which such direct intervention by the researcher is not possible \cite{Morgan2014,Imbens2015,Pearl2000}.  Many authors consider experimental studies to be the only way to truly determine causality in a system (see, e.g., \cite{Holland1986,Fisher1960}).  A researcher, however, may not be able to perform experiments on a given system for some reason, including ethical concerns (e.g., in medical studies) or technology limitations (e.g., in astrophysical studies).  Thus, many data causality techniques were motivated by the researcher's potential restriction to only observational data \cite{Pearl2000,Morgan2014,Imbens2015}.

Data causality tools encompass many different tools and techniques, including both experimental design (i.e., prior to data collection) and data analysis (i.e., post data collection).  There is no clean taxonomy of these tools, so the following three categories are characterized primarily by the type of data being collected and/or analyzed.  The first category, {\em statistical causality}, includes the most commonly used data causality methods, such as randomized trials.  The second category, {\em computational causality}, includes computational approaches to large, usually observational, data sets.  And, the third category, {\em time series causality}, includes techniques that rely on not only the collected data but also the timestamps of those data.  Times series causality is, as mentioned in Section \ref{sec:whatis}, the focus of this work.

Physics includes both experimental and observational data collection but is often more associated with foundational causality studies rather than data causality studies \cite{Bunge1979,Bohm1971,Penrose1999}.  Data causality is, however, a large part of physics.  Many of the time series causality tools discussed in this work were developed by physicists seeking solutions to questions of physical causality, including information-theoretic causality (see Section \ref{sec:TE}) and state space reconstruction causality (see Section \ref{sec:SSRC}).  Physics is mentioned here to illustrate that despite the seemingly field-specific language used by many authors (e.g., ``treatment'' and ``control''), data causality is a concern for many different scientific disciplines.  

\subsubsection{Statistical causality} 
Fisher outlined his views on what he called ``the arts of experimental design'' and ``the valid interpretation of experimental results'' in his influential book {\em The Design of Experiments} \cite{Fisher1960}.  He introduced the notions of a null hypothesis, significance testing, and randomized trials.  On the latter, he concludes ``It is apparent, therefore, that the random choice of the objects to be treated in different ways would be a complete guarantee of the validity of the test of significance, if these treatment were the last in time of the stages in the physical history of the objects which might affect their experimental reaction.'' \cite{Fisher1960}.  Fisher's ``randomized trials'' design of an experiment is considered by many to be the only way to accurately draw causal inferences from experimental data \cite{Imbens2015,Morgan2014}, although some authors disagree \cite{Pearl2000}.  Fisher recognized that randomized trials would not always be possible in practice \cite{Fisher1960}, and work was done by other authors to determine when (and how) causal inferences could be drawn from non-randomized trials.  A detailed review of this work is in \cite{Morgan2014}.

One of the most commonly used data causality approaches is the {\em counterfactual} or {\em potential outcome} approach.  The label {\em counterfactual} has origins in philosophical studies of causality and is used to refer to outcomes of a cause that may presumably have occurred but did not \cite{Illari2014,Imbens2015}.  All such outcomes (both those that did and those that did not occur) are called potential outcomes, and unobserved potential outcomes are called counterfactual \cite{Morgan2014}.  In the potential outcome framework, each unit $u$ in the system may be exposed to one of two potential causes, the ``treatment'' $t$ or the ``control'' $c$.  The effect of that cause is given by some response variable $Y$ acting on a given unit, i.e., $Y_t(u)$ is the effect of the treatment and $Y_c(u)$ is the effect of the control \cite{Holland1986,Morgan2014,Imbens2015}.  The ``causal effect of $t$ (relative to $c$) on $u$ (as measured by $Y$)'' \cite{Holland1986} is
\begin{equation}
\label{eqn:iCE}
Y_t(u)-Y_c(u)\;\;.
\end{equation}
The issue facing an analyst, however, is that Eqn.\ \ref{eqn:iCE} can never be measured for some systems.  Holland refers to this as the {\em Fundamental Problem of Causal Inference}, i.e.,
\begin{mydef}
{\em Fundamental Problem of Causal Inference} It is impossible to {\em observe} the value of $Y_t(u)$ and $Y_c(u)$ on the same unit and, therefore, it is impossible to {\em observe} the effect of $t$ on $u$. \cite{Holland1986} (emphasis in original)
\end{mydef}

Holland posits two possible solutions to the fundamental problem of causal inference, the scientific solution and the statistical solution \cite{Holland1986}.  The scientific solution is the approach used in most experimental physics studies, i.e., if $Y_{(t,c)}(u_i,\tau_m)$ is the response variable $Y$ (treatment or control) measured on unit $u_i$ at time $\tau_m$, then assume $Y_{(t,c)}(u_i,\tau_m)=Y_{(t,c)}(u_i,\tau_n)\;\forall\tau_m,\tau_n$ and/or assume $Y_{(t,c)}(u_i,\tau_m)=Y_{(t,c)}(u_j,\tau_m)\;\forall u_i,u_j$.  Holland refers to the former as a temporal stability assumption (along with a ``causal transience'' assumption whereby it is assumed that the measurement at time $\tau_n$ does not affect measurements made at some time $\tau_m>\tau_n$) and the latter as a homogeneity assumption, but he points out that, in principle, neither assumption can be verified\footnote{``By careful work he may convince himself and others that this assumption is right, but he can never be absolutely certain.'' \cite{Holland1986}} \cite{Holland1986}.  The statistical solution is to define an {\em average causal effect}, $T$, as
\begin{equation}
\label{eqn:aCE}
T = E\left(Y_t-Y_c\right) = E\left(Y_t\right)-E\left(Y_c\right)\;\;,
\end{equation}
where $E(\cdot)$ is the expectation value \cite{Holland1986,Morgan2014,Imbens2015}.  Eqn.\ \ref{eqn:aCE} is often considered the great success of the potential outcome approach to data causality because, as Holland states, Eqn.\ \ref{eqn:aCE} ``reveals that information on {\em different} units that {\em can be observed} can be used to gain knowledge about $T$'' \cite{Holland1986} (emphasis in original); i.e., causal inferences may be drawn from data despite the fundamental problem of causal inference.

Rubin is often credited with originally developing the potential outcome approach to data causality in \cite{Rubin1974} (see, e.g., \cite{Holland1986,Morgan2014}), although Rubin himself, in \cite{Rubin1986}, has claimed that the potential outcome framework was implicit in the early work of Fisher \cite{Fisher1960} and Neyman \cite{Neyman1935}.  Many authors have contributed to the field since the work of Rubin; detailed overviews of the potential outcome model as an approach to data causality can be found in \cite{Morgan2014,Imbens2015}, and an introduction to the philosophical framework of the approach can be found in \cite{Illari2014}.

The potential outcome approach, as outlined by Rubin and Holland \cite{Rubin1974,Holland1986}, has been criticized as a tool for causal inference, despite its apparently successful application to many problems in the social sciences \cite{Morgan2014,Imbens2015}.  Dawid, in particular, has criticized the model as unnecessarily metaphysical, stating ``$\ldots$the counterfactual approach to causal inference is essentially metaphysical, and full of temptations to make `inferences' that cannot be justified on the basis of empirical data and are thus unscientific.'' \cite{Dawid2000}.  Dawid states directly  ``There are many problems where workers who have grown familiar and comfortable with counterfactual modeling and analysis evidently consider that it forms the only satisfactory basis for {\em causal inference}. However, I have not as yet encountered any use of counterfactual models for inference about the effects of causes that is not either (a) a goat, delivering misleading inferences of no empirical content, or (b) interpretable, or readily reinterpretable, in noncounterfactual terms.'' \cite{Dawid2000} (emphasis in original)\footnote{Pearl, a proponent of the counterfactual approach, responds ``Dawid is correct in noting that many problems about the effects of causes can be reinterpreted and solved in noncounterfactual terms. Analogously, some of my colleagues can derive De-Moivre's theorem, $\cos ne = \mathrm{Re}[(\cos e +i \sin e)^n]$, without the use of those mistrustful imaginary numbers. So, should we strike complex analysis from our math books?'' \cite{Pearl2000c}}.  Granger has also criticized the potential outcome approach for relying on an identification of ``treatment'' and ``control'' responses, which is often not possible in practice, and has labeled the approach as ``cross-sectional causation'' that cannot be applied to many important causal questions (particularly those regarding time series data) \cite{Granger1986}.

Dawid has introduced a decision-theoretic approach to data causality in contrast to the counterfactual approach \cite{Dawid2002,Dawid2000}.  The decision-theoretic approach has been introduced using a similar framework, i.e., influence diagrams, to the directed acyclic graph (DAG) approach (which is discussed in the {\em computational causality} subsection) \cite{Dawid2002}, but Dawid maintains that the decision-theoretic approach is distinct (and superior) to both the DAG and potential outcome (or counterfactual) approaches \cite{Dawid2007,Dawid2010}.  Dawid extends the potential outcome approach by introducing marginal distributions $P_t$ and $P_c$ to represent the uncertainty in the response $Y$ (conditional on $t$ or $c$) and a loss function $L(\cdot)$ to represent the consequence (or cost) of the decision to either apply the treatment $t$ or the cost $c$ to a unit $u$ \cite{Dawid2000,Illari2011Dawid}.

Marked point processes have also been introduced as a method for drawing causal inferences from longitudinal studies \cite{Arjas1993,Arjas2004}.  A set of causal events $C_r$ with $r=1,2,\ldots,k$ is described by a pair of random variables $(T_n,X_n)$ where $T_n$ are the ordered time variables obeying $0\le T_1\le T_2 \le\ldots$ and $X_n$ are the ``marks'' that ``describe'' the causal events occurring at $T_n$ \cite{Eerola2012}.  The set of pairs $\{(T_n,X_n)\;|\;n\ge 1\}$ is known as a {\em marked point process } \cite{Eerola2012}.  The marked points prior to some time $t$ define a {\em history process } $H_t = \{(T_n,X_n)\;|\;T_n\le t\}$, which may be used to define a {\em prediction process} to draw inferences regarding causal relationships within data sets.  A concise introduction to causality studies using marked point processes can be found in \cite{Eerola2012}.

\subsubsection{Computational causality}
Illari et al.\ remark in \cite{Illari2011b} that the 1980s saw a ``revolution'' in causality studies ``stemming from interest amongst computer scientists and statisticians in probabilistic and graphical methods for reasoning with causal relationships.''  In 1997, identifying causal structure in data networks was identified as a major goal of machine learning \cite{Ditterrich1997}.  Causal inference has, for some authors, become a computational data analysis problem (see, e.g., \cite{Pearl2000}).  The research effort has become so popular in recent years that in 2011 a ``virtual lab'' was built for the express purpose of testing causal discovery algorithms \cite{Guyon2011}.

Causal inference with structural equation modeling (SEM) relies on potential causal models fit to data and given causal interpretations \cite{Anderson1988,Pearl2012,Bollen2013,Bollen2014}.  The method is similar to causal interpretation of regressions, which has been criticized by proponents of the potential outcome approach (see, e.g., \cite{Holland1986}).  Proponents of SEM, however, argue the methods are distinct from older regression techniques (see, e.g., \cite{Bollen2013}).  Consider two data sets $\mathbf{M}=\{ m_i \}$ and $\mathbf{N} = \{ n_i \}$ where $i$ is some general discrete index.  An SEM of this system might be
\begin{equation}
m_i = \alpha + \beta_{mn}n_i + \varphi_i\;\;,
\end{equation}
where $\beta_{mn}$ is the structural coefficient (to which the causal interpretations are applied), $\alpha$ is a fitting coefficient, and $\varphi_i$ are noise terms \cite{Anderson1988,Bollen2013,Bollen2014}.  This equation is an SEM, not a regression, which implies it is not equivalent \cite{Bollen2013} to 
\begin{equation}
n_i = \beta_{mn}^{-1}\left(m_i-\alpha-\varphi_i\right)\;\;.
\end{equation}
The first SEM is for the causal relationship $\mathbf{M}\rightarrow\mathbf{N}$, and modeling the associated causal relationship of this data pair, $\mathbf{N}\rightarrow\mathbf{M}$, requires a separate SEM in this framework, e.g., 
\begin{equation}
n_i = \gamma + \beta_{nm}m_i + \vartheta_i \;\;.
\end{equation}
The ambiguity of the equals sign (i.e., ``$=$'') in SEM has been argued to be one of the primary sources of confusion for analysts using the method, and proposals have been made to instead use assignment operators (i.e., ``$:=$'') \cite{Pearl2012} or associated ``path diagrams'' (i.e., directed acyclic graphs) \cite{Pearl2000}.

Bollen and Pearl provide an overview of many common criticisms (along with responses) of SEM \cite{Bollen2013}.  The philosophical framework of using SEM for causal inference has also been criticized in the literature (see, e.g., \cite{Hall2007,Hitchcock2009}).  There have also been criticisms regarding the causal interpretations of SEM in particular (see, e.g., \cite{Biddle1987,Cliff1983}) It has been shown that SEM and the potential outcome approach are equivalent \cite{Bollen2013,Pearl2000,Morgan2014}, although it has been argued that the potential outcome approach is more formal (see a summary of the argument in \cite{Bollen2013}).  An SEM may be seen as a ``formula for computing the potential outcomes'' \cite{Greenland2002}.

Graphical models are a part of many statistical fields, particularly statistical physics \cite{Lauritzen1996}.  Path analysis has been a part of statistics since the early work of Wright \cite{Wright1934}.  Eerola notes in \cite{Eerola2012} that the practice actually began before Wright with the work of Yule in 1903 \cite{Yule1903}.  Causal inference using directed acyclic graphs (DAGs; also called path diagrams or causal graphs) was originally an aid for SEM \cite{Greenland2002}.  The formal theory of DAGs was developed as part of machine learning efforts to model probabilistic reasoning, e.g., using Bayesian nets \cite{Spirtes2000}.  An example of a DAG for a system containing three variables $A$, $B$, and $C$ might be
\begin{equation}
A \rightarrow B \rightarrow C
\end{equation}
or
\begin{equation}
A \rightarrow B \leftarrow C\;\;.
\end{equation}
Formally, a DAG obeys three conditions, the ``causal Markov'' condition, the ``causal minimality'' condition, and the faithfulness condition \cite{Spirtes2000,Pearl2000}.  It may be assumed that $A$ and $C$ are independent in the second DAG, which is written as $A\ci C$.  The Markov condition states $A$ and $C$ are also independent in the first DAG given (or ``conditional on'') the presence of $B$, i.e., $A\ci C|B$ \cite{Spirtes2000}.  The minimality condition states that any proper subgraph (e.g., removing one of the directed edges, i.e., deleting an arrow) of the DAG containing the same vertex set will obey the Markov condition \cite{Spirtes2000,Hitchcock2012}.  The faithfulness condition states that all probabilistic independences within the model set of variables (e.g., $\{A,B,C\}$ in the example DAGs above) are required by the Markov condition \cite{Spirtes2000,Pearl2000,Hitchcock2012}.  These conditions are the framework by which a DAG models probabilistically causal relationships among variables \cite{Pearl2000}.  

SEM and DAG approaches to computational causality have been combined, along with counterfactuals, in the Structural Causal Model (SCM) proposed by Pearl \cite{Pearl2000,Pearl2009}.  Pearl lists the goals of SCM as (in \cite{Pearl2009})
\begin{enumerate}
\item ``The unification of the graphical, potential outcome, structural equations, decision analytical \cite{Dawid2002}, interventional \cite{Woodward2003}, sufficient component \cite{Rothman1976} and probabilistic \cite{Suppes1970} approaches to causation; with each approach viewed as a restricted version of the SCM.''
\item ``The definition, axiomatization and algorithmization of counterfactuals and joint probabilities of counterfactuals''
\item ``Reducing the evaluation of effects of causes, mediated effects, and causes of effects to an algorithmic level of analysis.''
\item ``Solidifying the mathematical foundations of the potential-outcome model, and formulating the counterfactual foundations of structural equation models.''
\item ``Demystifying enigmatic notions such as confounding, mediation, ignorability, comparability, exchangeability (of populations), superexogeneity and others within a single and familiar conceptual framework.''
\item ``Weeding out myths and misconceptions from outdated traditions \cite{Meek1994,Greenland1999,Cole2002,Arah2008,Shrier2009,Pearl2009l}.''
\end{enumerate}
Introductions to SCM may be found in \cite{Pearl2009,Pearl2000}.  Pearl emphasizes that SCM pays special attention to confounding (through the ``back-door criteria'' for DAGs) and relies on non-parametric (i.e., in general, non-linear) SEMs to study counterfactuals, rather than the more traditional linear SEM \cite{Pearl2009}.  Criticisms of SCM include arguments over the types of causes being explored with the approach and discussion of counterexamples for which SCM fails (see, e.g., \cite{Hall2007,Glymour2010,Menzies2004}).

Kleinberg has proposed a logical approach to data causality whereby causes are formulated using probabilistic computation tree logic (PCTL) \cite{Kleinberg2009,Kleinberg2011,Kleinberg2012}.  A potential cause $c$ is identified in this framework as a PCTL formula obeying the following three conditions, $c$ has some finite probability of occurring, the probability of the effect $e$ is less than some value $p$, and there is a logical path from $c$ to $e$ that may occur with a probability greater than or equal to $p$ within a finite amount of time (paraphrased from \cite{Kleinberg2011}).  The causal significance $\varepsilon_{avg}$ is defined as
\begin{equation}
\label{eqn:Klein}
\varepsilon_{avg}(c,e) = \sum_{x\in \mathcal{X}\setminus c} \frac{P(e|c\wedge x) - P(e|\neg c\wedge x)}{|\mathcal{X}\setminus c|}\;\;,
\end{equation}
where $\mathcal{X}$ is the set of all potential causes of $e$ \cite{Kleinberg2011,Kleinberg2009}, $P(a)$ is the probability of $a$, $A\wedge B$ is the intersection of $A$ and $B$, and $A\setminus B$ is the set $A$ minus the set $B$, i.e., $A\setminus B = \{x\;|\;x\in A\mathrm{\ and\ }x\not\in B\}$.  The logic used to define the cause and effect relationships is temporal, so there are time windows associated with each term of the sum in Eqn.\ \ref{eqn:Klein}.  A cause $c$ is an {\em $\varepsilon$-significant cause} of $e$ if $|\varepsilon_{avg}|\nless\varepsilon$ \cite{Kleinberg2011}.  A full introduction to this approach can be found in \cite{Kleinberg2012}, which also includes discussions of algorithmically finding $\varepsilon$-significant causes in large data sets and appropriately determining $\varepsilon$.  

\subsubsection{Time series causality} 
Time series causality studies are data causality studies using time series data.  Time series data are common to many research fields \cite{ITbook_placeholder,Box2013}, although many authors have argued that causal inferences should not be drawn from such data\footnote{See Section \ref{sec:whatis} for a discussion of this point.}.  The rest of this work is dedicated to times series causality studies, specifically times series causality tools used in the exploratory causal analysis of bi-variate time series data.  

\section{Time series causality tools}
\label{sec:tools}
There are many time series causality tools.  Attempting to catalog them all would be laborious, if it could be done at all, and would yield this work out-of-date before it is ever printed.  Most popular time series tools, however, appear to fall into one of five broad categories, Granger causality, information-theoretic causality, state space reconstruction causality, correlation causality, or penchant causality.  These categories are defined by both the theoretical and computational differences between them, though there may be substantial theoretical, computational, and especially motivational similarities between them.  Each category contains several different specific time series causality tools, and each category has critics and proponents, as described in the individual sections below.  The main idea behind the exploratory causal analysis posited in this work is that tools from each of these categories are complementary to each other and can (and should) be used in concert during the analysis process.

The Granger causality tool category contains model-based tools.  No other tool category relies on models of the time series data for causal inference.  Granger's original motivation, as explained in Section \ref{sec:GC}, was independent any model considerations, including linearity and stationarity.  However, Granger's insistence on a ``operational definition'' of causality \cite{Granger1963} led to comparisons of potential forecast models for the data being investigated.  The original operational definition proposed by Granger has been extended to include a wide variety of modeling frameworks, including linear, nonlinear, stationary, non-stationary, and computational methods, including many open source software packages (see, e.g., \cite{Cui2008,Luo2013,Tana2012,Barnett2014,Zang2012,Seth2010}).  In this work, any time series causality tool that involves models of the data is considered to belong to the Granger causality tool category.  For example, both directed transfer function \cite{Kaminski1991} and partial directed coherence \cite{Baccala2001} are considered tools that fall into this category.

The information-theoretic causality tool category contains tools that rely on information theory concepts for causal inferences; i.e., all the tools in this category use entropies of some kind to quantify the information in the data \cite{ITbook_placeholder}.  Times series causality tools from this category are often lauded for the use of rigorous definitions of information and uncertainty (see, e.g., \cite{Schindler2007}) but are often computationally difficult to calculate on empirical data (see, e.g., \cite{Kaiser2002}).  There are many open source software packages available to calculate transfer entropy (see, e.g., \cite{Wibral2014,Lindner2011,Montalto2014,Lizier2014}), which is the most popular times series causality tool in this category.  

The state space reconstruction causality tool category contains tools that rely on state space reconstructions of the times series data \cite{Packard1980,ITbook_placeholder,Sauer1991} for causal inferences.  The state space reconstruction involves delay vector embedding that is often used in nonlinear and chaotic times series analysis (see, e.g., \cite{Farmer1987,Casdagli1991}).  The individual tools themselves, however, often differ significantly in the way embeddings are used for causal inferences (see Section \ref{sec:SSRC}).  Embedding dimension and delay vector lag values must be set for each of the tools in this category, and this task can be difficult for empirical data (see, e.g., \cite{Hong2006,Ataei2003,Small2004,Kennel1992}).  There is at least one open source software package for convergent cross mapping \cite{Maher2015}, which is the most popular time series causality tool in this category.

The correlation causality tool category contains tools that directly use correlation (or coherence) between the times series data for causal inference.  This category includes tools that rely on various signal processing techniques (e.g., whitening \cite{Mcnames2007,Box2013} or Fourier transforms \cite{Box2013}) applied to the data before correlation calculations are used for causal inference, which may make this category appear to overlap with other categories.  For example, if a given tool uses an autoregressive model to remove noise from the signals and then draws causal inferences from the correlation between the signals, should that tool be considered part of the Granger causality or correlation causality category?  In this work, such a tool would be considered part of the correlation causality category because the causal inference depends directly on the correlation calculation, not the model used to remove noise from the signal.  Similarly, even though convergent cross mapping involves a correlation calculation, the tool is considered part of the state space reconstruction category because the causal inference is posited to be impossible without the state space reconstruction.  In practice, the tools in this category are all variants of lagged cross-correlations calculated in either the time or frequency domain.  Correlation calculations are part of many standard software packages (see, e.g., \cite{R2012,MATLAB2007,Octave2013}).

The penchant causality tool category contains tools that draw causal inference from counting  and comparing features between time series data sets.  Penchant causality and information-theoretic causality tools both must estimate probabilities from the data, which is not required for any of the other tool categories.  Penchant causality tools, however, do not use information-theoretic concepts for causal inferences.  The tools in this category rely only on identifying features in the time series pair that might be considered cause-effect pairs and then counting those pairs to estimate the associated probabilities.  In this work, kernel density estimation \cite{Kaiser2002} (and other methods for estimating probabilities from empirical data) will only be used with information-theoretic causality tools, not penchant causality tools.  Instead, tolerance domains will be used with penchant causality tools to provide probability estimation methods unrelated to those used by the information-theoretic tools and to help ensure the exploratory causal analysis uses a time series causality tool set that is not unnecessarily homogeneous in calculation techniques.  Unfortunately, there currently are not any software packages available to calculate penchants and leanings.  All the software used in this work is, however, available online\footnote{\url{https://github.com/jmmccracken}}.

\subsection{Granger causality}
\label{sec:GC}
Clive Granger made the following comment in his 2003 Nobel prize acceptance speech:
``$\ldots$causality has just two components:
\begin{enumerate}
\item The cause occurs before the effect; and
\item The cause contains information about the effect that is unique, and is in no other variable.
\end{enumerate}
A {\em consequence} of these statements is that the causal variable can help forecast the effect variable after other data has first been used. $\ldots$'' (emphasis in original) \cite{Granger2003}.  This statement reflects the motivation behind Granger causality, which is perhaps the best known and most widely used time series causality tool.  The precedent cause is common to all time series causality tools, as they are being considered in this work.  Ganger does not provide formal definitions of ``information'', in contrast to the information-theoretic measures, but the the second item in the quote may also be considered common to most time series causality tools.  However, Granger's ``consequence of these statements'' is the formulation of a tool based on forecasting models, which is unique among the time series causality tools discussed in this work.  

\subsubsection{Background}
\label{sec:GCback}
Consider a discrete universe with two time series $\mathbf{X}=\{X_t\;|\; t=1,\ldots,n\}$ and $\mathbf{Y}=\{Y_t\;|\; t=1,\ldots,n\}$, where $t=n$ is considered the present\footnote{The phrase ``present'' is used here to represent ``now''; i.e., the time that separates what is considered to be the past from what is considered to be the future.  These definitions are not meant to be formal in the physical sense (e.g., as a hyperplane in space-time).  Rather, the language here is meant to be notional, as Granger originally used them \cite{Granger1980}.} time.  All knowledge available in the universe at all times $t\le n$ will be denoted as $\Omega_n$.  Granger introduces the following two axioms, which he assumes always hold \cite{Granger1980} (Axioms A and B, {\em Ibid.)},
\begin{ax}
The past and present may cause the future, but the future cannot cause the past. 
\end{ax}
\begin{ax}
$\Omega_n$ contains no redundant information, so that if some variable $\mathbf{Z}$ is functionally related to one or more other variables, in a deterministic fashion, then $\mathbf{Z}$ should be excluded from $\Omega_n$. 
\end{ax}

Given this framework\footnote{Granger also notes the following third axiom {\em All causal relationships remain constant in direction throughout time} (Axiom C \cite{Granger1980}), but this axiom is more relevant to drawing causal conclusions in the larger system from which $\mathbf{X}$ and $\mathbf{Y}$ have been measured.  The goal of exploratory causal inference is, as described in Section \ref{sec:whatis}, more limited in scope.}, Granger introduces the following definition: Given some set $A$, $\mathbf{Y}$ causes $\mathbf{X}$ if
\begin{equation}
\label{eq:GCdef}
P(X_{n+1}\in A|\Omega_n) \neq P(X_{n+1}\in A|\Omega_n-\mathbf{Y})\;\;;
\end{equation}
i.e., $\mathbf{Y}$ causes $\mathbf{X}$ if the probability that a future value of the series $\mathbf{X}$ is in some set $A$ is different depending on whether or not all the knowledge in the universe up to the present is given or only that knowledge which is not in $\mathbf{Y}$ is given.  Intuitively, this difference in probability implies knowledge of $\mathbf{Y}$ provides some knowledge of $\mathbf{X}$.  Granger's original motivation was to take this definition and develop a practical, operational definition \cite{Granger1980,Granger1969,Granger1963,Granger1988}.

The operational definition of Granger causality centers on building forecast models for the time series.  For example, consider two autoregressive models for $f_1\left(\mathbf{X}\right)$ and $f_2\left(\mathbf{X}\right)$, one of which, $f_2$, is multivariate; i.e.,
\begin{eqnarray}
f_1\left(\mathbf{X}\right) &=& \left\{X_t = \sum_{i=1}^n a_i X_{t-i} + \varepsilon_i\right\}\\
f_2\left(\mathbf{X}\right) &=& \left\{X_t = \sum_{i=1}^n\sum_{j=1}^n b_i X_{t-i} + c_j Y_{t-j} + \nu_{ij}\right\}\;\;,
\end{eqnarray}
where $\varepsilon,\nu$ are uncorrelated noise terms and $a$, $b$, and $c$ are the appropriate model coefficients.  If $\sigma^2\left(f_2\left(\mathbf{X}\right)\right)<\sigma^2\left(f_1\left(\mathbf{X}\right)\right)$, where $\sigma^2\left(\mathbf{Z}\right)$ is the variance of the forecast errors for $\mathbf{Z}$, then $\mathbf{Y}$ ``Granger causes'' $\mathbf{X}$; i.e., if a better prediction of $\mathbf{X}$ can be made with $\mathbf{Y}$ rather than without it, then $\mathbf{Y}$ causes $\mathbf{X}$ in Granger's framework \cite{Schwert1979}.  This operational definition corresponds Granger's original formulation of causality \cite{Granger1963,Granger1969}, as Granger points out in \cite{Granger1980}.  Often, however, vector autoregressive definitions are used in practice, in conjunction with statistical tests (see, e.g, \cite{Lin2008,Ding2006}).

Consider a vector autoregressive (VAR) model for the system of $\mathbf{X}$ and $\mathbf{Y}$,
\begin{equation}
\label{eqn:VARex1}
\begin{pmatrix}
X_t \\ 
Y_t
\end{pmatrix} = \sum_{i=1}^n \begin{pmatrix}
A_{11}^i & A_{12}^i\\
A_{21}^i & A_{22}^i
\end{pmatrix}\begin{pmatrix}
X_{t-i} \\ 
Y_{t-i}
\end{pmatrix} + \begin{pmatrix}
\varepsilon_{1,t}\\
\varepsilon_{2,t}
\end{pmatrix}
\end{equation}
where $\varepsilon_{1,2}$ are, again, uncorrelated noise terms.  Suppose the coefficient matrix $A$ is found such that this model is optimal in some sense, e.g., the forecast error is minimized.  If this model is the best fit possible for the system of $\mathbf{X}$ and $\mathbf{Y}$, then $\mathbf{Y}$ Granger causes $\mathbf{X}$ only if $A_{12}^i\neq 0\;\forall i$ and $\mathbf{X}$ Granger causes $\mathbf{Y}$ only if $A_{21}^i\neq 0\;\forall i$.  A statistical test can then be formulated under the null hypothesis for non-causality, i.e., $\mathbf{Y}$ does not Granger cause $\mathbf{X}$ or vice versa, if $A_{12}^i = 0$ or $A_{21}^i = 0$.  For example, Toda et al.\ outline the creation of several different statistics, including a Wald statistic, to test for Granger non-causality \cite{Toda1994}.

\subsubsection{Practical Usage}
Consider a time series pair $\{\mathbf{X},\mathbf{Y}\}$ with
\begin{eqnarray*}
\mathbf{X} &=& \{X_t\; | \; t=1,2,\ldots,10\}\\
&=& \left\{0,0,1,0,0,1,0,0,1,0\right\}\\
\mathbf{Y} &=& \{Y_t\; | \; t=1,2,\ldots,10\}\\
&=& \left\{0,0,0,1,0,0,1,0,0,1\right\}.
\end{eqnarray*}
This response time series $\mathbf{Y}$ is described by $Y_t=X_{t-1}$ with the initial condition $Y_{t=1}=X_{t=1}=0$.  It follows that $\mathbf{X}$ drives $\mathbf{Y}$.  A model for this system can be written down, given the aforementioned initial condition, as
\begin{equation}
\label{eqn:GCsimpleex}
\begin{pmatrix}
X_t \\ 
Y_t
\end{pmatrix} = \begin{pmatrix}
B_t & 0\\
1 & 0
\end{pmatrix}\begin{pmatrix}
X_{t-1} \\ 
Y_{t-1}
\end{pmatrix}+
\begin{pmatrix}
C_t \\ 
0
\end{pmatrix}\;\;,
\end{equation}
where $B_t = C_t = 0\;\forall\;t\in \mathcal{T}$ and $B_t = C_t = 1\;\forall\;t\not\in \mathcal{T}$ with $\mathcal{T} = \{t\;|\;t\mod 3 \neq 0\}$.  It follows that $\mathbf{X}$ Granger causes $\mathbf{Y}$ because  $A_{21}^i\neq 0\;\forall i$.  The causal inference for this example is $\mathbf{X}\rightarrow\mathbf{Y}$, as expected.

In practice, fitting VAR models to the empirical data is not as straightforward as the example shown in Eqn.\ \ref{eqn:GCsimpleex}.  Often two different models,
\begin{equation}
\label{eqn:GCex2}
\begin{pmatrix}
X_t \\ 
Y_t
\end{pmatrix} = \sum_{i=1}^n \begin{pmatrix}
A_{xx,i} & A_{xy,i}\\
A_{yx,i} & A_{yy,i}
\end{pmatrix}\begin{pmatrix}
X_{t-i} \\ 
Y_{t-i}
\end{pmatrix} + \begin{pmatrix}
\varepsilon_{x,t}\\
\varepsilon_{y,t}
\end{pmatrix}
\end{equation}
(which is identical to Eqn.\ \ref{eqn:VARex1} but with notation changes that have been made to simplify the present discussion) and
\begin{equation}
\label{eqn:GCex3}
\begin{pmatrix}
X_t \\ 
Y_t
\end{pmatrix} = \sum_{i=1}^n \begin{pmatrix}
A_{xx,i}^\prime & 0\\
0 & A_{yy,i}^\prime
\end{pmatrix}\begin{pmatrix}
X_{t-i} \\ 
Y_{t-i}
\end{pmatrix} + \begin{pmatrix}
\varepsilon_{x,t}^\prime\\
\varepsilon_{y,t}^\prime
\end{pmatrix}\;\;,
\end{equation}
are fit to the data using well-known algorithms (see \cite{Barnett2014} for a discussion of such algorithms).  These models can be compared using a null hypothesis that, e.g., $A_{xy,1}=A_{xy,2}=\ldots=A_{xy,n}=0$ in Eqn.\ \ref{eqn:GCex2}, which can be tested using different test statistics \cite{Barnett2014,Toda1994}.  It has been argued that log-likelihood statistic
\begin{equation}
F_{Y\rightarrow X} = \ln\frac{|\Sigma_{xx}^\prime|}{|\Sigma_{xx}|}\;\;,
\end{equation}
where $\Sigma_{xx}^\prime=\mathop{cov}(\varepsilon_{x,t}^\prime)$ is the covariance of the $\mathbf{X}$ model residuals for Eqn.\ \ref{eqn:GCex3} and $\Sigma_{xx}=\mathop{cov}(\varepsilon_{x,t})$ is the covariance of the $\mathbf{X}$ model residuals for Eqn.\ \ref{eqn:GCex2}, is the most appropriate Granger causality test statistic because of various formal mathematical properties and an information theoretic interpretation in analogy with transfer entropy \cite{Barnett2014,Barnett2009}.

The interpretation of the magnitude of the log-likelihood statistic in information theoretic terms (i.e., as information flow) allows the individual statistics to be compared.  As Barnett et al.\ point out \cite{Barnett2014}, Granger causality statistics are often used only for hypothesis testing.  However, the primary question of bivariate exploratory causal analysis is which time series may been seen as the stronger driver, and such a question may be difficult to address using traditional Granger causality testing.  For example, consider a scenario in which the null hypothesis, $N_{XY}$, ``$\mathbf{X}$ does not cause $\mathbf{Y}$'' has been rejected at a significance level of 0.05 and the null hypothesis, $N_{YX}$, ``$\mathbf{Y}$ does not cause $\mathbf{X}$'' has also been rejected at a significance level of 0.05.  What should the causal inference be?  If $N_{XY}$ is rejected at a lower significance level than $N_{YX}$, e.g., $10^{-3}$ and $0.05$, respectively, should the causal inference be $\mathbf{Y}\rightarrow\mathbf{X}$ because there is ``more confidence'' that $\mathbf{X}$ does not cause $\mathbf{Y}$ than {\em vice versa} (i.e., $N_{XY}$ is rejected at a lower significance level)?  If the log-likelihood statistic is interpreted as an information flow, then the information flow between the time series can be compared\footnote{A similar approach will be used with the transfer entropy in Section \ref{sec:TE}}.  For example, if $F_{X\rightarrow Y}-F_{Y\rightarrow X}>0$, then the causal inference is $\mathbf{X}\rightarrow\mathbf{Y}$.

Many of the theoretical criticisms of Granger causality can be levied on most of the other time series causality measures used in this work.  For example, Granger emphasizes if $\mathbf{X}$ Granger causes $\mathbf{Y}$ then $\mathbf{X}$ should only be considered a potential physical cause \cite{Granger1963,Berzuini2012}, which is true of every measure used in this work.   The inability of Granger causality to identify confounding in the system, the apparent equating of causality with predictability, and the complete dependence on observed data for causal inference are, likewise, not unique to this tool.  These issues are discussed in Section \ref{sec:whatis}.  

A pair of perceived limitations of Granger causality, linearity and stationarity \cite{He2001}, have been addressed by extensions of the operational definitions described in Section \ref{sec:GCback}.  Eqn.\ \ref{eq:GCdef} is not restricted by linearity or stationarity, but the operational definitions originally introduced by Granger relied on linear models for the times series under consideration.  Nonlinear extensions have been approached with a variety of techniques, including SSR techniques \cite{Chen2004}, radial basis functions \cite{Ancona2004}, and assumptions of local linearity \cite{Freiwald1999}.   The use of Granger causality with non-stationary time series has also been explored in the literature (see, e.g., \cite{Hesse2003,Kaminski2001,Barnett2015}).  Computational approaches to Granger causality have also been studied as tools for both causal modeling \cite{Arnold2007} and causal inference in general \cite{Shojaie2010,Lozano2009}.  The Granger causality framework has also been extended to include spectral (e.g., Fourier transform) methods \cite{Dhamala2008}.

\subsection{Information-theoretic causality}
\label{sec:TE}
In 2000, Schreiber introduced transfer entropy as ``an information theoretic measure$\ldots$that quantifies the statistical coherence between systems evolving in time'' \cite{Schreiber2000}.  The quantity has become one of the primary tools of information-theoretic times series causality \cite{Schindler2007,Kaiser2002}, which focuses on using the tools of information theory (i.e., entropy and mutual information) for causal inference between times series data.  

\subsubsection{Background}
Consider a random variable $\mathbf{X}$ that takes value $X_n$ with probability $p_n$ with $n = 1,2,\ldots,N_X$.  The probability distribution $P(\mathbf{X}=X_n) = p_n\;\forall X_n$ has a discrete Shannon entropy, $H_X$ defined as
\begin{equation}
H_X = -\sum_{n=1}^{N_X} p_n \log_2 p_n\;\;,
\end{equation}
where the logarithm base determines the entropy units, which, in this case, is ``bits'' \cite{Shannon1948,Schreiber2000,Schindler2007,Kaiser2002}, and $\log_2 0:= 0$.  The Shannon entropy was developed as a measure of ``of how uncertain we are of the outcome'' $\mathbf{X}=X_n$ \cite{Shannon1948}.

The error made by incorrectly assuming $P(\mathbf{X}=X_n) = q_n$ (rather than $p_n$) is the Kullback entropy\footnote{This quantity is also known as the Kullback-Leibler divergence, relative entropy, and discrimination information, among others.  Kullback noted in 1987 that this quantity could be found under nine different names in the literature \cite{Kullback1987}.}
\begin{equation}
K_X =  \sum_{n=1}^{N_X} p_n \log_2 \frac{p_n}{q_n}\;\;,
\end{equation}
where, again, the base of the logarithm is due to the unit choice \cite{Kullback1951,Schreiber2000,Schindler2007,Kaiser2002}.  Henceforth throughout this subsection, the logarithm base notation will be dropped and all logarithms should be assumed base 2 (i.e., everything is in units of bits) unless otherwise noted.

Consider a second random variable $\mathbf{Y}$ that takes value $Y_m$ with probability $p_m$ with $m = 1,2,\ldots,N_Y$.  The joint entropy is defined as
\begin{equation}
H_{X,Y} = -\sum_{n=1}^{N_X} \sum_{m=1}^{N_Y} p_{n,m} \log p_{n,m}\;\;,
\end{equation}
where $p_{n,m}$ is the joint probability $P(\mathbf{X}=X_n,\mathbf{Y}=Y_m)$.  If the two random variables are statistically independent, then $H_{X,Y} = H_X+H_Y$ \cite{Schindler2007}, which is motivation for the introduction of the mutual information $I_{X;Y}$ as
\begin{equation}
I_{X;Y} = H_X + H_Y - H_{X,Y} = \sum_{n=1}^{N_X} \sum_{m=1}^{N_Y} p_{n,m} \log \frac{p_{n,m}}{p_n p_m}\;\;,
\end{equation}
where the last equality can also be seen as the Kullback entropy due to assuming $P(\mathbf{X}=X_n,\mathbf{Y}=Y_m)=p_n p_m$ \cite{Kaiser2002}.  The mutual information is symmetric and is, therefore, not much use as a time series causality tool.  Time lags and conditional entropies, i.e., $H_{X|Y} = H_{X,Y} - H_{Y}$, can be used to make the mutual information non-symmetric, but such modifications are not easily interpreted in terms of information flow \cite{Schreiber2000} (the assumption is that a flow of information from one time series to another may be indicative of a driving relationship).  

Schreiber's approach for using entropies to study dynamical structure of data was to focus on transitional probabilities in the system \cite{Schreiber2000}.  Suppose at time $t$, $\mathbf{X}(t) = X_n$ with some probability $P(\mathbf{X}(t) = X_n^{(t)})=p_n$.  The additional temporal structure allows for more complicated questions such as ``what is the uncertainty in $\mathbf{X}(t)$ given some value of $\mathbf{X}(t-1)$?''  The more basic question is how to define the transitional probabilities themselves, i.e., what is $P(\mathbf{X}(t) = X_n | \mathbf{X}(t-1) = X_{n-1},\mathbf{X}(t-2) = X_{n-2},\ldots,\mathbf{X}(0) = X_{0}) = p_{n|n-1,n-2,\ldots,0}$?

Assume $\mathbf{X}(t)$ is governed by a Markov process; i.e., $p_{n|n-1,n-2,\ldots,0} = p_{n|n-1}$ \cite{statsbook_placeholder}.  The basic concept of transfer entropy is to measure the error made by assuming the Markov process generating $\mathbf{X}$ does not depend at all on the second time series $\mathbf{Y}$.  This error is quantified, in analogy to the mutual information expression shown above, with the Kullback entropy as
\begin{equation}
\label{eqn:TE}
T_{Y\rightarrow X} = \sum_{n=1}^{N_X} \sum_{m=1}^{N_Y} p_{n+1,n,m}\log \frac{p_{n+1|n,m}}{p_{n+1|n}}\;\;,
\end{equation}
where $p_{n+1,n,m} = P(\mathbf{X}(t+1)=X_{n+1},\mathbf{X}(t)=X_n,\mathbf{Y}(\tau)=Y_m)$ is the joint probability of $\mathbf{X}$ at times $t$ and $t+1$ with $\mathbf{Y}$ at time $\tau$, and the two conditional probabilities are $p_{n+1|n,m} = P(\mathbf{X}(t+1)=X_{n+1}|\mathbf{X}(t)=X_n,\mathbf{Y}(\tau)=Y_m)$ and $p_{n+1|n} = P(\mathbf{X}(t+1)=X_{n+1}|\mathbf{X}(t)=X_n)$.  Schrieber notes that the ``most natural choices'' for $\tau$ are $\tau=t$ and $\tau=0$ \cite{Schreiber2000}.  The quantity $T_{Y\rightarrow X}$ is called the transfer entropy.  If $H_{X(t+1)|X(t)}$ is the conditional Shannon entropy at time $t+1$ given $t$, then the above expression can be rewritten as $T_{Y\rightarrow X} = H_{X(t+1)|X(t)}-H_{X(t+1)|X(t),Y(\tau)}$ \cite{Kaiser2002}.  Any pair of times series, $\mathbf{X}$ and $\mathbf{Y}$, will have (at least) two transfer entropies, $T_{Y\rightarrow X}$ and $T_{X\rightarrow Y}$, which can be compared to determine the times series causality \cite{Schreiber2000}.  

Transfer entropy is often considered just one part of an information-theoretic approach to time series causality \cite{Schindler2007}, but it will be the primary information-theoretic time series causality tool used in this work.

\subsubsection{Practical usage}
\label{sec:tePUSE}
Consider a time series pair $\{\mathbf{X},\mathbf{Y}\}$ with
\begin{eqnarray*}
\mathbf{X} &=& \{X_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,1,0,0,1,0,0,1,0\right\}\\
\mathbf{Y} &=& \{Y_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,0,1,0,0,1,0,0,1\right\},
\end{eqnarray*}
where, for convenience, the notation is $Z_t := Z(t)$. This example system obeys the joint and conditional probabilities shown in Table \ref{tab:teEx}.  The causal intuition for this system is that $\mathbf{X}$ drives $\mathbf{Y}$.  
\begin{table}
\begin{center}
\begin{tabular}{ll}
\toprule
$P\left(X_{t+1} = 0 |X_t=0\right) = \frac{1}{2}$ & $P\left(Y_{t+1} = 0 |Y_t=0\right) = \frac{4}{7}$ \\
$P\left(X_{t+1} = 1 |X_t=0\right) = \frac{1}{2}$ & $P\left(Y_{t+1} = 1 |Y_t=0\right) = \frac{3}{7}$ \\
$P\left(X_{t+1} = 0 |X_t=1\right) = 1$ & $P\left(Y_{t+1} = 0 |Y_t=1\right) = 1$ \\
$P\left(X_{t+1} = 1 |X_t=1\right) = 0$ & $P\left(Y_{t+1} = 1 |Y_t=1\right) = 0$\\
\midrule
$P\left(X_{t+1} = 0 |X_t=0,Y_t=0\right) = \frac{1}{4}$ & $P\left(Y_{t+1} = 0 |Y_t=0,X_t=0\right) = 1$\\
$P\left(X_{t+1} = 0 |X_t=0,Y_t=1\right) = 1$ & $P\left(Y_{t+1} = 0 |Y_t=0,X_t=1\right) = 0$\\
$P\left(X_{t+1} = 0 |X_t=1,Y_t=0\right) = 1$ & $P\left(Y_{t+1} = 0 |Y_t=1,X_t=0\right) = 1$\\
$P\left(X_{t+1} = 0 |X_t=1,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 0 |Y_t=1,X_t=1\right) = 0$\\
$P\left(X_{t+1} = 1 |X_t=0,Y_t=0\right) = \frac{3}{4}$ & $P\left(Y_{t+1} = 1 |Y_t=0,X_t=0\right) = 0$\\
$P\left(X_{t+1} = 1 |X_t=0,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 1 |Y_t=0,X_t=1\right) = 1$\\
$P\left(X_{t+1} = 1 |X_t=1,Y_t=0\right) = 0$ & $P\left(Y_{t+1} = 1 |Y_t=1,X_t=0\right) = 0$\\
$P\left(X_{t+1} = 1 |X_t=1,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 1 |Y_t=1,X_t=1\right) = 0$\\
\midrule
$P\left(X_{t+1} = 0 ,X_t=0,Y_t=0\right) = \frac{1}{9}$ & $P\left(Y_{t+1} = 0 ,Y_t=0,X_t=0\right) = \frac{4}{9}$\\
$P\left(X_{t+1} = 0 ,X_t=0,Y_t=1\right) = \frac{2}{9}$ & $P\left(Y_{t+1} = 0 ,Y_t=0,X_t=1\right) = 0$\\
$P\left(X_{t+1} = 0 ,X_t=1,Y_t=0\right) = \frac{1}{3}$ & $P\left(Y_{t+1} = 0 ,Y_t=1,X_t=0\right) = \frac{2}{9}$\\
$P\left(X_{t+1} = 0 ,X_t=1,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 0 ,Y_t=1,X_t=1\right) = 0$\\
$P\left(X_{t+1} = 1 ,X_t=0,Y_t=0\right) = \frac{1}{3}$ & $P\left(Y_{t+1} = 1 ,Y_t=0,X_t=0\right) = 0$\\
$P\left(X_{t+1} = 1 ,X_t=0,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 1 ,Y_t=0,X_t=1\right) = \frac{1}{3}$\\
$P\left(X_{t+1} = 1 ,X_t=1,Y_t=0\right) = 0$ & $P\left(Y_{t+1} = 1 ,Y_t=1,X_t=0\right) = 0$\\
$P\left(X_{t+1} = 1 ,X_t=1,Y_t=1\right) = 0$ & $P\left(Y_{t+1} = 1 ,Y_t=1,X_t=1\right) = 0$\\
\bottomrule
\end{tabular}
\caption{Conditional and joint probabilities of $\{\mathbf{X},\mathbf{Y}\}$ in Section \ref{sec:tePUSE} (the shorthand notation $Z_t := Z(t)$ is used for convenience).}
\label{tab:teEx}
\end{center}
\end{table}
The transfer entropy pair for this example can be calculated using Eqn. \ref{eqn:TE} and Table \ref{tab:teEx} as
\begin{equation}
T_{Y\rightarrow X} = \frac{1}{9}\log\left(\frac{1}{2}\right)+\frac{2}{9}\log\left(2\right)+\frac{1}{3}\log\left(1\right)+\frac{1}{3}\log\left(\frac{3}{2}\right) \approx 0.31
\end{equation}
and
\begin{equation}
T_{X\rightarrow Y} =  \frac{4}{9}\log\left(\frac{7}{4}\right)+\frac{2}{9}\log\left(1\right)+\frac{1}{3}\log\left(\frac{7}{3}\right) \approx 0.77 \;\;.
\end{equation}
The difference $T_{X\rightarrow Y}-T_{Y\rightarrow X} = 0.46$ is positive, which implies $\mathbf{X}\rightarrow\mathbf{Y}$ as expected.

It can be shown that the transfer entropy is equivalent to Granger causality (up to a factor of 2) if $\mathbf{X}$ and $\mathbf{Y}$ are jointly multivariate Gaussian (i.e., both variables follow normal (Gaussian) distributions individually and jointly) \cite{Barnett2009}.  As Barnett et al.\ point out in their paper, this result provided ``for the first time a unified framework for data-driven causal inference that bridges information-theoretic and autoregressive methods.''  The Gaussian restriction of the result implies the use of Granger causality and transfer entropy for exploratory causal analysis, in general, still depends on the data under consideration.  Other authors have also explored the relationship between Granger causality and information-theoretic causality measures such as transfer entropy; e.g., see \cite{Amblard2012,Lungarella2007}.

Criticism of transfer entropy has centered on two major issues, the estimation of probabilities necessary for the calculation of transfer entropy in continuous processes \cite{Kaiser2002} and the inability of transfer entropy to quantify the strength of causal influences \cite{Janzing2013}.  The latter is, as explained in Section \ref{sec:whatis}, not a concern for times series causality as it has been defined in this work.  The former is considered a more serious concern\footnote{It is interesting to note that this concern seems to have first been raised by the author who originally introduced transfer entropy \cite{Kaiser2002}.}, but transfer entropy has been shown to agree with intuitive notions of driving in several different examples, including both linear and nonlinear dynamics, using many different estimation techniques \cite{Kaiser2002,Nichols2006}.  Data is often assumed to be drawn from discrete state processes, in which case probability estimations are not a concern \cite{Kaiser2002}.  Estimating probabilities from the data is not unique to information-theoretic causality tools.  These issues are also present in the leaning calculations described in Section \ref{sec:lean}.  Possible issues involving probability estimations from the data will be addressed (following the philosophy outlined in Section \ref{sec:whatis}) by not relying on transfer entropy alone to draw causal inferences and, if necessary, calculating the transfer entropy using different estimation techniques and comparing the results.  

\subsection{State space reconstruction causality}
\label{sec:SSRC}
State space reconstruction techniques have been used extensively in nonlinear (e.g., see \cite{Deyle2011}) and chaotic (e.g., see \cite{Farmer1987}) times series analysis.  State space reconstruction causality (SSRC) is closely related to simplex projection \cite{Sugihara1990,Sugihara1990a}, which predicts a point in the time series $\mathbf{X}$ at a time $t+1$, labeled $X_{t+1}$, by using the points with the most similar histories to $X_t$.  One of the most commonly used SSRC tools is convergent cross-mapping (CCM) \cite{Sugihara2012}, which was originally proposed for confirmatory, as opposed to exploratory, causal analysis (see, e.g., \cite{Ye2014,Sugihara2012})\footnote{For example, CCM has been used to draw conclusions regarding the ``controversial sardine-anchovy-temperature'' problem \cite{Sugihara2012}, confirm predictions of climate effects on sardines \cite{Deyle2013}, compare the driving effects of precipitation, temperature, and solar radiation on the atmospheric CO$_2$ growth rate \cite{Wang2014}, and to quantify cognitive control in developmental psychology \cite{Anastas2013}.  The technique has also been presented as a useful tool in studying the causality of respiratory systems in insects \cite{Bozorgmagham2013}.}.  CCM will be the primary focus of this subsection.  However, in practice, the primary SSRC tool used in the exploratory causal analysis discussed in this work will be pairwise asymmetric inference (PAI) \cite{Weigel2014}, which is closely related to CCM.  

\subsubsection{Background}
CCM uses points with the most similar histories to $X_t$ to estimate $Y_t$.  The CCM correlation is the squared Pearson correlation coefficient\footnote{This definition differs slightly from the definition in \cite{Sugihara2012}, which uses the un-squared Pearsons correlation coefficient.} between the original time series $\mathbf{Y}$ and an estimate of $\mathbf{Y}$ made using its convergent cross-mapping with $\mathbf{X}$, which is labeled as $\mathbf{Y}|\tilde{\mathbf{X}}$:
\begin{equation}
C_{YX} = \left[\rho(\mathbf{Y},\mathbf{Y}|\tilde{\mathbf{X}})\right]^2\;\;.
\end{equation}
Any pair of times series, $\mathbf{X}$ and $\mathbf{Y}$, will have two CCM correlations, $C_{YX}$ and $C_{XY}$, which are compared to determine the time series causality.  Sugihara {\em et al.\ }\cite{Sugihara2012} define a difference of CCM correlations
\begin{equation}
\label{eqn:delta}
\Delta = C_{YX} - C_{XY}
\end{equation}
and use the sign of $\Delta$ (along with arguments of convergence\footnote{Sugihara {\em et al.\ }consider convergence to be critically important for determining times series causality, and note that it is ``a key property that distinguishes causation from simple correlation'' \cite{Sugihara2012}.}) to determine the time series causality between $\mathbf{X}$ and $\mathbf{Y}$.  If $\mathbf{X}$ can be estimated using $\mathbf{Y}$ better than $\mathbf{Y}$ can be estimated using $\mathbf{X}$ (e.g., if $\Delta < 0$), then $\mathbf{X}$ drives $\mathbf{Y}$.

An algorithm to find the CCM correlations may be written in terms of five steps:
\begin{enumerate}
\item {\bf Create the {\em shadow manifold} for $\mathbf{X}$, called $\tilde{\mathbf{X}}$}
Given an embedding dimension $E$, the {\em shadow manifold} of $\mathbf{X}$, labeled  $\tilde{\mathbf{X}}$, is created by associating an $E$-dimensional vector (also called a {\em delay vector}) to each point $X_t$ in $\mathbf{X}$, i.e., $\tilde{X}_t=\left(X_t,X_{t-\tau},X_{t-2\tau},\ldots,X_{t-(E-1)\tau}\right)$.  The first such vector is created at $t=1+(E-1)\tau$ and the last is at $t=L$ where $L$ is the number of points in the time series (also called the {\em library length}).

\item {\bf Find the nearest neighbors to a point in the shadow manifold at time $t$, $\tilde{X}_t$}
The minimum number of points required for a bounding simplex in an $E$-dimensional space is $E+1$ \cite{Sugihara1990,Sugihara1990a}.  Thus,  the set of $E+1$ nearest neighbors must be found for each point on the shadow manifold, $\tilde{X}_t$.  For each $\tilde{X}_t$, the nearest neighbor search results in a set of distances that are ordered by closeness $\{d_1,d_2,\ldots,d_{E+1}\}$ and an associated set of times $\{\hat{t}_1,\hat{t}_2,\ldots,\hat{t}_{E+1}\}$.  The distances from $\tilde{X}_t$ are
\begin{equation}
d_i = D\left(\tilde{X}_t,\tilde{X}_{\hat{t}_i}\right)\;\;,
\end{equation}
where $D(\tilde{a},\tilde{b})$ is the Euclidean distance between vectors $\tilde{a}$ and $\tilde{b}$.

\item {\bf Create weights using the nearest neighbors}
Each of the $E+1$ nearest neighbors\footnote{$E+1$ is the minimum number of points needed for a bounding simplex in an $E$-dimensional space \cite{Sugihara1990}.} are used to compute an associated weight.  The weights are defined as
\begin{equation}
\label{eqn:CCMweights}
w_i = \frac{u_i}{N}\;\;,
\end{equation}
where
$u_i = e^{-d_i/d_1}$ and the normalization factor is $N = \sum_{j=1}^{E+1} u_j\;\;.$

\item {\bf Estimate $\mathbf{Y}$ using the weights; (this estimate is called $\mathbf{Y}|\tilde{\mathbf{X}}$)}
A point $Y_t$ in $\mathbf{Y}$ is estimated using the weights calculated above.  This estimate is
\begin{equation}
Y_t|\tilde{\mathbf{X}} = \sum_{i=1}^{E+1} w_i Y_{\hat{t_i}}\;\;.
\end{equation}

\item {\bf Compute the correlation between $\mathbf{Y}$ and $\mathbf{Y}|\tilde{\mathbf{X}}$}
The CCM correlation is defined as 
\begin{equation}
C_{YX} = \left[\rho\left(\mathbf{Y},\mathbf{Y}|\tilde{\mathbf{X}}\right)\right]^2\;\;,
\end{equation}
where $\rho\left(A,B\right)$ is the standard Pearson's correlation coefficient between data sets $A$ and $B$.  
\end{enumerate}

The CCM algorithm depends on the embedding dimension $E$ and the lag time step $\tau$.  A dependence on $E$ and $\tau$ is a feature of most state space reconstruction methods \cite{Hong2006,vlachos2009,Small2004}.  Sugihara {\em et al.} mention that ``optimal embedding dimensions'' are found using univariate SSR \cite{Sugihara2012} (supplementary material), and other methods for determining $E$ and $\tau$ for SSR algorithms can be found in the literature (e.g., \cite{Hong2006,Small2004,Kennel1992}).

The CCM correlations shown above are not the only SSR correlations that can be tested.  The time series $\mathbf{X}$ may also be estimated using a multivariate shadow manifold consisting of points from both $\mathbf{X}$ and $\mathbf{Y}$ \cite{Deyle2013}.  For example, an $E+1$ dimensional point in the a multivariate shadow manifold constructed using both $\mathbf{X}$ and $\mathbf{Y}$ may be defined as $\tilde{X}_t=(X_t,X_{t-\tau},X_{t-2\tau},\ldots,X_{t-(E-1)\tau},Y_t)$.  An estimate of $\mathbf{X}$ using weights from a shadow manifold using this specific construction will be referred to as $\mathbf{X}|(\mathbf{XY})$ and the correlation between this estimate and the original time series will be labeled $C_{X(XY)}$.  A difference in CCM correlations similar to $\Delta$ can be defined using the multivariate embedding.  Consider $\Delta^\prime = C_{Y(YX)} - C_{X(XY)}$.  This multivariate embedding extension of CCM is referred to as pairwise asymmetric inference (PAI).  Comparisons between CCM and PAI can be found in Weigel et al.\ \cite{Weigel2014}.  

\subsubsection{Practical usage}
Consider a time series pair $\{\mathbf{X},\mathbf{Y}\}$ with
\begin{eqnarray*}
\mathbf{X} &=& \{X_t\; | \; t=1,2,\ldots,10\}\\
&=& \left\{0,0,1,0,0,1,0,0,1,0\right\}\\
\mathbf{Y} &=& \{Y_t\; | \; t=1,2,\ldots,10\}\\
&=& \left\{0,0,0,1,0,0,1,0,0,1\right\}.
\end{eqnarray*}
This noiseless impulse-response system obeys $Y_t=X_{t-1}$, leading to the intuitive causal relationship $\mathbf{X}$ drives $\mathbf{Y}$.  The PAI shadow manifolds for these two signals can be written down using an embedding dimension $E=3$ and a delay time step $\tau=1$ as
\begin{eqnarray}
\tilde{\mathbf{X}} &=& \left\{\tilde{X}_t\;|\;t=3,4,\ldots,10\right\}\\
&=&\left\{\begin{array}{c} 
\left\{1,0,0,0\right\},\\
\left\{0,1,0,1\right\},\\
\left\{0,0,1,0\right\},\\
\left\{1,0,0,0\right\},\\
\left\{0,1,0,1\right\},\\
\left\{0,0,1,0\right\},\\
\left\{1,0,0,0\right\},\\
\left\{0,1,0,1\right\}\\
\end{array}\right\}
\end{eqnarray}
and
\begin{eqnarray}
\tilde{\mathbf{Y}} &=& \left\{\tilde{Y}_t\;|\;t=3,4,\ldots,10\right\}\\
&=&\left\{\begin{array}{c} 
\left\{0,0,0,1\right\},\\
\left\{1,0,0,0\right\},\\
\left\{0,1,0,0\right\},\\
\left\{0,0,1,1\right\},\\
\left\{1,0,0,0\right\},\\
\left\{0,1,0,0\right\},\\
\left\{0,0,1,1\right\},\\
\left\{1,0,0,0\right\}\\
\end{array}\right\}\;\;.
\end{eqnarray}
Let the Euclidean distances between a PAI shadow manifold vector and every other vector in the manifold be 
\begin{eqnarray}
\left\{d_{t}^Z\right\} &=& \left\{D\left(\tilde{Z}_{m},\tilde{Z}_{t}\right)\;|\;m\in[3,10]\right\} \\
&=& \left\{\sqrt{(a_m- a_t)^2+(b_m- b_t)^2+(c_m- c_t)^2+(d_m -d_t)^2}\;|\;m\in[3,10]\right\}\;\;,
\end{eqnarray}
where $\tilde{Z}_i=\{a_i,b_i,c_i,d_i\}$.  The distances for the above shadow manifolds are
\begin{equation}
\left\{d_{t}^X\right\} = \left\{\begin{array}{c} 
\left\{0,\sqrt{3},\sqrt{2},0,\sqrt{3},\sqrt{2},0,\sqrt{3}\right\},\\
\left\{\sqrt{3},0,\sqrt{3},\sqrt{3},0,\sqrt{3},\sqrt{3},0\right\},\\
\left\{\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3}\right\},\\
\left\{0,\sqrt{3},\sqrt{2},0,\sqrt{3},\sqrt{2},0,\sqrt{3}\right\},\\
\left\{\sqrt{3},0,\sqrt{3},\sqrt{3},0,\sqrt{3},\sqrt{3},0\right\},\\
\left\{\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3}\right\},\\
\left\{0,\sqrt{3},\sqrt{2},0,\sqrt{3},\sqrt{2},0,\sqrt{3}\right\},\\
\left\{\sqrt{3},0,\sqrt{3},\sqrt{3},0,\sqrt{3},\sqrt{3},0\right\}
\end{array}\right\}
\end{equation}
and
\begin{equation}
\left\{d_{t}^Y\right\} = \left\{\begin{array}{c} 
\left\{0,\sqrt{2},\sqrt{2},1,\sqrt{2},\sqrt{2},1,\sqrt{2}\right\},\\
\left\{\sqrt{2},0,\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3},0\right\},\\
\left\{\sqrt{2},\sqrt{2},0,\sqrt{3},\sqrt{2},0,\sqrt{3},\sqrt{2}\right\},\\
\left\{1,\sqrt{3},\sqrt{3},0,\sqrt{3},\sqrt{3},0,\sqrt{3}\right\},\\
\left\{\sqrt{2},0,\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3},0\right\},\\
\left\{\sqrt{2},\sqrt{2},0,\sqrt{3},\sqrt{2},0,\sqrt{3},\sqrt{2}\right\},\\
\left\{1,\sqrt{3},\sqrt{3},0,\sqrt{3},\sqrt{3},0,\sqrt{3}\right\},\\
\left\{\sqrt{2},0,\sqrt{2},\sqrt{3},0,\sqrt{2},\sqrt{3},0\right\}
\end{array}\right\}\;\;.
\end{equation}
Let the pair $\left(d_{t(j)}^Z,j\right)$ denote for each manifold vector $\tilde{Z}_t$ the distance to $\tilde{Z}_j$ and the time $t=j$.  The ordered distances, ignoring the self-distances, are then
\begin{equation}
\left\{d_{t}^X\right\}_o = \left\{\begin{array}{c} 
\left\{\left(0,6\right),\left(0,9\right),\left(\sqrt{2},8\right),\left(\sqrt{2},5\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right),\left(\sqrt{3},10\right)\right\},\\
\left\{\left(0,7\right),\left(0,10\right),\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,8\right),\left(\sqrt{2},3\right),\left(\sqrt{2},6\right),\left(\sqrt{2},9\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right),\left(\sqrt{3},10\right)\right\},\\
\left\{\left(0,3\right),\left(0,9\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right),\left(\sqrt{3},10\right)\right\},\\
\left\{\left(0,4\right),\left(0,10\right),\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,5\right),\left(\sqrt{2},3\right),\left(\sqrt{2},6\right),\left(\sqrt{2},9\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right),\left(\sqrt{3},10\right)\right\},\\
\left\{\left(0,3\right),\left(0,6\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right),\left(\sqrt{3},10\right)\right\},\\
\left\{\left(0,4\right),\left(0,7\right),\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right),\left(\sqrt{3},9\right)\right\}
\end{array}\right\}
\end{equation}
and
\begin{equation}
\left\{d_{t}^Y\right\}_o = \left\{\begin{array}{c} 
\left\{\left(\sqrt{2},4\right),\left(\sqrt{2},5\right),\left(\sqrt{2},7\right),\left(\sqrt{2},8\right),\left(\sqrt{2},10\right),\left(1,6\right),\left(1,9\right)\right\},\\
\left\{\left(0,7\right),\left(0,10\right),\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,8\right),\left(\sqrt{2},3\right),\left(\sqrt{2},4\right),\left(\sqrt{2},7\right),\left(\sqrt{2},10\right),\left(\sqrt{3},6\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,9\right),\left(\sqrt{3},4\right),\left(\sqrt{3},5\right),\left(\sqrt{3},7\right),\left(\sqrt{3},8\right),\left(\sqrt{3},10\right),\left(1,3\right)\right\},\\
\left\{\left(0,4\right),\left(0,10\right),\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,5\right),\left(\sqrt{2},3\right),\left(\sqrt{2},4\right),\left(\sqrt{2},7\right),\left(\sqrt{2},10\right),\left(\sqrt{3},6\right),\left(\sqrt{3},9\right)\right\},\\
\left\{\left(0,6\right),\left(\sqrt{3},4\right),\left(\sqrt{3},5\right),\left(\sqrt{3},7\right),\left(\sqrt{3},8\right),\left(\sqrt{3},10\right),\left(1,3\right)\right\},\\
\left\{\left(0,4\right),\left(0,7\right),\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right),\left(\sqrt{3},9\right)\right\}
\end{array}\right\}\;\;.
\end{equation}
These ordered distances are then subset to the $E+1=4$ closest non-zero\footnote{It is assumed that $d_1\neq 0$ in Eqn.\ \ref{eqn:CCMweights} for any vector in the manifold because $\lim_{x\rightarrow \infty}e^{-x} = 0$ \cite{statsbook_placeholder}, which may imply that all the weights are zero if $d_1=0$.  In practice (i.e., with empirical time series), $d_1$ is rarely identically equal to zero.  However that is not always the case in simple examples like the one presented in this section.  Only manifold vector pairs with non-zero distances are used in this example because it is only meant to be illustrative.  The basic algorithm can be altered to handle zero distance manifold vector pairs (e.g., by changing how the weights are calculated), but such alterations would be counter to the point of this example.} distances for each vector in the manifold, which are then used to calculate the weights; i.e.,
\begin{equation}
\left\{\begin{array}{c} 
\left\{\left(\sqrt{2},8\right),\left(\sqrt{2},5\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right)\right\},\\
\left\{\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},6\right),\left(\sqrt{2},9\right),\left(\sqrt{3},4\right)\right\},\\
\left\{\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right)\right\},\\
\left\{\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},6\right),\left(\sqrt{2},9\right),\left(\sqrt{3},4\right)\right\},\\
\left\{\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},4\right),\left(\sqrt{3},7\right)\right\},\\
\left\{\left(\sqrt{3},3\right),\left(\sqrt{3},5\right),\left(\sqrt{3},6\right),\left(\sqrt{3},8\right)\right\}
\end{array}\right\} \Longrightarrow
\left\{\begin{array}{c} 
\left\{\left(0.278,8\right),\left(0.278,5\right),\left(0.222,4\right),\left(0.222,7\right)\right\},\\
\left\{\left(0.250,3\right),\left(0.250,5\right),\left(0.250,6\right),\left(0.250,8\right)\right\},\\
\left\{\left(0.263,3\right),\left(0.263,6\right),\left(0.263,9\right),\left(0.210,4\right)\right\},\\
\left\{\left(0.278,5\right),\left(0.278,8\right),\left(0.222,4\right),\left(0.222,7\right)\right\},\\
\left\{\left(0.250,3\right),\left(0.250,5\right),\left(0.250,6\right),\left(0.250,8\right)\right\},\\
\left\{\left(0.263,3\right),\left(0.263,6\right),\left(0.263,9\right),\left(0.210,4\right)\right\},\\
\left\{\left(0.278,5\right),\left(0.278,8\right),\left(0.222,4\right),\left(0.222,7\right)\right\},\\
\left\{\left(0.250,3\right),\left(0.250,5\right),\left(0.250,6\right),\left(0.250,8\right)\right\}
\end{array}\right\} = \left\{w_{t}^X\right\}_o
\end{equation}
and
\begin{equation}
\left\{\begin{array}{c} 
\left\{\left(\sqrt{2},4\right),\left(\sqrt{2},5\right),\left(\sqrt{2},7\right),\left(\sqrt{2},8\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},4\right),\left(\sqrt{2},7\right),\left(\sqrt{2},10\right)\right\},\\
\left\{\left(\sqrt{3},4\right),\left(\sqrt{3},5\right),\left(\sqrt{3},7\right),\left(\sqrt{3},8\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},4\right),\left(\sqrt{2},7\right),\left(\sqrt{2},10\right)\right\},\\
\left\{\left(\sqrt{3},4\right),\left(\sqrt{3},5\right),\left(\sqrt{3},7\right),\left(\sqrt{3},8\right)\right\},\\
\left\{\left(\sqrt{2},3\right),\left(\sqrt{2},5\right),\left(\sqrt{2},8\right),\left(\sqrt{3},6\right)\right\}
\end{array}\right\}\Longrightarrow
\left\{\begin{array}{c} 
\left\{\left(0.250,4\right),\left(0.250,5\right),\left(0.250,7\right),\left(0.250,8\right)\right\},\\
\left\{\left(0.263,3\right),\left(0.263,5\right),\left(0.263,8\right),\left(0.210,6\right)\right\},\\
\left\{\left(0.250,3\right),\left(0.250,4\right),\left(0.250,7\right),\left(0.250,10\right)\right\},\\
\left\{\left(0.250,4\right),\left(0.250,5\right),\left(0.250,7\right),\left(0.250,8\right)\right\},\\
\left\{\left(0.263,3\right),\left(0.263,5\right),\left(0.263,8\right),\left(0.210,6\right)\right\},\\
\left\{\left(0.250,3\right),\left(0.250,4\right),\left(0.250,7\right),\left(0.250,10\right)\right\},\\
\left\{\left(0.250,4\right),\left(0.250,5\right),\left(0.250,7\right),\left(0.250,8\right)\right\},\\
\left\{\left(0.263,3\right),\left(0.263,5\right),\left(0.263,8\right),\left(0.210,6\right)\right\}
\end{array}\right\} = \left\{w_{t}^Y\right\}_o\;\;,
\end{equation}
where $\left\{w_{t}^Z\right\}_o$ is the set of $E+1$ pairs $\left(w_{t(j)}^Z,j\right)$ consisting of normalized\footnote{The weights are shown, for convenience, with only three significant digits. As such, not all of the normalized weights for a given manifold vector sum to one exactly.} weights $w_{t(j)}$ calculated from the Euclidean distances between manifold vectors $\tilde{Z}_t$ and $\tilde{Z}_j$ as described in Eqn.\ \ref{eqn:CCMweights}.  These weights can be used to estimate the original signals as
\begin{eqnarray}
\mathbf{Y}|\tilde{\mathbf{X}} &=& \left\{Y_t|\tilde{\mathbf{X}}\;|\;t=3,4,\ldots,10\right\}\\ 
&=& \left\{ 0.444,0,0.210,0.444,0,0.210,0.444,0\right\} 
\end{eqnarray}
and
\begin{eqnarray}
\mathbf{X}|\tilde{\mathbf{Y}} &=& \left\{X_t|\tilde{\mathbf{Y}}\;|\;t=3,4,\ldots,10\right\}\\ 
&=& \left\{ 0,0.473,0.250,0,0.473,0.250,0,0.473\right\}\;\;. 
\end{eqnarray}
The PAI correlations are
\begin{equation}
C_{YX} = \left[\rho\left(\mathbf{Y},\mathbf{Y}|\tilde{\mathbf{X}}\right)\right]^2 \approx 0.78
\end{equation}
and
\begin{equation}
C_{XY} = \left[\rho\left(\mathbf{X},\mathbf{X}|\tilde{\mathbf{Y}}\right)\right]^2 \approx 0.88\;\;,
\end{equation}
which implies $\Delta \approx -0.1$ and $\mathbf{X}\rightarrow\mathbf{Y}$, as expected.

Proponents of SSRC often point out that such techniques may be more capable than Granger causality of identifying causality given weak or nonseparable dynamics \cite{Sugihara2012,Ma2014,Cummins2015}.  SSRC techniques have been described as a ``complementary approach'' to the more standard time series causality studies using GC techniques \cite{Cummins2015}.  One of the key ideas presented in this work is that no times series causality tool should be used alone, so we will follow the thought process implied by Cummins et al.\ in \cite{Cummins2015} and use both SSRC and GC techniques together.

It has been pointed out that CCM requires long times series \cite{Ma2014}, which may be a criticism of PAI as well\footnote{As Ma et al.\ state ``In fact, due to the computational way of state space reconstruction using delayed embedding technique, sufficiently long time series are required to guarantee that the nearest neighbors on the reconstructed attractor converge to the true neighborhood. $\ldots$  Thus, detecting causality based on nearest neighbors and mutual neighbors essentially requires sufficiently long time series data to make reliable causality detection.''  PAI, like CCM, relies on finding nearest neighbors in the shadow manifold, so this concern also applies to PAI.}.  Ma et al.\ have proposed a new SSRC technique called Cross Map Smoothness (CMS) to address this problem.  CMS is a measure of the smoothness of the cross map (i.e., the map from, e.g., the shadow manifold of $\mathbf{Y}$ to the shadow manifold of $\mathbf{X}$).  ``Smoothness'' is quantified by training error of a neural network that takes, e.g., the shadow manifold of $\mathbf{Y}$ as input and the shadow manifold of $\mathbf{X}$ as output\footnote{This technique relies on the proof that any smooth map can be approximated by a neural network \cite{Park1991}.}.  Other authors have argued that the projection back to a scalar time series from the state space reconstructions required by CCM and PAI (step 4 of the CCM algorithm) is ``inconsistent'' with the underlying theories of state space reconstruction \cite{Cummins2015}.  Cummins et al.\ suggest ``it is more consistent with the theory to test relationships between the state space reconstructions directly'' and propose testing the continuity of the cross map\footnote{This techniques relies on a hypothesis-testing framework to explore continuity in state space reconstructions developed by Pecora et al.\ \cite{Pecora1995}.} to determine the time series causality \cite{Cummins2015}.  

Fortunately, most of the time series used in this work are not short as Ma et al.\ defines it (i.e., 20 data points or less).  This work is also not explicitly concerned with the  consistency of a given technique with underlying SSR theories, especially if the technique is shown to be a reliable tool for causal inference.  As such, the primary SSRC tool used in this work will be PAI, primarily because its reliability has been tested for the kinds of physical data sets explored in the following sections \cite{Weigel2014}.  Of course, just as with any of the general classes of time series causality tools, other SSRC techniques can and should be used during the exploratory causal analysis if such techniques are thought to be useful for the given data.

\subsection{Correlation causality}
Lagged cross-correlation, also known as cross-lagged correlation, has been a popular time series causality tool in psychology \cite{Kenny1975,Rogosa1980} and general signal analysis for many years \cite{Mcnames2007}.  Some authors consider it to be the first time series causality tool \cite{Kenny1975}, with origins that can be traced back to 1901 \cite{Bartlett1935}.  The shortcomings of lagged cross-correlation have been discussed at length in the literature \cite{Rogosa1980,Runge2014,Mcnames2007}.  It is still, however, among the most popular time series causality tools because of its simplicity \cite{Mcnames2007,Rogosa1980}.  

\subsubsection{Background}
Consider two time series $\mathbf{X} = \{X_t\;|t=0,1,2,\ldots,N\}$ and $\mathbf{Y} = \{Y_t\;|t=0,1,2,\ldots,N\}$.  The lagged cross-correlation is defined as the normalized cross-covariance \cite{Box2013}
\begin{equation}
\rho^{xy}_l = \frac{E\left[\left(X_t-\mu_X\right)\left(Y_{t-l}-\mu_Y\right)\right]}{\sqrt{\sigma^2_X\sigma^2_Y}}\;\;,
\end{equation}
where $l$ is the lag, $\sigma^2_Z$ is the variance of $\mathbf{Z}$, $\mu_Z$ is the mean of $\mathbf{Z}$, $E\left[\left(X_t-\mu_X\right)\left(Y_{t-l}-\mu_Y\right)\right]$ is the cross-covariance, and $E[z]$ is the expectation value of $z$ \cite{Carter1987,Mcnames2007,Box2013}.  Causal inference usually relies on using differences of these cross-correlations \cite{Rogosa1980,Rozelle1969,Yee1968}; i.e.,
\begin{equation}
\Delta_l = |\rho^{xy}_l| - |\rho^{yx}_l|\;\;,
\end{equation}
where $|z|$ is the absolute value of $z$.  If $\Delta_l$ is positive, then the correlation between $\{X_t\;|t=l,l+1,l+2,\ldots,N\}$ and $\{Y_t\;|t=0,1,2,\ldots,N-l\}$ is higher (i.e., further from zero) than the correlation between $\{X_t\;|t=0,1,2,\ldots,N-l\}$ and $\{Y_t\;|t=l,l+1,l+2,\ldots,N\}$.  The causal interpretation is as follows: If $\Delta_l > 0$, then $\mathbf{Y}\rightarrow\mathbf{X}$ at lag $l$, and if $\Delta_l < 0$, then $\mathbf{X}\rightarrow\mathbf{Y}$ at lag $l$.  If $\Delta_l = 0$, then there is no causal inference at lag $l$.  This interpretation depends on the definition of $l$ as a lag, i.e., $l\le 0$.  If $l$ is allowed to be a lead, i.e., $l>0$, then these causal inference rules need to be altered.

The causal inference appears to depend on symmetry in the lags used to calculate the cross-correlations.  This symmetry is not required, but it does make the interpretation of $\Delta_l$ more straightforward.  For example, consider
\begin{equation}
\Delta_{ll^\prime} = |\rho^{xy}_l| - |\rho^{yx}_{l^\prime}|\;\;.
\end{equation}
Suppose a pair of signals exist such that $\Delta_{ll^\prime}>0$ and $\Delta_{l^\prime l}>0$.  What is the causal inference for this data?  What is the causal inference if for example, $\mathbf{X}$ is more correlated with $\mathbf{Y}$ lagged by two time steps than $\mathbf{Y}$ is with $\mathbf{X}$ lagged by one time step?  Such subtle questions will be avoided in this work, and $\Delta_l$ will be the lagged cross-correlation tool used in the exploratory causal analysis examples.

\subsubsection{Practical usage}
\label{sec:lccPUSE}
Consider a time series pair $\{\mathbf{X},\mathbf{Y}\}$ with
\begin{eqnarray*}
\mathbf{X} &=& \{X_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,1,0,0,1,0,0,1,0\right\}\\
\mathbf{Y} &=& \{Y_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,0,1,0,0,1,0,0,1\right\}.
\end{eqnarray*}
The structure of this system, i.e., $Y_t=X_{t-1}$, implies $\mathbf{X}$ drives $\mathbf{Y}$.  Table \ref{tab:lccEx} can be calculated\footnote{Table \ref{tab:lccEx} is calculated using using the {\sc MATLAB} function {\em corr}, which calculates the cross-correlation as $\rho_l^{xy} = m \sum_i \tilde{X}_i \tilde{Y}_{i-l}$ with $\tilde{Z}_t = Z_t-\mu_Z$ where $m=\left(||\tilde{\mathbf{X}}||_2||\tilde{\mathbf{Y}}||_2\right)^{-1}$ is the inverse of the product of the Euclidean norms of $\tilde{\mathbf{X}}$ and $\tilde{\mathbf{Y}}$, $\mu_z$ is the mean of $\mathbf{Z}$, and $\tilde{\mathbf{Z}} = \{\tilde{Z}_t\;|\;t=0,1,\ldots,9\}$.} by considering $l\in[0,6]$.
\begin{table}
\begin{center}
\begin{tabular}{ccc|r}
$l$ & $\rho^{xy}_l$ & $\rho^{yx}_l$ & $\Delta_l$\\
\midrule
0 & 0.43 & 0.43 & 0.0\\
1 & 0.38 & 1.0 & -0.62 \\
2 & 0.75 & 0.45 & 0.30 \\
3 & 0.40 & 0.55 & -0.15 \\
4 & 0.32 & 1.0 & -0.68 \\
5 & 0.61 & 0.41 & 0.20 \\
6 & 0.33 & 0.58 & -0.24
\end{tabular}
\caption{Lagged cross-correlation calculations for the example times series pair $\{\mathbf{X},\mathbf{Y}\}$ in Section \ref{sec:lccPUSE}.}
\label{tab:lccEx}
\end{center}
\end{table}

One of the main practical issues with lagged cross-correlations is the decision of which lag to consider for causal inference.  Table \ref{tab:lccEx} shows $\Delta_l$ is nonzero for most $l$ but does not suggest the same causal inference $\forall\;l>0$.  One strategy is to determine the relevant lag as the lag corresponding to the maximum difference, i.e., use $\Delta_{m}$ for causal inference where
\begin{equation}
|\Delta_{m}| = \max_l |\Delta_l|\;\;.
\end{equation}
For this example, $\Delta_m = - 0.68$, which implies $\mathbf{X}\rightarrow\mathbf{Y}$ as expected.  However, $\Delta_m=\Delta_l$ at $l=4$ not $l=1$ as might be expected.  One of the primary criticisms of lagged cross-correlation causality tools is the difficulties arising from auto-correlations in the data \cite{Mcnames2007,Runge2014}, as seen in this example.  Other criticisms of lagged cross-correlations include underlying assumptions of linearity \cite{Mcnames2007} and stationarity \cite{Rogosa1980}.  The simplicity of these calculations, however, often mean lagged cross-correlations are calculated as a first step of an exploratory causal analysis.  

\subsection{Penchant causality}
\label{sec:lean}
Leaning is a time series causality technique that is derived directly from the definition of probabilistic causality \cite{Suppes1970}.  Penchants, from which the leaning is found, are related to the Eells measure of causal strength (also called the probability contrast) \cite{Illari2011}, the weight of evidence \cite{Good1984}, and the causal significance \cite{Kleinberg2012}.  The main difference between penchants and the related measures is the intended use.  Penchants and leanings will not be used as measures of causal strength in this work.  Rather, they will be considered indicative of driving without any concern for notions of the ``strength'' of such driving.  The penchant is non-parametric in the sense that there is no assumed functional relationship between the time series being investigated.

\subsubsection{Background}
The causal penchant $\rho_{EC}\in\left[1,-1\right]$ is defined as
\begin{equation}
\label{eq:pen}
\rho_{EC} := P\left(E|C\right) - P\left(E|\bar{C}\right).
\end{equation}
The motivation for this expression is in the straightforward interpretation of $\rho_{EC}$ as a causal indicator; i.e.,\ if $C$ drives $E$, then $\rho_{EC} > 0$, and if $\rho_{EC} \le 0$, then the direction of causal influence is undetermined.    

One of the main ideas of the penchant definition is to circumvent philosophical issues regarding $P(E|\bar{C})$ as being unobservable by using an expression that removes any conditioning on the absence of an assumed cause.  Eqn.\ \ref{eq:pen} can be rewritten using Bayes' theorem 
\begin{equation}
\label{eq:bayes}
P(E|C) = P(C|E)\frac{P(E)}{P(C)}
\end{equation}
and the definitions of probability complements
\begin{equation}
\label{eq:comp1}
P(\bar{C}) = 1-P(C)
\end{equation}
\begin{equation}
\label{eq:comp2}
P(\bar{C}|E) = 1-P(C|E).  
\end{equation}
Using Eqn.\ \ref{eq:comp2} with Eqn.\ \ref{eq:bayes} gives 
\begin{eqnarray*}
P(\bar{C}|E) &=& 1-P(E|C)\frac{P(C)}{P(E)}
\end{eqnarray*}
Inserting this into Eq.\ \ref{eq:bayes} written in terms of $\bar{C}$\;\;,
\begin{eqnarray*}
P(E|\bar{C}) &=& P(\bar{C}|E)\frac{P(E)}{P(\bar{C})}\\
\end{eqnarray*}
yields an alternative form of the second term in Eqn.\ \ref{eq:pen}
\begin{eqnarray*}
P(E|\bar{C}) &=&\left(1-P(E|C)\frac{P(C)}{P(E)}\right)\frac{P(E)}{1-P(C)}\;\;,
\end{eqnarray*}
This expression gives a penchant that requires only a single conditional probability estimate:
\begin{equation}
\label{eq:pencal}
\rho_{EC} = P(E|C)\left(1+\frac{P(C)}{1-P(C)}\right)-\frac{P(E)}{1-P(C)}\;\;.
\end{equation}

The penchant is not defined if $P(C)$ or $P(\bar{C})$ are zero (because the conditionals in Eqn.\ \ref{eq:pen} would be undefined).  Thus, the penchant is not defined if $P(C)=0$ or if $P(C)=1$.  The former condition corresponds to an inability to determine causal influence between two time series when a cause does not appear in one of the series; the latter condition is interpreted as an inability to determine causal influence between two time series if one is constant.  The use of Bayes' theorem in the derivation of Eqn.\ \ref{eq:pencal} implies that the penchant is not defined if $P(E)$ or $P(\bar{E})$ are zero.  The method given in this work uses no {\em a priori} assignment of ``cause'' or ``effect'' to a given time series pair when using penchants for causal inference.  So, operationally, the constraints on $P(C)$ and $P(E)$ only mean that the penchant is undefined between pairs of time series where one series is constant. 

Consider the assignment of $\mathbf{X}$ as the cause, $C$, and $\mathbf{Y}$ as the effect, $E$.  If $\rho_{EC}>0$, then the probability that $\mathbf{X}$ drives $\mathbf{Y}$ is higher than the probability that it does not, i.e., $\mathbf{X}\xrightarrow{pen}\mathbf{Y}$.  It is possible, however, that the penchant could also be positive when $\mathbf{X}$ is assumed as the effect and $\mathbf{Y}$ is assumed as the cause, i.e., $\mathbf{Y}\xrightarrow{pen}\mathbf{X}$.  The leaning addresses this apparent confusion via
\begin{equation}
\label{eq:leaning}
\lambda_{EC} := \rho_{EC} - \rho_{CE}
\end{equation}
for which $\lambda_{EC}\in\left[-2,2\right]$. A positive leaning implies the assumed cause $C$ drives the assumed effect $E$ more than the assumed effect drives the assumed cause, a negative leaning implies the effect $E$ drives the assumed cause $C$ more than the assumed cause drives the assumed effect, and a zero leaning yields no causal inference.  

The possible outcomes are notated as
\begin{eqnarray*}
\lambda_{EC}>0 \quad\{C,E\} = \{\mathbf{X},\mathbf{Y}\}&\Rightarrow&\mathbf{X}\xrightarrow{lean}\mathbf{Y}\\
\lambda_{EC}<0\quad\{C,E\} = \{\mathbf{X},\mathbf{Y}\}&\Rightarrow&\mathbf{Y}\xrightarrow{lean}\mathbf{X}\\
\lambda_{EC}=0\quad\{C,E\} = \{\mathbf{X},\mathbf{Y}\}&\Rightarrow& \mbox{no conclusion}
\end{eqnarray*}
with $\{C,E\} = \{\mathbf{A},\mathbf{B}\}$ meaning $\mathbf{A}$ is the assumed cause and $\mathbf{B}$ as the assumed effect.

If $\lambda_{EC}>0$ with $\mathbf{X}$ as the assumed cause and $\mathbf{Y}$ as the assumed effect, then $\mathbf{X}$ has a larger penchant to drive $\mathbf{Y}$ than $\mathbf{Y}$ does to drive $\mathbf{X}$.  That is, $\lambda_{EC}>0$ implies that the difference between the probability that $\mathbf{X}$ drives $\mathbf{Y}$ and the probability that it does not is higher than the difference between the probability that $\mathbf{Y}$ drives $\mathbf{X}$ and the probability that it does not.  

The leaning is a function of four probabilities, $P(C)$, $P(E)$, $P(C|E)$, and $P(E|C)$.  The usefulness of the leaning for causal inference will depend on an effective method for estimating these probabilities from times series and a more specific definition of the cause-effect assignment within the time series pair.  An operational definition of $C$ and $E$ will need to be drawn directly from the time series data if the leaning is to be useful for causal inference.  Such assignments, however, may be difficult to develop and may be considered arbitrary without some underlying theoretical support.  For example, if the cause is $x_{t-1}$ and the effect is $y_{t}$, then it may be considered unreasonable to provide a causal interpretation of the leaning without theoretical support that $\mathbf{X}$ may be expected to drive $\mathbf{Y}$ on the time scale of $\Delta t=1$.  This issue is, however, precisely one of the reasons for divorcing the causal inference proposed in this work (i.e., exploratory causal inference) from traditional ideas of causality.  Statistical tools are associational, and cannot be given formal causal interpretation without the use of assumptions and outside theories (see \cite{Illari2014} for an in-depth discussion of these ideas).  In practice, many different potential cause-effect assignments may be used to calculate different leanings, which may then be compared as part of the causal analysis of the data.  It can be noted that $\lambda_{AB} := \rho_{AB} - \rho_{BA}\Rightarrow -\lambda_{AB} = \rho_{BA} - \rho_{AB} := \lambda_{BA}$.  Thus, the causal inference is independent of which times series is initially assumed to be the cause (or effect).

\subsubsection{Practical usage}
The initial derivation of the penchant and leaning is intentionally left in terms of the vague quantities of ``cause'' $C$ and ``effect'' $E$.  This decision comes directly from the probabilistic definition of causality as $P(E|C)>P(E|\bar{C})$ \cite{Suppes1970} (or, e.g., \cite{Illari2014}), which was meant to convey a philosophical idea about the relationship between an object capable of generally being called a cause, i.e., $C$, and the associated object capable of generally being called an effect, i.e., $E$.   Granger introduced his causality measure in a similar fashion using the same probabilistic causality definition \cite{Granger1980}.  The practicality of the penchant and leaning depends on an interpretation of how to make the terms $C$ and $E$ ``operational'' (as Granger puts it \cite{Granger1980}).  

Consider a time series pair $(\mathbf{X},\mathbf{Y})$ with
\begin{eqnarray*}
\mathbf{X} &=& \{x_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,1,0,0,1,0,0,1,0\right\}\\
\mathbf{Y} &=& \{y_t\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,0,1,0,0,1,0,0,1\right\}.
\end{eqnarray*}

Because $y_t=x_{t-1}$, one may conclude that $\mathbf{X}$ drives $\mathbf{Y}$.  However, to show this result using a leaning calculation requires first a calculation using the cause-effect assignment $\{C,E\}=\{\mathbf{X},\mathbf{Y}\}$. For consistency with the intuitive definition of causality, we require that a cause must precede an effect.  It follows that a natural assignment may be $\{C,E\}=\{x_{t-l},y_t\}$ for $1 \leq l < t \leq 9$.  This cause-effect assignment will be referred to as the $l$-standard assignment.

The cause-effect assignment is an assignment of a given structure or feature of the data in one time series as the ``cause'' and another structure or feature of the data in the other time series as the ``effect''.  For example, in the $l$-standard cause-effect assignment, the cause is the lag $l$ time step in one time series and the effect is the current time step in the other.  The leaning compares the symmetric application of these cause-effect definitions to the time series pair.  So, for the above example of $\{C,E\}=\{x_{t-l},y_t\}$, the first penchant will be calculated using $\{C,E\}=\{x_{t-l},y_t\}$ and the second will be calculated using $\{C,E\}=\{y_{t-l},x_t\}$.  The second penchant is not the direct interchange of $C\Leftrightarrow E$ from the first penchant because such an interchange would violate the assumption that a cause must precede an effect.  For example, if the first penchant in the leaning calculation is calculated using $\{C,E\}=\{x_{t-l},y_t\}$, then the second penchant is not calculated using $\{C,E\}=\{y_t,x_{t-l}\}$ because the definition of the effect, $x_{t-l}$, precedes the definition of the cause, $y_t$.

Given $(\mathbf{X},\mathbf{Y})$, one possible penchant that can be defined using the 1-standard assignment is
\begin{eqnarray*}
\rho_{y_{t}=1,x_{t-1}=1} &=& \kappa \left(1+\frac{P\left(x_{t-1} = 1\right)}{1-P\left(x_{t-1} = 1\right)}\right)\\
& & -\frac{P\left(y_{t} = 1\right)}{1-P\left(x_{t-1} = 1\right)}\;\;,
\end{eqnarray*}
with $\kappa = P\left( y_t = 1 | x_{t-1} = 1\right)$.  Another penchant defined using this assignment is $\rho_{y_t=0,x_{t-1}=0}$ with  $\kappa = P\left( y_t = 0 | x_{t-1} = 0\right)$.  These two penchants are called observed penchants because they correspond to conditions that were found in the measurements.  Two other penchants have $\kappa = P\left( y_t = 0 | x_{t-1} = 1\right)$ and $\kappa = P\left( y_t = 1 | x_{t-1} = 0\right)$, and they are associated with unobserved conditions.  These unobserved penchants in the leaning calculation would involve a comparison of how unlikely postulated causes are to cause given effects.  Such comparisons are not as easily interpreted in the intuitive framework of causality, and as such, are often not used as part of leaning calculations. 

The probabilities in the penchant calculations can be estimated from time series using counts, e.g.,\
$$
P\left( y_t = 1 | x_{t-1} = 1\right) = \frac{n_{EC}}{n_C} = \frac{3}{3} = 1\;\;,
$$
where $n_{EC}$ is the number of times $y_t=1$ and $x_{t-1}=1$ appears in $(\mathbf{X},\mathbf{Y})$, and $n_{C}$ is the number of times the assumed cause, $x_{t-1}=1$, has appeared in $(\mathbf{X},\mathbf{Y})$.  

Estimating the other two probabilities in this penchant calculation using frequency counts from $(\mathbf{X},\mathbf{Y})$ requires accounting for the assumption that the cause must precede the effect by shifting $\mathbf{X}$ and $\mathbf{Y}$ into $\tilde{\mathbf{X}}$ and $\tilde{\mathbf{Y}}$ such that, for any given $t$, $\tilde{\mathbf{x}}_t$ precedes $\tilde{\mathbf{y}}_t$.  For this example, the shifted sequences are
\begin{eqnarray*}
\tilde{\mathbf{X}} &=& \left\{0,0,1,0,0,1,0,0,1\right\}\\
\tilde{\mathbf{Y}} &=& \left\{0,0,1,0,0,1,0,0,1\right\}
\end{eqnarray*}
which are both shorter than their counterparts above by a single value because the penchants are being calculated using the 1-standard cause-effect assignment. It follows that $\tilde{x}_t = x_{t-1}$ and $\tilde{y}_t=y_t$.  The probabilities are then
\begin{equation}
P\left( y_t = 1\right) = \frac{n_E}{L} = \frac{3}{9}
\end{equation}
and
\begin{equation}
P\left( x_{t-1} = 1\right) = \frac{n_C}{L} = \frac{3}{9}\;\;,
\end{equation}
where $n_C$ is the number of times $\tilde{x}_t = 1$, $n_E$ is the number of times $\tilde{y}_t = 1$, and $L$ is the (``library'') length of $\tilde{\mathbf{X}}$ and $\tilde{\mathbf{Y}}$ (which are assumed to be the same length).  

The two observed penchants in this example under the assumption that $\mathbf{X}$ causes $\mathbf{Y}$ (with $l=1$) are
\begin{equation}
\label{eqn:rhoex1}
\rho_{y_t=1,x_{t-1}=1}=1
\end{equation}
and
\begin{equation*}
\rho_{y_t=0,x_{t-1}=0}=1\;\;.
\end{equation*}
The observed penchants when $\mathbf{Y}$ is assumed to cause $\mathbf{X}$ are
\begin{eqnarray*}
\rho_{x_t=1,y_{t-1}=0} &=& \frac{3}{7}\;\;,\\
\rho_{x_t=0,y_{t-1}=1} &=& \frac{3}{7}\;\;,
\end{eqnarray*}
and
\begin{equation*}
\rho_{x_t=0,y_{t-1}=0}=-\frac{3}{7}\;\;.
\end{equation*}

The mean observed penchant is the algebraic mean of the observed penchants,  For $\mathbf{X}$ causes $\mathbf{Y}$, it is
\begin{eqnarray*}
\langle \rho_{y_t,x_{t-1}} \rangle &=& \frac{1}{2}\left(\rho_{y_t=1,x_{t-1}=1} + \rho_{y_t=0,x_{t-1}=0}\right)\\
&=& 1
\end{eqnarray*}
and for $\mathbf{Y}$ causes $\mathbf{X}$ is
\begin{eqnarray*}
\langle \rho_{x_t,y_{t-1}} \rangle &=& \frac{1}{3}\left(\rho_{x_t=1,y_{t-1}=0} \right.\\
& &\left. +\rho_{x_t=0,y_{t-1}=1} + \rho_{x_t=0,y_{t-1}=0}\right)\\
&=& \frac{1}{7}\;\;.
\end{eqnarray*}
The mean observed leaning that follows from the definition of the mean observed penchants is
\begin{eqnarray}
\label{eqn:meanlean}
\langle \lambda_{y_t,x_{t-1}} \rangle &=& \langle \rho_{y_t,x_{t-1}} \rangle - \langle \rho_{x_t,y_{t-1}} \rangle\\
&=& \frac{6}{7}\;\;.
\end{eqnarray}

The weighted mean observed penchant is defined similarly to the mean observed penchant, but each penchant is weighted by the number of times it appears in the data; e.g.,\
\begin{eqnarray*}
\langle \rho_{y_t,x_{t-1}} \rangle_w &=& \frac{1}{L}\left(n_{y_t=1,x_{t-1}=1}\rho_{y_t=1,x_{t-1}=1} \right.\\
& & \left.+ n_{y_t=0,x_{t-1}=0}\rho_{y_t=0,x_{t-1}=0}\right)\\
&=& 1
\end{eqnarray*}
and
\begin{eqnarray*}
\langle \rho_{x_t,y_{t-1}} \rangle_w &=& \frac{1}{L}\left(n_{x_t=1,y_{t-1}=0}\rho_{x_t=1,y_{t-1}=0} \right.\\
& & +n_{x_t=0,y_{t-1}=1}\rho_{x_t=0,y_{t-1}=1}\\
& & \left.+ n_{x_t=0,y_{t-1}=0}\rho_{x_t=0,y_{t-1}=0}\right)\\
&=& \frac{3}{63}\;\;,
\end{eqnarray*}
where $n_{a,b}$ is the number of times the assumed cause $a$ appears with the assumed effect $b$ and $L$ is the library length of $\tilde{\mathbf{X}}$ (i.e., $L=N-l$ where $N$ is the library length of $\mathbf{X}$ and $l$ is the lag used in the $l$-standard cause-effect assignment).  

The weighted mean observed leaning follows naturally as
\begin{eqnarray*}
\langle \lambda_{y_t,x_{t-1}} \rangle_w &=& \langle \rho_{y_t,x_{t-1}} \rangle_w - \langle \rho_{x_t,y_{t-1}} \rangle_w\\
&=& \frac{60}{63}\;\;.
\end{eqnarray*}
For this example, $\langle \lambda_{y_t,x_{t-1}} \rangle_w\Rightarrow \mathbf{X}\rightarrow\mathbf{Y}$ as expected.

Conceptually, the weighted mean observed penchant is preferred to the mean penchant because it accounts for the frequency of observed cause-effect pairs within the data, which is assumed to be a predictor of causal influence.  For example, given some pair $(\mathbf{A},\mathbf{B})$, if it is known that $a_{t-1}$ causes $b_{t}$ and both $b_t = 0\; |\; a_{t-1} = 0$ and $b_t = 0\; |\; a_{t-1} = 1$ are observed, then comparison of the frequencies of occurrence is used to determine which of the two pairs represents the cause-effect relationship.

If the example time series contained noise, then a realization of of the example time series $(\mathbf{X}^\prime,\mathbf{Y}^\prime)$ could be
\begin{eqnarray*}
\mathbf{X}^\prime &=& \{x_t^\prime\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,0,1.1,0,0,1,-0.1,0,0.9,0\right\}\\
\mathbf{Y}^\prime &=& \{y_t^\prime\; | \; t=0,1,\ldots,9\}\\
&=& \left\{0,-0.2,0.1,1.2,0,0.1,0.9,-0.1,0,1\right\}.
\end{eqnarray*}

The previous time series pair, $(\mathbf{X},\mathbf{Y})$ had only five observed penchants, but $(\mathbf{X}^\prime,\mathbf{Y}^\prime)$ has more due to the noise.  It can be seen in the time series definitions that $x_t^\prime = x_t \pm 0.1 := x_t \pm \delta_x$ and $x_t^\prime = x_t \pm 0.2 := x_t \pm \delta_y$.  The weighted mean observed leaning for $(\mathbf{X}^\prime,\mathbf{Y}^\prime)$ is $\langle \lambda_{y_t^\prime,x_{t-1}^\prime} \rangle_w \approx 0.19$. 

If the noise is not restricted to a small set of discrete values, then the effects of noise on the leaning calculations can be addressed by using the tolerances $\delta_x$ and $\delta_y$ in the probability estimations from the data.  For example, the penchant calculation in Eqn.\ \ref{eqn:rhoex1} relied on estimating $P(y_t=1|x_{t-1}=1)$ from the data, but if, instead, the data is known to be noisy, then the relevant probability estimate may be $P(y_t\in[1-\delta_y,1+\delta_y]|x_{t-1}\in[1-\delta_x,1+\delta_x])$.  If the tolerances, $\delta_x$ and $\delta_y$, are made large enough, then the noisy system weighted mean observed leaning, $\langle \lambda_{y_t^\prime\pm\delta_y,x_{t-1}^\prime\pm\delta_x} \rangle_w$, can, at least in the simple examples considered here, be made equal to the noiseless system weighted mean observed leaning, i.e.,\ $\langle \lambda_{y_t^\prime\pm\delta_y,x_{t-1}^\prime\pm\delta_x} \rangle_w = \langle \lambda_{y_t,x_{t-1}} \rangle_w$.  Tolerance domains, however, can be set too large.  If the tolerance domain is large enough to encompass every point in the time series, then the probability of the assumed cause becomes one, which leads to undefined penchants.  For example, given the symmetric definition of the tolerance domain used here, $\delta_x = 2$ implies $P(x_{t-1} = 1\pm\delta_x) = 1$, which implies $\langle \lambda_{y_t^\prime,x_{t-1}} \rangle_w$ is undefined.  The tolerance domains can be interpreted as the set of values that an analyst is willing to consider equivalent causes or effects.  For example, if the lag $l$ time step of $\mathbf{X}$, i.e., $x_{t-l}$, is the assumed cause of some assumed effect (e.g., the current time step of $\mathbf{Y}$, $y_t$), then an x-tolerance domain of $[x_{t-1}-a,x_{t-1}+b]$ may be thought of as an analyst's willingness to consider all values that fall within that domain equivalently as the assumed cause of that assumed effect.

Reasonable leaning calculations require an understanding of the noise in the measurements, which may not always be possible.  Estimating relevant tolerance domains is one of the two key difficulties in using penchants and leanings for causal inference.  The other is finding an appropriate cause-effect assignment.

\section{Exploratory Causal Analysis}
\label{sec:ECA}
Section \ref{sec:whatisECA} outlined a proposed framework for exploratory causal analysis.  This framework was characterized more by an approach to the analysis (i.e., a way of thinking about the data analysis) rather than the use of any specific technique.  This work will focus on performing exploratory causal analysis using a report of five different time series causality tools, one from each category presented in Section \ref{sec:tools}. 

Leanings will be used with various cause-effect assignments and tolerance domains, which will be set based on the data being analyzed.  The weighted mean observed leanings will be calculated using {\sc MATLAB}\footnote{The scripts and functions used to calculate the penchants and leanings can be found at \url{https://github.com/jmmccracken}}.  Lagged cross-correlation differences will be used with various lags but without any pre-treatment of the data.  All lagged cross-correlations will be calculated using the standard {\sc MATLAB} function {\em corr}.  PAI will be calculated using the methods and software\footnote{The software used to calculate PAI can be found at \url{https://github.com/jmmccracken}.} discussed in Section \ref{sec:SSRC}; the embedding dimension will always be $E=3$ and the delay time step will always be $\tau=1$, unless otherwise noted.  Transfer entropy will be calculated using the Java Information Dynamics Toolkit (JIDT) \cite{Lizier2014}.  This software package includes different methods for estimating probabilities from the data, but, unless otherwise noted, this work will only calculate the transfer entropy using the default kernel estimator with normalized data, a delay time step of 1, and a kernel width of 0.5\footnote{i.e., unless otherwise noted, the JIDT transfer entropy calculator will always be instantiated in {\sc MATLAB} with the following commands, ``{\tt teCalc=javaObject('infodynamics.measures.continuous.kernel.TransferEntropyCalculatorKernel');}'', ``{\tt teCalc.setProperty('NORMALISE','true');}'', and {\tt teCalc.initialise(1,0.5);}''.}.  Granger causality will calculated using the Multivariate Granger Causality (MVGC) toolbox, which calculates Granger causality in both the temporal and spectral domains \cite{Barnett2015}.  The MVGC toolbox provides several different ways to estimate the model order for the VAR model estimation step of the Granger causality calculation.  For consistency, the VAR model order will be set using the Bayesian information criterion \cite{Box2013,Weakliem1999} routine provided by the MVGC toolbox \cite{Barnett2015}, unless otherwise noted.

\subsection{ECA guess}
Exploratory causal analysis is the first step in a more rigorous data causality study of a system.  The results should guide future experiments or more formal and rigorous data techniques.  Nevertheless, there is a use in having a quick causal guess for a given time series pair.  Such a guess might be considered a very short summary of the exploratory causal analysis.  Consider a ternary vector define as
\begin{equation}
\vec{g} = (g_1,g_2,g_3,\ldots,g_n)\;\;,
\end{equation}
where each trit\footnote{{\em tr}inary dig{\em it} (see, e.g., \cite{Hayes2001})} represents the causal inference of a given time series causality tool for a given time series pair $(\mathbf{X},\mathbf{Y})$, 0 for $\mathbf{X}\rightarrow\mathbf{Y}$, 1 for $\mathbf{Y}\rightarrow\mathbf{X}$, and 2 if there is no conclusion (e.g., if the leaning is 0).  The vector $\vec{g}$ may then be used to provide a concise summary of the exploratory causal analysis (ECA) results, which will be called the {\em ECA guess}; i.e., $g_i = 0\;\forall g_i\in\vec{g}\Rightarrow\mathbf{X}\rightarrow\mathbf{Y}$ and $g_i = 1\;\forall g_i\in\vec{g}\Rightarrow\mathbf{Y}\rightarrow\mathbf{X}$.    The inner product of $\vec{g}$ with itself may be simple test for an ECA guess,
\begin{equation}
\vec{g}\cdot\vec{g} = |\vec{g}|^2 = \left\{
  \begin{array}{lr}
    0 & \mathrm{ECA\ guess\ is\ }\mathbf{X}\rightarrow\mathbf{Y}\\
    \mathrm{anything\ else} & \mathrm{ECA\ guess\ is\ not\ defined\ or\ }\mathbf{Y}\rightarrow\mathbf{X}
  \end{array}
\right.
\end{equation}
If $g_i = 1\;\forall g_i\in\vec{g}$, then the ECA guess would be $\mathbf{Y}\rightarrow\mathbf{X}$, which may make it tempting to interpret $|\vec{g}|^2=n$ as implying $\mathbf{Y}\rightarrow\mathbf{X}$.  It may be true, however, that $|\vec{g}|^2=n$ but $g_i \neq 1\;\forall g_i\in\vec{g}$.  As discussed in the previous subsection, $n=5$ in all the examples in this work.

It should be emphasized that the ECA guess is neither the final product nor the only conclusion that should be drawn from the exploratory causal analysis.  The ECA guess will often be undefined in situations where a majority of $g$-trits in $\vec{g}$ agree with each other.  For example, the transfer entropy, Granger causality, lagged cross-correlation, and PAI tools could all provide a causal inference of $\mathbf{Y}\rightarrow\mathbf{X}$ while the leaning fails to provide any causal inference because, e.g., the cause-effect assignment is inappropriate for the system being studied.  An undefined ECA guess does not immediately imply that the exploratory causal inference is inconclusive.  Rather, it only implies that each time series causality tool may need to be applied more carefully.  

The automated generation of ECA guesses for a set of time series may be appealing in the speed and ease with which a large number of causal inferences can be performed, but such automated procedures should not be considered a substitution for a more complete exploratory causal analysis.  The ECA guess is part of the exploratory causal analysis and, as discussed in Section \ref{sec:whatisECA}, no part of such analysis should be confused with causality as it is defined traditionally in fields such as physics and philosophy.

In all the examples presented in this work, $\vec{g}$ has five elements with $g_1$ as the causal inference implied by the JIDT transfer entropy, $g_2$ as the causal inference implied by the MVGC Granger causality log-likelihood test statistics, $g_3$ as the causal inference implied by the PAI differences, $g_4$ as the causal inference implied by the weighted mean observed leanings averaged over all the tested lags, and $g_5$ as the causal inference implied by the lagged cross-correlation differences averaged over all the tested lags.

\subsection{Synthetic data examples}
Synthetic data sets can be used to explore how the results of an exploratory causal analysis compare with the intuitive causal structure of the system.  Simple systems, with strongly intuitive causal structure, are useful in demonstrating the strengths and weakness of different approach to the analysis.  Example systems with less intuitive causal structure will also be used because of their relationship to physical systems, which allows outside theories to be used as confirmation of the exploratory causal analysis results. 


\subsubsection{Impulse with linear response}
\label{sec:IR}
Consider the linear example dynamical system of
\begin{eqnarray}
\label{eqn:IReqn}
\left\{\mathbf{X},\mathbf{Y}\right\} = \left\{\{x_t\},\{y_t\}\right\}
\end{eqnarray}
where $t=0,1,\ldots,L$,
\begin{equation*}
x_t = \left\{
  \begin{array}{lr}
    2 & t = 1\\
    A\eta_t & \forall\; t\in\{t\;|\;t\neq 1 \;\mathrm{and}\; t\bmod 5 \neq 0\}\\
    2 & \forall\; t\in\{t\;|\;t\bmod 5 = 0\}
  \end{array}
\right.
\end{equation*}
and
\begin{equation*}
y_t = x_{t-1} + B\eta_t
\end{equation*}
with $y_0 = 0$, $A,B\in\mathbb{R}\ge 0$ and $\eta_t\sim\mathcal{N}\left(0,1\right)$.  Specifically, consider $A\in[0,1]$ and $B\in[0,1]$.  The driving system $\mathbf{X}$ is a periodic impulse with a signal amplitude above the maximum noise level of both the driving and the response systems, and the response system $\mathbf{Y}$ is a lagged version of the driving signal with standard normal (i.e.,  $\mathcal{N}\left(0,1\right)$) noise of amplitude $B$ applied at each time step.  

Let the instance of Eqn.\ \ref{eqn:IReqn} with $L=500$, $A=0.1$, and $B=0.4$ shown in Figure \ref{fig:IRxyplot} be considered the synthetic data set $(\mathbf{X},\mathbf{Y})$ upon which the exploratory causal analysis will be performed.  A preliminary visual inspection of Figure \ref{fig:IRxyplot} shows $\mathbf{X}$ appears less noisy than $\mathbf{Y}$ (as expected), but perhaps more importantly, both times series appear to have two major groupings for their data, around 0 and 2 for $\mathbf{X}$ and $\mathbf{Y}$, albeit with a wider spread in $\mathbf{Y}$.  This observation is supported by the histograms of these data shown in Figure \ref{fig:IRxyhist}.  This data set is synthetic, so such observations may seem pointlessly obvious.  However, if the data were not synthetic, then these observations would be useful to setting the leaning tolerance domains, $\delta_x$ and $\delta_y$.  It has been shown that if $A$ and $B$ are known {\em a priori}, then the leaning will agree with intuition if $\delta_x=A$ and $\delta_Y=B$ \cite{Weigel2014}.  It is assumed here, however, that $A$ and $B$ are unknown to the analyst.  From Figure \ref{fig:IRxyhist}, initial tolerance domains of $\pm\delta_x = 0.5$ and $\pm\delta_y=1$ will be used for the leaning calculations.  

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyResponseExample_X.eps} & \includegraphics[scale=0.48]{NoisyResponseExample_Y.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{An instance of Eqn.\ \ref{eqn:IReqn} for $L=500$, $A=0.1$, and $B=0.4$.}
\label{fig:IRxyplot}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{NoisyResponseExample_Xhist.eps} & \includegraphics[scale=0.5]{NoisyResponseExample_Yhist.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Histograms of the instance of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot}.}
\label{fig:IRxyhist}
\end{figure}

Autocorrelations in the data are useful to understand for both potential cause-effect assignments for the leaning calculations and potential issues in drawing causal inferences from the lagged cross-correlations.  This data is synthetic, so it is known from Eqn.\ \ref{eqn:IReqn} that a reasonable cause-effect assignment for the leaning would be $\{C,E\}=\{x_{t-1},y_t\}$.  The goal here is to show how such potential cause-effect assignments can be drawn directly from the data.  Figure \ref{fig:IRxyautocorr} shows strong autocorrelations for both $\mathbf{X}$ and $\mathbf{Y}$ at $l=6,12,18,\ldots,48$.  The autocorrelations appear cyclic, which implies the leaning and lagged cross-correlation time series causality tools need not be calculated for more than $l=1,2,\ldots,6$, which is the lag after which the autocorrelations pattern seems to repeat. If $l>6$ in these calculations, then the causal inference may be strongly influenced by the autocorrelations in the data.  The similar autocorrelations pattern seen in Figure \ref{fig:IRxyautocorr} may imply a strong driving relationship within the time series pair (or perhaps a strong shared driving relationship with some outside driver) but do not immediately suggest a cause-effect assignment for the leaning calculation.  The most straightforward cause-effect assignment is the $l$-standard assignment, which will be used with $l = 1,2,\ldots,6$. 

The leaning calculations using the $l$-standard cause-effect assignment and tolerance domains suggested by Figures \ref{fig:IRxyautocorr} and \ref{fig:IRxyhist}, respectively, fit naturally on a plot with the lagged cross-correlations (because both depend on some lag $l$).  These values are shown in Figure \ref{fig:IRxyLandLCC} for $l=1,2,\ldots,6$.  This figure shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, suggest the same causal inference for almost every lag\footnote{$\langle \lambda_l\rangle > 0$ and $\Delta_l<0\Rightarrow\mathbf{X}\rightarrow\mathbf{Y}$ and {\em vice versa}.  See Sections \ref{sec:lean} and \ref{sec:lccPUSE} for more details.}.  The causal inferences for the leanings are $\mathbf{Y}\rightarrow\mathbf{X}$ for $l=2,\ldots,6$ and $\mathbf{X}\rightarrow\mathbf{Y}$ for $l=1$ with a maximum absolute value at $l=1$, which implies $\mathbf{X}\rightarrow\mathbf{Y}$, and a mean across all the lags, $\langle\langle\lambda_l\rangle\rangle_l=6.6\times 10^{-3}$, which also implies $\mathbf{X}\rightarrow\mathbf{Y}$.  The causal inferences for the lagged cross-correlation differences are $\mathbf{Y}\rightarrow\mathbf{X}$ for $l=2,3,5,6$ and $\mathbf{X}\rightarrow\mathbf{Y}$ for $l=1,4$ with a maximum absolute value at $l=1$, which implies $\mathbf{X}\rightarrow\mathbf{Y}$, and a mean across all the lags, $\langle\Delta_l\rangle_l=-2.8\times 10^{-3}$, which also implies $\mathbf{X}\rightarrow\mathbf{Y}$.  Both the mean across all lags and the maximum absolute value for both tools yields the same causal inference, and that causal inference agrees with intuition for this example.  However, the second largest value of both tools in Figure \ref{fig:IRxyLandLCC} suggests the opposite (counter-intuitive) causal inference.  
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyResponseExample_autocorrX.eps} & \includegraphics[scale=0.48]{NoisyResponseExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Autocorrelations of the instances of $\mathbf{X}$ and $\mathbf{Y}$ of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:IRxyautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{NoisyResponseExample_LandLCC.eps} 
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $\pm\delta_x = 0.5$ and $\pm\delta_y=1$) for the instances of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot} given lags of $l=1,2,\ldots,6$.}
\label{fig:IRxyLandLCC}
\end{figure}

These lags can be investigated further by examining the correlation plots, i.e., plots of $(y_{t-l},x_t)$ (Figure \ref{fig:lagplotsYX}) and $(x_{t-l},y_t)$ (Figure \ref{fig:lagplotsXY}) for $l=1,2,\ldots,6$.  These figures show the data clusters around 0 and 2, as expected from Figure \ref{fig:IRxyhist}.  A notable feature is the strong linear relationship seen in Figure \ref{fig:lagplotsXY}(a) and Figure \ref{fig:lagplotsYX}(e).  These are the relationships shown by the lagged cross-correlation differences (and the leaning) in Figure \ref{fig:IRxyLandLCC}.  These relationships are not unexpected given the structure of Eqn\ \ref{eqn:IReqn}.  The $(y_t,x_{t-1})$ relationship is the explicit part of the system that accounts for, in large part, the intuitive causal structure.  The $(x_t,y_{t-5})$ relationship is a by-product of the structured pulse pattern created for $\mathbf{X}$; i.e., if the pulses of $\mathbf{X}$ were set to occur at a different interval, then it is expected that this $(x_t,y_{t-l})$ relationship would appear for a lag $l$ corresponding to that different interval.  

The assumption, however, has been that the analyst doing the exploratory causal analysis of this synthetic data does not know Eqn.\ \ref{eqn:IReqn} {\em a priori}.  The question is what causal inference should such an analyst make for this example?  It has already been shown that the causal inference would be $\mathbf{X}\rightarrow\mathbf{Y}$ (which agrees with intuition) if the analyst were to use the average across all the calculated lags for either the leaning or the lagged cross-correlation difference, but the strong counter inferences provided by $l=1$ and $l=5$ may be seen as a concern that needs to be investigated further.  The most desirable path forward may be to change the impulse pattern of $\mathbf{X}$ and see if the leaning and lagged cross-correlation differences change for either $l=1$ or $l=5$.  As explained in the previous paragraph, it is expected that doing so would change the result for $l=5$ but may create a similar result for a different lag, while the $l=1$ is expected to remain unchanged.  This type of experimental result may be seen as strong evidence that the $l=1$ results are the more correct causal inferences for this example system, but such experiments may not be possible.  The analyst may only have access to the single instances of $\mathbf{X}$ and $\mathbf{Y}$ shown in Figure \ref{fig:IRxyplot}.  Another possible approach is to calculate the leaning using other tolerance domains.
\begin{figure}[ht]
\begin{tabular}{ccc}
\includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl1.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl2.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl3.eps} \\
(a) $l = 1$ & (b) $l = 2$ & (c) $l = 3$ \\
\includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl4.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl5.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotXYl6.eps} \\
(d) $l = 4$ & (e) $l = 5$ & (f) $l = 6$
\end{tabular}
\caption{Lagged cross-correlation plots, $(x_{t-l},y_t)$, for the instance of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot} given lags of $l=1,2,\ldots,6$.}
\label{fig:lagplotsXY}
\end{figure}
\begin{figure}[ht]
\begin{tabular}{ccc}
\includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl1.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl2.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl3.eps} \\
(a) $l = 1$ & (b) $l = 2$ & (c) $l = 3$ \\
\includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl4.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl5.eps} & \includegraphics[scale=0.55]{NoisyResponseExample_lagplotYXl6.eps} \\
(d) $l = 4$ & (e) $l = 5$ & (f) $l = 6$
\end{tabular}
\caption{Lagged cross-correlation plots, $(y_{t-l},x_t)$, for the instance of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot} given lags of $l=1,2,\ldots,6$.}
\label{fig:lagplotsYX}
\end{figure}

Consider the tolerance domains used in Figure \ref{fig:IRxyLandLCC}, $\pm\delta_x = 0.5$ and $\pm\delta_y=1$.  These domains were found by visual inspection of Figures \ref{fig:IRxyplot} and \ref{fig:IRxyhist}.  A more computational approach is to set the tolerance domains as $\pm\delta_x=f(\max(\mathbf{X})-\min(\mathbf{X}))$ and $\pm\delta_y=f(\max(\mathbf{Y})-\min(\mathbf{Y}))$ with $f=1/4$ (see \cite{Weigel2014} for other examples of setting tolerances domains).  This method for setting the tolerance domains will be used often, so for brevity, it will be referred to as the {\em f-width} tolerance domains; i.e., this example uses the $(1/4)$-width tolerance domains.  Figure \ref{fig:IRxyLtoldomains} shows the leaning calculations using the $l$-standard assignment for $l=1$ and $l=5$ for different reasonable\footnote{``Reasonable'' is defined in reference to Figure \ref{fig:IRxyhist}.  For example, $\pm\delta_x=2$ would lead to undefined leanings as the domain would be large enough to include all possible values of $x_t$ and $\pm\delta_x=1.5$ appears equivalent to $\pm\delta_x=1.0$, so both such tolerance domains are considered ``unreasonable''.} tolerance domains of $\pm\delta_x\in[0,1]$ and $\pm\delta_y\in[0,1]$ in steps of 0.05.  This figure shows the causal inferences implied for $l=1$ and $l=5$ in Figure \ref{fig:IRxyLandLCC} are consistently implied by the leaning calculations using different tolerance domains.  Figure \ref{fig:IRxyLtoldomains} shows the leaning calculation changes sign for small tolerance domains, as expected
\footnote{See Section \ref{sec:lean}.}, but is consistently either positive (for $l=1$) or negative (for $l=5$) as the tolerance domain increases.  This behavior implies the signs of original leaning calculations were not attributable to the specific tolerance domains used in those calculations.  At this point, causal inference for this system might be better approached by comparing the leaning and lagged cross-correlation differences to other times series causality tools.
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.70]{NoisyResponseExample_leandifftoll1.eps} & \includegraphics[scale=0.70]{NoisyResponseExample_leandifftoll5.eps} \\
(a) $l=1$ & (b) $l=5$
\end{tabular}
\caption{Leaning calculations for the instance of Eqn.\ \ref{eqn:IReqn} shown in Figure \ref{fig:IRxyplot} using the $l$-standard assignment for $l=1$ and $l=5$ and tolerance domains defined as $\pm\delta_x\in[0,1]$ and $\pm\delta_y\in[0,1]$ in steps of 0.05.}
\label{fig:IRxyLtoldomains}
\end{figure}

For this example, the MVGC toolbox returns Granger causality log-likelihood statistics of $F_{Y\rightarrow X}=4.1\times 10^{-3}$ and $F_{X\rightarrow Y}=4.5\times 10^{-1}$, or $F_{X\rightarrow Y}-F_{Y\rightarrow X}\approx4.5\times 10^{-1}$.  The JIDT transfer entropy calculation returns $T_{X\rightarrow Y}=6.0\times 10^{-1}$ and $T_{Y\rightarrow X}=6.9\times 10^{-2}$, or $T_{X\rightarrow Y}-T_{Y\rightarrow X}=5.3\times 10^{-1}$.  Both of these results imply $\mathbf{X}\rightarrow\mathbf{Y}$, which agrees with intuition.  The PAI correlation difference is $-8.3\times 10^{-3}$, which also implies $\mathbf{X}\rightarrow\mathbf{Y}$.  If the leaning and lagged cross-correlation difference contributions to the ECA guess vector are defined as the mean across all the tested lags, then the ECA guess for this example is $|\vec{g}|^2=0\Rightarrow \mathbf{X}\rightarrow\mathbf{Y}$, which, again, is the intuitively correct answer.  

Figure \ref{fig:IRxyECAguess} shows the ECA guess for different instances of Eqn.\ \ref{eqn:IReqn} evaluated with $A\in[0,1]$ and $B\in[0,1]$ in steps on 0.05 and $L=500$.  The  leaning and lagged cross-correlation difference causal inferences were made with the average across all the tested lags, and the leaning calculations use the $l$-standard cause-effect assignment with $l=1,2,\ldots,6$ (which are the same lags used by the lagged cross-correlation differences).  The tolerance domains are calculated as $\pm\delta_x=f(\max(\mathbf{X})-\min(\mathbf{X}))$ and $\pm\delta_y=f(\max(\mathbf{Y})-\min(\mathbf{Y}))$ with $f=1/4$.  The maximum value of $|g|^2$ shown in Figure \ref{fig:IRxyECAguess} is 1 which implies that the ECA guess never implies the counter-intuitive causal inference of $\mathbf{Y}\rightarrow\mathbf{X}$ for this example.  The majority of the elements of $\vec{g}$, i.e., $g_1$ (transfer entropy), $g_2$ (Granger), and $g_4$ (leaning), imply the intuitive causal inference of $\mathbf{X}\rightarrow\mathbf{Y}$ for almost every point\footnote{The causal inference for $g_2$  failed to be defined for approximately 20 points in Figure \ref{fig:IRxyECAguess} because the MVGC toolbox failed to successfully fit a VAR model with the desired maximum model orders for some of the points with low noise in the impulse signal, e.g., $A=0.05$.  Every defined $g_2$, however, agreed with intuition, i.e., $g_2=0$.  Every calculated $g_1$ and $g_4$ agreed with intuition.} calculated in Figure \ref{fig:IRxyECAguess}.  Counter-intuitive inferences are implied by $g_3$ (PAI) as $A$ increases when $B$ is relatively small (i.e., as the noise level in the impulse signal increases above the noise level in the response signal), and they are implied by $g_5$ (lagged cross-correlation) as $B$ increases when $A$ is relatively small (i.e., as the noise level in the response signal increases above the noise level in the impulse signal).  Interestingly, both $g_3$ and $g_5$ imply the intuitive causal inference if $A\approx B$ for this example.  
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.8]{NoisyResponseExample_ECAguessMat.eps} 
\end{center}
\caption{ECA guesses for different instances of Eqn.\ \ref{eqn:IReqn} evaluated with $A\in[0,1]$ and $B\in[0,1]$ in steps on 0.05 and $L=500$ with $l$-standard assignment leaning calculations and lagged cross-correlation differences given $l=1,2,\ldots,6$ and leaning tolerance domains calculated as $\pm\delta_x=f(\max(\mathbf{X})-\min(\mathbf{X}))$ and $\pm\delta_y=f(\max(\mathbf{Y})-\min(\mathbf{Y}))$ with $f=1/4$.  The black indicates $|g|^2=0\Rightarrow\mathbf{X}\rightarrow\mathbf{Y}$, as expected, and the white indicates $|g|^2 \neq 0$.}
\label{fig:IRxyECAguess}
\end{figure}

A more rigorous exploratory causal analysis of this example might investigate further those points in Figure \ref{fig:IRxyECAguess} for which the ECA guess does not agree with intuition.  It may be possible to change the PAI and lagged cross-correlation difference calculations, e.g., by using different embedding dimensions $E$ and/or delay time steps $\tau$ in the PAI calculations or by pre-treating the data in the lagged cross-correlation difference calculations.  If, and how, such changes to the calculations change the causal inferences may provide insight into the relationship between the data sets.  Such effort may seem inconsequential or trivial on a synthetic data set, but if an analyst has very little knowledge of the system dynamics that generated a given time series pair, then anything that may be drawn from exploratory causal analysis may be considered helpful.  

\subsubsection{Cyclic driving with linear response}
\label{sec:Cyc}
Consider the linear example dynamical system of
\begin{eqnarray}
\label{eqn:cyceqn}
\left\{\mathbf{X},\mathbf{Y}\right\} = \left\{\{x_t\},\{y_t\}\right\}
\end{eqnarray}
where $t=0,1,\ldots,L$,
\begin{equation*}
x_t = a\sin(bt+c)+A\eta_t
\end{equation*}
and
\begin{equation*}
y_t = x_{t-1} + B\eta_t
\end{equation*}
with $y_0 = 0$, $A\in[0,1]$, $B\in[0,1]$, $\eta_t\sim\mathcal{N}\left(0,1\right)$, and with the amplitude $a$, the frequency $b$, and the phase $c$ all in the appropriate units.  This example is very similar to the previous one, except that the driving system $\mathbf{X}$ is sinusoidal.

Let the instance of Eqn.\ \ref{eqn:cyceqn} with $L=500$, $A=0.1$, $B=0.4$, $a=b=1$, and $c=0$ shown in Figure \ref{fig:cycxyplot} be considered the synthetic data set $(\mathbf{X},\mathbf{Y})$ for the exploratory causal analysis.  The histograms of these data shown in Figure \ref{fig:cycxyhist}.  These data have a wider spread than the data seen in Figure \ref{fig:IRxyplot}, and do not appear to be clustered about some small set of points.  This observation is supported by Figure \ref{fig:cycxyhist}.  The tolerance domains might be set by visual inspection of the histograms, as was done in Section \ref{sec:IR}, but for this example, the leaning calculation will use the $(1/4)$-width tolerance domains.
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{NoisyCyclicResponseExample_X.eps} & \includegraphics[scale=0.5]{NoisyCyclicResponseExample_Y.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{An instance of Eqn.\ \ref{eqn:cyceqn} for $L=500$, $A=0.1$, and $B=0.4$.}
\label{fig:cycxyplot}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{NoisyCyclicResponseExample_Xhist.eps} & \includegraphics[scale=0.5]{NoisyCyclicResponseExample_Yhist.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Histograms of the instance of Eqn.\ \ref{eqn:cyceqn} shown in Figure \ref{fig:cycxyplot}.}
\label{fig:cycxyhist}
\end{figure}

Figure \ref{fig:cycxyautocorr} shows strong autocorrelations for both $\mathbf{X}$ and $\mathbf{Y}$, and the autocorrelations appear cyclic.  So, the leaning and lagged cross-correlation time series causality tools will not be calculated for more than $l=1,2,\ldots,20$, which is the lag after which the autocorrelations pattern seems to repeat.  The most straightforward cause-effect assignment is the $l$-standard assignment, which will be used with $l = 1,2,\ldots,20$. 

The leaning and lagged cross-correlation differences are shown in Figure \ref{fig:cycxyLandLCC} for $l=1,2,\ldots,20$.  This figure shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, seem to suggest different causal inferences for almost every third lag.  The causal inference for both tools at $l=1$ is the same, intuitively correct, inference of $\mathbf{X}\rightarrow\mathbf{Y}$, and the mean across all the lags is $\langle\langle\lambda_l\rangle\rangle_l=3.9\times 10^{-3}$ and $\langle\Delta_l\rangle_l=-2.9\times 10^{-2}$, which also imply $\mathbf{X}\rightarrow\mathbf{Y}$.  
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyCyclicResponseExample_autocorrX.eps} & \includegraphics[scale=0.48]{NoisyCyclicResponseExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Autocorrelations of the instances of $\mathbf{X}$ and $\mathbf{Y}$ of Eqn.\ \ref{eqn:cyceqn} shown in Figure \ref{fig:cycxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:cycxyautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{NoisyCyclicResponseExample_LandLCC.eps} 
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $(1/4)$-width tolerance domains) for the instances of Eqn.\ \ref{eqn:cyceqn} shown in Figure \ref{fig:cycxyplot} given lags of $l=1,2,\ldots,20$.}
\label{fig:cycxyLandLCC}
\end{figure}

For this example, the MVGC toolbox returns Granger causality log-likelihood statistics of $F_{Y\rightarrow X}=2.8\times 10^{-2}$ and $F_{X\rightarrow Y}=2.4\times 10^{-1}$, or $F_{X\rightarrow Y}-F_{Y\rightarrow X}=2.1\times 10^{-1}$.  The JIDT transfer entropy calculation returns $T_{X\rightarrow Y}=7.6\times 10^{-1}$ and $T_{Y\rightarrow X}=5.7\times 10^{-1}$, or $T_{X\rightarrow Y}-T_{Y\rightarrow X}=1.9\times 10^{-1}$.  The PAI correlation difference is $-9.8\times 10^{-3}$, which also implies $\mathbf{X}\rightarrow\mathbf{Y}$.  If the leaning and lagged cross-correlation difference contributions to the ECA guess vector are defined as the mean across all the tested lags, then the ECA guess for this example is $|\vec{g}|^2=0\Rightarrow \mathbf{X}\rightarrow\mathbf{Y}$.  All of these results imply $\mathbf{X}\rightarrow\mathbf{Y}$, which agrees with intuition.    

Figure \ref{fig:cycxyECAguess} shows the ECA guess for different instances of Eqn.\ \ref{eqn:cyceqn} evaluated with $A\in[0,1]$ and $B\in[0,1]$ in steps on 0.05 and $L=250$.  The  leaning and lagged cross-correlation difference causal inferences were made with the average across all the tested lags, and the leaning calculations use the $l$-standard cause-effect assignment with $l=1,2,\ldots,20$ (which are the same lags used by the lagged cross-correlation differences).  The tolerance domains calculated as the $(1/4)$-width domains.  The maximum value of $|g|^2$ shown in Figure \ref{fig:cycxyECAguess} is 1, not 5, which implies that the ECA guess never implies the counter-intuitive causal inference of $\mathbf{Y}\rightarrow\mathbf{X}$ for this example.  However, a visual comparison of Figures \ref{fig:IRxyECAguess} and \ref{fig:cycxyECAguess} shows the ECA guess agrees with intuition less reliably for this example than for the example of Section \ref{sec:IR}.  The majority of the elements of $\vec{g}$, i.e., $g_1$ (transfer entropy), $g_2$ (Granger), and $g_5$ (lagged cross-correlation), imply the intuitive causal inference of $\mathbf{X}\rightarrow\mathbf{Y}$ for almost every point\footnote{As with the example in Section \ref{sec:IR}, the MVGC toolbox failed to successfully fit a VAR model with the desired maximum model orders for some of the points with low noise in the impulse signal (three points were undefined).  Again, every defined $g_2$ agreed with intuition, i.e., $g_2=0$.  Every calculated $g_1$ and $g_5$ agreed with intuition.} calculated in Figure \ref{fig:cycxyECAguess}.  The ECA guess failed to agree with intuition in this example for all the tested time series pairs because of counter-intuitive inferences implied by $g_3$ (PAI) and $g_4$ (leaning), which differs from the example shown in Section \ref{sec:IR} where $g_4$ implied the intuitive causal inference for every tested time series pair.  This observation helps illustrate the need for multiple types of tools in an exploratory causal analysis; the naive application of some tools may be better suited to a given system than others, and the use of different tools together can help guide the analyst in how to apply the time series causality tools differently (e.g., by changing the cause-effect assignment of the leaning or the model parameters of the Granger test statistic) for different systems. The inference implied by $g_3$ (PAI) is counter-intuitive as $A$ increases, which is similar to the behavior seen for this tool in Section \ref{sec:IR}.  The inference implied by $g_4$ (leaning) is counter-intuitive as $B$ increases, which is in contrast to the behavior of $g_3$ (PAI) and implies the ECA guess may agree with intuition for most of the test times series pairs if either $g_4$ or $g_3$ were removed from $\vec{g}$.    
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.8]{NoisyCyclicResponseExample_ECAguessMat.eps} 
\end{center}
\caption{ECA guesses for different instances of Eqn.\ \ref{eqn:cyceqn} evaluated with $A\in[0,1]$ and $B\in[0,1]$ in steps on 0.05 and $L=250$ with $l$-standard assignment leaning calculations and lagged cross-correlation differences given $l=1,2,\ldots,20$ and $(1/4)$-width tolerance domains.  The black indicates $|g|^2=0\Rightarrow\mathbf{X}\rightarrow\mathbf{Y}$, as expected, and the white indicates $|g|^2 \neq 0$.}
\label{fig:cycxyECAguess}
\end{figure}
As with the example in Section \ref{sec:IR}, a more rigorous exploratory causal analysis of this example might investigate further those points in Figure \ref{fig:cycxyECAguess} for which the ECA guess does not agree with intuition.  It may be possible to change the PAI and weighted mean observed leaning calculations, e.g., by using different embedding dimensions $E$ and/or delay time steps $\tau$ in the PAI calculations or tolerance domains in the leaning calculations.  

\subsubsection{RL series circuit}
\label{sec:rlcirc}
Consider a series circuit containing a resistor, inductor, and time varying voltage source related by
\begin{equation}
\label{eqn:it}
\frac{dI}{dt} = \frac{V(t)}{L} - \frac{R}{L} I(t),
\end{equation}
where $I(t)$ is the current at time $t$, $V(t)= \sin\left(t\right)$ is the voltage at time $t$, $R$ is the resistance, and $L$ is the inductance.  The time series pair for this example is then 
\begin{eqnarray}
\label{eqn:RLcirceqn}
\left\{\mathbf{V},\mathbf{I}\right\} = \left\{\{V_t\},\{I_t\}\right\}
\end{eqnarray}
where $\mathbf{V}$ is the set of discrete values of $V(t)$ evaluated using $t=0,f\pi,2f\pi,3f\pi,\ldots,8\pi$ with $f=1/10$ and $\mathbf{I}$ is the set of discrete values found either by solving Eqn.\ \ref{eqn:it} numerically or by evaluating the analytical solution 
\begin{equation}
I(t) = \frac{1}{D}\left(Le^{-\frac{t}{\tau}}+R\sin(t)-L\cos(t)\right)
\end{equation}
with $D = L^2 + R^2$ and $\tau = L/R$, for the same time set used for $\mathbf{V}$.

Physical intuition is that $V$ drives $I$, and so we expect to find that $\mathbf{V}\rightarrow\mathbf{I}$.  These dynamics are well-known and have been thoroughly explored experimentally \cite{Halliday2010,Knight2012}.  As such, this example presents a slightly different test of the efficacy of the exploratory causal analysis than the last two examples.  Previously, the intuitive causal inference relied on intuition about the mathematical form of the dynamics used to create the synthetic data.  Here, the intuitive causal inference may be considered physical intuition and empirical experience, rather than any specific form or structure of Eqn.\ \ref{eqn:it}.    

Figure \ref{fig:VIplot} shows $\mathbf{V}$ and $\mathbf{I}$ generated with both the analytical solution and a numerical solution to Eqn. \ref{eqn:it} using the {\em ode45} integration function in {\sc MATLAB }.  The time series $\mathbf{V}$ is created by defining values at fixed points and using linear interpolation to find the time steps required by the ODE solver.  Two different physical scenarios are considered in which $L$ and $R$ are constant, $L=10$ H and $R=5$ $\Omega$ and $L=5$ H and $R=20$ $\Omega$.  Figure \ref{fig:VIplot} shows the numerical and analytical solutions are very similar, but the causal inferences will be made using both for completeness.  Figure \ref{fig:VIhist} shows the 25 bin histograms for these signals. 
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_Y.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_Y.eps} \\
(a) $\mathbf{I}$ ($L=10$ H and $R=5$ $\Omega$) & (b) $\mathbf{I}$ ($L=5$ H and $R=20$ $\Omega$)\\
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_X.eps} \\
(c) $\mathbf{V}$
\end{tabular}
\end{center}
\caption{The voltage and current signals of a circuit containing a resistor $R$ and inductor $L$ in series where the driving voltage is $V(t)=\sin(t)$ and the current response is given by the solution to Eqn.\ \ref{eqn:it}.  Eqn.\ \ref{eqn:it} is solved both numerically (represented by the open dots in (a) and (b)) and analytically (represented by the solid dots in (a) and (b)).  The signals are plotted for a sampling length of $8\pi$ seconds at a sampling interval of $10^{-1}\pi$ (or a sampling frequency of approximately 3 Hz), which corresponds to a time series length of 81 data points.}
\label{fig:VIplot}
\end{figure}
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_Yhist_an.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_Yhist_num.eps} \\
(a) $\mathbf{I}$ ($L=10$ H and $R=5$ $\Omega$, analytical solution) & (b) $\mathbf{I}$ ($L=10$ H and $R=5$ $\Omega$, numerical solution)\\
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_Yhist_an.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_Yhist_num.eps} \\
(c) $\mathbf{I}$ ($L=5$ H and $R=20$ $\Omega$, analytical solution) & (d) $\mathbf{I}$ ($L=5$ H and $R=20$ $\Omega$, numerical solution)\\
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_Xhist.eps} \\
(c) $\mathbf{V}$
\end{tabular}
\end{center}
\caption{The 25 bin histograms of the signals shown in Figure \ref{fig:VIplot}.}
\label{fig:VIhist}
\end{figure}

Figure \ref{fig:VIautocorr} shows, as expected, strong cyclic autocorrelations for both $\mathbf{V}$ and $\mathbf{I}$.  The leaning and lagged cross-correlation differences are shown in Figure \ref{fig:VILandLCC} for $l=1,2,\ldots,5$.  This figure shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, imply the intuitive causal inferences, i.e., $\mathbf{V}\rightarrow\mathbf{I}$, for every calculated lag.  The mean across all the lags is $\langle\langle\lambda_l\rangle\rangle_l=3.9\times 10^{-1}$ and $\langle\Delta_l\rangle_l=-4.7\times 10^{-1}$, for both the numerical and analytical solutions, given $L=10$ H and $R=5$ $\Omega$, and $\langle\langle\lambda_l\rangle\rangle_l=2.2\times 10^{-1}$ and $\langle\Delta_l\rangle_l=-2.6\times 10^{-1}$, for both the numerical and analytical solutions, given $L=5$ H and $R=20$ $\Omega$.  These values all imply $\mathbf{V}\rightarrow\mathbf{I}$.  
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_autocorrY.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_autocorrY.eps} \\
(a) $\mathbf{I}$ ($L=10$ H and $R=5$ $\Omega$) & (b) $\mathbf{I}$ ($L=5$ H and $R=20$ $\Omega$)\\
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_autocorrX.eps} \\
(c) $\mathbf{V}$
\end{tabular}
\end{center}
\caption{Autocorrelations of the signals shown in Figure \ref{fig:VIplot}.  The numerical solution for $\mathbf{I}$ is represented by the open dots in (a) and (b) and the analytical solution is represented by the solid dots in (a) and (b).}
\label{fig:VIautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_LandLCC_an.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL10R5_LandLCC_num.eps} \\
(a) $L=10$ H and $R=5$ $\Omega$ (analytical solution) & (b) $L=10$ H and $R=5$ $\Omega$ (numerical solution)\\
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_LandLCC_an.eps} &
\includegraphics[scale=0.48]{IRCircuitResponseExampleL5R20_LandLCC_num.eps} \\
(a) $L=5$ H and $R=20$ $\Omega$ (analytical solution) & (b) $L=5$ H and $R=20$ $\Omega$ (numerical solution)
\end{tabular}
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $(1/4)$-width tolerance domains) for the signals shown in Figure \ref{fig:VIplot} given lags of $l=1,2,\ldots,5$.}
\label{fig:VILandLCC}
\end{figure}

The JIDT transfer entropy calculation returns $T_{V\rightarrow I}=4.8\times 10^{-1}$ and $T_{I\rightarrow V}=4.6\times 10^{-1}$, or $T_{V\rightarrow I}-T_{I\rightarrow V}=1.7\times 10^{-2}$ given $L=10$ H and $R=5$ $\Omega$, and $T_{V\rightarrow I}=3.5\times 10^{-1}$ and $T_{I\rightarrow V}=5.0\times 10^{-2}$, or $T_{V\rightarrow I}-T_{I\rightarrow V}=3.0\times 10^{-1}$ given $L=5$ H and $R=20$ $\Omega$.  These values imply the intuitively correct causal inference, $\mathbf{V}\rightarrow\mathbf{I}$.  The leaning and lagged cross-correlation difference contributions also imply the intuitive causal inference.  The ECA guess for this example, however, is undefined for both physical scenarios because neither $g_2$ (Granger) nor $g_3$ (PAI) are defined.  The PAI difference is undefined for these examples because the algorithm used to calculate the PAI correlations fails if two points in the shadow manifold have a separation distance of zero\footnote{This scenario leads to a division by zero.  See step 2 and 3 of the algorithm outlined in Section \ref{sec:SSRC}.  The implementation of the PAI algorithm used in this work declares the correlations undefined in such scenarios.}  Likewise, the MVGC toolbox algorithms fail to return defined log-likelihood statistics for this example.  These issues may be seen as technical issues regarding the different implementation algorithms or fundamental issues regarding the use of these techniques with ``perfect'' signals (such as $\mathbf{V}$ in this example).  The use of multiple times series causality tools for the exploratory analysis, as has been done in this example, helps the analyst to understand the undefined results do not necessarily imply a lack of possible causal inferences.  

This example can also illustrate the importance of sample frequency and sample length.  For example, the leaning calculation requires an assumed cause and effect pair to appear in the data enough times to provide reliable estimates of probabilities.  Thus, data that is sampled for too few periods or too sparsely may lead to leanings that do not agree with intuition.  Consider the signals shown in Figure \ref{fig:VIplot} with $L=10$ H and $R=5$ $\Omega$ sampled at the time steps $t=0,f\pi,2f\pi,3f\pi,\ldots,8\pi$ for $f = 80^{-1},60^{-1},40^{-1},20^{-1},10^{-1}$ and $5^{-1}$.  The tolerance domains for the leaning calculation will be set as the $(1/4)$-width domains, and the number of lags to average over for the ECA guess using the leaning and lagged cross-correlation difference will be set as $l=1,\ldots,l_a$, where $l_a$ is the lag for which the autocorrelation of the voltage signal is minimum in a set of autocorrelations calculated with lags from 1 to half the length of $\mathbf{V}$.  This method is not equivalent to the method used to produce Figure \ref{fig:VILandLCC} (which relied on a visual inspection of Figure \ref{fig:VIautocorr}), but it is easier to implement computationally and for $f=10^{-1}$ it provides leaning and lagged cross-correlation difference calculations that imply the same causal inference as Figure \ref{fig:VILandLCC}. Table \ref{tab:samp} shows the variation of $\vec{g}$ as $f$ changes.  The ECA guess is undefined at each sampling frequency but $g_3$ (PAI) begins to imply the intuitive causal inference as $f$ in increases. Nothing about the signals has physically changed but the times series data (upon which the causal inference is drawn) has changed because of the changing sampling procedure.  
\begin{table}
\begin{center}
\begin{tabular}{ccc}
$f$ & $\vec{g}$  & ECA guess\\
\midrule
$80^{-1}$ & $(0,2,2,0,0)$ & undefined\\
$60^{-1}$ & $(0,2,2,0,0)$ & undefined\\
$40^{-1}$ & $(0,2,2,0,0)$ & undefined\\
$20^{-1}$ & $(0,2,2,0,0)$ & undefined\\
$10^{-1}$ & $(0,2,2,0,0)$ & undefined\\
$5^{-1}$ & $(0,2,0,0,0)$ & undefined\\
\end{tabular}
\caption{The ECA guess and vector, $\vec{g}$, for the signals shown in Figure \ref{fig:VIplot} with $L=10$ H and $R=5$ $\Omega$ sampled at the time steps $t=0,f\pi,2f\pi,3f\pi,\ldots,8\pi$.}
\label{tab:samp}
\end{center}
\end{table}

\subsubsection{Cyclic driving with non-linear response}
\label{sec:nonli}
Consider the nonlinear dynamical system of
\begin{eqnarray}
\label{eqn:nonlinearEX}
\left\{\mathbf{X},\mathbf{Y}\right\} = \left\{\{x_t\},\{y_t\}\right\}
\end{eqnarray}
where $t=0,1,\ldots,L$,
\begin{equation*}
x_t = a\sin(bt+c)+A\eta_t
\end{equation*}
and
\begin{equation*}
y_t = Bx_{t-1}\left(1-Cx_{t-1}\right)+D\eta_t,
\end{equation*}
with $y_0 = 0$, with $A,B,C,D\in[0,1]$, $\eta_t\sim\mathcal{N}\left(0,1\right)$, and with the amplitude $a$, the frequency $b$, and the phase $c$ all in the appropriate units given $t=0,f\pi,2f\pi,3f\pi,\ldots,6\pi$ with $f=1/30$, which implies $L=181$.

Let the instance of Eqn.\ \ref{eqn:nonlinearEX} with $A=0.1$, $B=0.3$, $C=0.4$, $D=0.5$, $a=b=1$, and $c=0$ shown in Figure \ref{fig:nonxyplot} be the time series pair $(\mathbf{X},\mathbf{Y})$ for the exploratory causal analysis.  The tolerance domains for the leaning calculation are set as the $(1/4)$-width tolerance domains.
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{NonlinearResponseExample_X.eps} & \includegraphics[scale=0.5]{NonlinearResponseExample_Y.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{An instance of Eqn.\ \ref{eqn:nonlinearEX} for $A=0.1$, $B=0.3$, $C=0.4$, $D=0.5$, $a=b=1$, and $c=0$.}
\label{fig:nonxyplot}
\end{figure}

Figure \ref{fig:nonxyautocorr} shows strong cyclic autocorrelations for $\mathbf{X}$.  The autocorrelations of $\mathbf{Y}$ are apparently acyclic, which might make it difficult to set the number of leaning and lagged cross-correlation difference lags to calculate based on $\mathbf{Y}$ in Figure \ref{fig:nonxyautocorr}.  The leaning (using the $l$-standard assignment) and lagged cross-correlation time series causality tools will not be calculated for more than $l=1,2,\ldots,15$, which is the lag after which the autocorrelations pattern seems to repeat for $\mathbf{X}$.  

The leaning and lagged cross-correlation differences are shown in Figure \ref{fig:nonxyLandLCC} for $l=1,2,\ldots,20$.  This figure shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, seem to suggest the intuitive causal inference, $\mathbf{X}\rightarrow\mathbf{Y}$, for the majority of the calculated lags.  The mean across all the lags is $\langle\langle\lambda_l\rangle\rangle_l=8.4\times 10^{-3}$ and $\langle\Delta_l\rangle_l=-6.8\times 10^{-2}$, which both imply $\mathbf{X}\rightarrow\mathbf{Y}$.  
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NonlinearResponseExample_autocorrX.eps} & \includegraphics[scale=0.48]{NonlinearResponseExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Autocorrelations of the instances of $\mathbf{X}$ and $\mathbf{Y}$ of Eqn.\ \ref{eqn:nonlinearEX} shown in Figure \ref{fig:nonxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:nonxyautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{NonlinearResponseExample_LandLCC.eps} 
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $(1/4)$-width tolerance domains) for the instances of Eqn.\ \ref{eqn:nonlinearEX} shown in Figure \ref{fig:nonxyplot} given lags of $l=1,2,\ldots,15$.}
\label{fig:nonxyLandLCC}
\end{figure}

For this example, the MVGC toolbox returns Granger causality log-likelihood statistics of $F_{X\rightarrow Y}-F_{Y\rightarrow X}=2.6\times 10^{-1}$.  The JIDT transfer entropy calculation returns $T_{X\rightarrow Y}-T_{Y\rightarrow X}=2.7\times 10^{-1}$.  The PAI correlation difference is $-1.8\times 10^{-3}$, which also implies $\mathbf{X}\rightarrow\mathbf{Y}$.  If the leaning and lagged cross-correlation difference contributions to the ECA guess vector are defined as the mean across all the tested lags, then the ECA guess for this example is $|\vec{g}|^2=0\Rightarrow \mathbf{X}\rightarrow\mathbf{Y}$.  All of these results imply $\mathbf{X}\rightarrow\mathbf{Y}$, which agrees with intuition.    

A natural question is whether the data series shown in Figure \ref{fig:nonxyplot} is a unique instance of Eqn.\ \ref{eqn:nonlinearEX}.  The synthetic data examples have, so far, interpreted the instances of Eqn.\ \ref{eqn:IReqn}, \ref{eqn:cyceqn}, and \ref{eqn:nonlinearEX} being explored as the only collection of data points potentially collected by an analyst.  However, the stochastic noise present in each of these examples raises the question of whether or not the ECA guesses for these examples would have agreed with intuition for a different instance of these systems; i.e., for instances of Eqn.\ \ref{eqn:IReqn}, \ref{eqn:cyceqn}, and \ref{eqn:nonlinearEX} with the same coefficients as those used to create Figures \ref{fig:IRxyplot}, \ref{fig:cycxyplot}, and \ref{fig:nonxyplot} but different realizations of the stochastic noise terms $\eta_t$.  In many physical systems, an analyst may be able to measure several instances of $\mathbf{X}$ and $\mathbf{Y}$.  Exploratory causal analysis may be performed on the collection of times series pairs.  For example, given $m$ sets of the pair $(\mathbf{X},\mathbf{Y})$, then an analyst may combine the time series in some way (e.g., $\bar{\mathbf{X}}=\{\bar{x}_t=m^{-1}\sum^m_i x_{t,i}\;\forall t=1,2,\ldots,L\}$ where $\mathbf{X}_i = \{x_{t,i}\}$ is the $i$th measured instance of $\mathbf{X}$, which contains $L$ data points) and form an ECA guess used the combined data series, or an analyst may calculate $m$ ECA guesses which may then be used for causal inference.  

Consider $10^4$ instances of Eqn.\ \ref{eqn:nonlinearEX} with the coefficients shown in Figure \ref{fig:nonxyplot}.  Table \ref{tab:ECAdist} shows the ECA guess vector distribution for this collection of time series pairs.  The individual causal inferences $g_1$ (transfer entropy), $g_2$ (Granger)\footnote{It is interesting to note that the MVGC toolbox uses a linear VAR model fitting procedure that implies the intuitively correct causal inference for every instance of this nonlinear example.  This might be seen as evidence for using every available time series causality tool during exploratory causal inference, even those with well documented shortcomings.}, and $g_3$ (PAI) agree with intuition for every instance.  The two that imply counterintuitive causal inferences do so only for a minority of the tested instances, approximately 41\% of the instances for $g_4$ (leaning) and approximately 27\% of the instances for $g_5$ (lagged cross-correlation).  The leaning calculation uses $(1/4)$-width tolerance domains and both the leaning and the lagged cross-correlation differences are calculated as the mean of lags $l=1,2,\ldots,15$.  The average leaning, $\langle\langle\lambda_l\rangle\rangle$, across all $10^4$ instances is $\langle\langle\lambda_l\rangle\rangle = 4\times 10^{-3}$ and the average lagged cross-correlation difference, $\langle\Delta_l\rangle=-4.3\times 10^{-2}$, both of which imply the intuitive causal inference.  A bootstrapping \cite{Efron1994} procedure can be set up with the sample of leaning and lagged cross-correlation calculations, whereby $10^6$ means are calculated from new sets (of the same size as the original set) of leanings and lagged cross-correlations that have been sampled (with replacement) from the original set.  This procedure yields no negative means for the leaning calculation and no positive means for the lagged cross-correlation differences; the null hypothesis that the mean leaning value is negative (i.e., $\langle\langle\lambda_1^z\rangle\rangle < 0$) and the null hypothesis that the mean lagged cross-correlation difference is positive (i.e., $\langle\Delta_l\rangle > 0$) can be rejected with a $p$-value less than $10^{-6}$.  The $90\%$ confidence interval for the mean of the $10^6$ bootstrapped leaning calculation means is $[3.7\times 10^{-3},4.3\times 10^{-3}]$ and for the lagged cross-correlation means is $[-4.4\times 10^{-2},-4.1\times 10^{-2}]$.  These results imply the intuitively correct causal inference for both $g_4$ and $g_5$.
\begin{table}
\begin{center}
\begin{tabular}{ccc}
$\vec{g}$  & counts & ECA guess\\
\midrule
$(0,0,0,0,0)$ & 5707 & undefined\\
$(0,0,0,0,1)$ & 231 & undefined\\
$(0,0,0,1,0)$ & 1608 & undefined\\
$(0,0,0,1,1)$ & 2454 & undefined\\
\end{tabular}
\caption{The ECA guess distribution of $10^4$ instances of Eqn.\ \ref{eqn:nonlinearEX} with the coefficients shown in Figure \ref{fig:nonxyplot}.}
\label{tab:ECAdist}
\end{center}
\end{table}

It becomes more difficult to visualize the agreement between the ECA guess and intuition for different sets of system parameters as the parameter space becomes larger.  Eqn.\ \ref{eqn:nonlinearEX} has a 4-dimensional parameter space in which such agreement may be explored, $A$, $B$, $C$, and $D$ where $a$, $b$, and $c$ are held constant.  One option for visualization may be plotting points within the unit cube framed by $B$, $C$, and $D$ for a given $A$ where $|g|^2 = 0$.  Every point tested within the 4-dim parameter space for which the ECA guess agrees with intuition should appear in one of the units cubes.  The number of plots, however, becomes unwieldy if $A$ is sampled for more than a few points on the unit domain, and the reader would rely on counting the number of points on each plot and comparing it to the total number of tested points to determine how often the ECA guess failed to agree with intuition.  Rather than produce such a set of plots, the 4-dim parameter space will be sampled to provide descriptive statistics.  The four parameters were sampled in steps of 0.05 in the domains of $A\in[0.05,0.55]$ and $B,C,D\in[0.05,1.0]$ for a total of 88,000 instances of Eqn.\ \ref{eqn:nonlinearEX}.  The ECA guess agreed with intuition, i.e., $|\vec{g}|^2=0$, in 60,155 (68\%) of those instances.  Most of the time series causality tools that failed to imply the intuitive causal inference did so by implying the counter-intuitive causal inference, i.e., $g_i\neq 2$ for any $i\neq 2$ of any of the ECA guess vectors.  The only exception was $g_2$ (Granger) which failed to provide any causal inference if a VAR forecast model could not be fit to the data within the requested maximum model order by the MVGC toolbox.  The fewest counter-intuitive inferences were implied by $g_1$ (transfer entropy) with 381 or 0.43\% of the total number of tested instances.  The majority (327 or 86\%) of those 381 counter-intuitive implications occurred for instances with $C>0.5$ and/or $D>0.5$.  The majority (3,414 or 73\%) of the 4,686 (5.3\% of the total number of tested instances) counter-intuitive inferences implied by $g_3$ (PAI) occurred for instances with $B>0.5$ and/or $C>0.5$.  The highest number of counter-intuitive inferences were implied by $g_4$ (leaning) and $g_5$ (lagged cross-correlation) with 19,971 and 14,051, or 23\% and 16\% of the total number of instances, respectively.  The counter-intuitive inferences implied by both tools occurred mostly (65\% for $g_4$ and 68\% for $g_5$) for instances with $D>0.5$.  The number of lags used in the calculation of both the leaning and the lagged cross-correlation difference was fixed (with $l=1,2,\ldots,15$) for each tested instance of Eqn.\ \ref{eqn:nonlinearEX}.  More intuitive causal inferences may have been implied by $g_4$ and $g_5$ if the number of lags used in those calculations was algorithmically set, e.g., with autocorrelation lengths as was discussed in Section \ref{sec:rlcirc}.  The $(1/4)$-width tolerance domains used in the leaning calculation may also have contributed to the counter-intuitive inferences in some instances. This assumption might be checked by varying the tolerance domains in the leaning calculation for every tested instance of Eqn.\ \ref{eqn:nonlinearEX} for which the $(1/4)$-width tolerance domain calculations implied a counter-intuitive causal inference.

\subsubsection{Coupled logistic map}
\label{sec:2Pop}
Consider the nonlinear dynamical system of
\begin{eqnarray}
\label{eqn:2pop}
\left\{\mathbf{X},\mathbf{Y}\right\} = \left\{\{x_t\},\{y_t\}\right\}
\end{eqnarray}
where $t=0,1,\ldots,L$,
\begin{equation*}
x_t = x_{t-1}\left(r_x-r_x x_{t-1}-\beta_{xy} y_{t-1}\right)
\end{equation*}
and
\begin{equation*}
y_t = y_{t-1}\left(r_y-r_y y_{t-1}-\beta_{yx} x_{t-1}\right)
\end{equation*}
where the parameters $r_x,r_y,\beta_{xy},\beta_{yx}\in\mathbb{R}\ge 0$.  This pair of equations is a specific form of the two-dimensional coupled logistic map system often used to model population dynamics \cite{Lloyd1995} and it was a system used in the introduction of cross convergent mapping, CCM, which is a SSR time series causality tool \cite{Sugihara2012}.

Sugihara et al.\ \cite{Sugihara2012} note that $\beta_{xy}>\beta_{yx}$ intuitively implies $\mathbf{Y}$ ``drives'' $\mathbf{X}$ more than $\mathbf{X}$ ``drives'' $\mathbf{Y}$, and vice versa.  Such intuition, however, can be difficult to justify for all instances of Eqn.\ \ref{eqn:2pop}.  The $x_{t-1}$ term that appears in $y_t$ can be seen as a function of $x_{t-2}$ with coefficients of $\beta_{yx}r_x$.  These product coefficients suggest that if $r_x>r_y$, then $\mathbf{X}$ may be seen as the stronger driver in the system even if $\beta_{yx}<\beta_{xy}$.  The same argument can be made, with the appropriate substitutions, to show that $\mathbf{Y}$ may be seen as the stronger driver in the system even if $\beta_{xy}<\beta_{yx}$.  As such, there is no clear intuitive causal inference for this system. 

Consider the instance of Eqn.\ \ref{eqn:2pop} with $L=500$, $\beta_{xy} = 0.5$, $\beta_{yx} = 1.5$, $r_x = 3.8$, and $r_y = 3.2$ with initial conditions $x_0 = y_0 = 0.4$ shown in Figure \ref{fig:2popxyplot}.  For this example, $r_x>r_y$, $\beta_{yx}>\beta_{xy}$, and the initial conditions are the same, which implies the intuitive causal inference for this example is $\mathbf{X}\rightarrow\mathbf{Y}$.  The histograms of these data shown in Figure \ref{fig:2popxyhist}.  For this example, the leaning calculation will use the $(1/4)$-width tolerance domains.
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{CoupLogMapExample_X.eps} & \includegraphics[scale=0.5]{CoupLogMapExample_Y.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{An instance of Eqn.\ \ref{eqn:2pop} for $L=500$, $\beta_{xy} = 0.5$, $\beta_{yx} = 1.5$, $r_x = 3.8$, and $r_y = 3.2$ with initial conditions $x_0 = y_0 = 0.4$.}
\label{fig:2popxyplot}
\end{figure}
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{CoupLogMapExample_Xhist.eps} & \includegraphics[scale=0.5]{CoupLogMapExample_Yhist.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Histograms of the instance of Eqn.\ \ref{eqn:2pop} shown in Figure \ref{fig:2popxyplot}.}
\label{fig:2popxyhist}
\end{figure}

Figure \ref{fig:2popxyautocorr} shows strong autocorrelations for both $\mathbf{X}$ and $\mathbf{Y}$ for a lag of $l=1$ and progressively weaker autocorrelations for $l=2,3,4$ with minimal autocorrelations for $l\ge 5$.  The autocorrelations do not appear cyclic.  The argument was made in Section \ref{sec:IR} that cyclic patterns in the autocorrelations of either times series might be used to limit the number of lags for which the leanings and lagged cross-correlation differences are calculated, i.e., it was argued that a repeating autocorrelation pattern after a given lag $l$ may imply that the leaning or cross-correlation calculations using lags greater than $l$ would be redundant information for drawing causal inferences.  This argument is not applicable for this example given that there are no apparent cyclic autocorrelation patterns.  There is no {\em a priori} reason to assume reasonable cause-effect assignments for the leaning might be drawn from autocorrelation patterns (i.e., the relationship of a signal to itself at different points in time is not necessarily related to the relationship between that signal and its potential driving or response partner signal).  However, visual inspection of the signals in Figure \ref{fig:2popxyplot} shows the signals have (roughly) similar shapes.  So, it may be reasonable to assume that if the signal $\mathbf{X}$ has a strong relationship with its own past at a given $l$, then, by a loose similarity argument, the partner signal $\mathbf{Y}$ may also have a strong relationship with $\mathbf{X}$ at lag $l$.  For this example, the leaning (with the $l$-standard assignment) and lagged cross-correlation time series causality tools will be calculated for lags $l=1,2,\ldots,4$, given the autocorrelations seem to decrease significantly for $l\ge 5$.  A cause-effect assignment must be made to calculate the leaning.  It will be shown that the leaning calculated using the $l$-standard assignment with $=1,2,\ldots,4$ implies the same causal inference as the other time series causality tools used in this example.  

The leaning and lagged cross-correlation differences are shown in Figure \ref{fig:2popxyLandLCC} for $l=1,2,\ldots,4$.  This figure shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, imply the intuitively correct causal inference $\mathbf{X}\rightarrow\mathbf{Y}$.  The mean across all the lags is $\langle\langle\lambda_l\rangle\rangle_l=2.7\times 10^{-1}$ and $\langle\Delta_l\rangle_l=-2.6\times 10^{-1}$, both of which imply $\mathbf{X}\rightarrow\mathbf{Y}$.  
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{CoupLogMapExample_autocorrX.eps} & \includegraphics[scale=0.48]{CoupLogMapExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Autocorrelations of the instances of $\mathbf{X}$ and $\mathbf{Y}$ of Eqn.\ \ref{eqn:2pop} shown in Figure \ref{fig:2popxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:2popxyautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{CoupLogMapExample_LandLCC.eps} 
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $(1/4)$-width tolerance domains) for the instances of Eqn.\ \ref{eqn:cyceqn} shown in Figure \ref{fig:2popxyplot} given lags of $l=1,2,\ldots,4$.}
\label{fig:2popxyLandLCC}
\end{figure}

For this example, the MVGC toolbox returns Granger causality log-likelihood statistics of $F_{X\rightarrow Y}-F_{Y\rightarrow X}=5.4\times 10^{-1}$.  The JIDT transfer entropy calculation returns $T_{X\rightarrow Y}-T_{Y\rightarrow X}=4.9\times 10^{-1}$.  The PAI correlation difference is $-3.9\times 10^{-3}$.  If the leaning and lagged cross-correlation difference contributions to the ECA guess vector are defined as the mean across all the tested lags, then the ECA guess for this example is $|\vec{g}|^2=0\Rightarrow \mathbf{X}\rightarrow\mathbf{Y}$.  All of these results imply $\mathbf{X}\rightarrow\mathbf{Y}$, which agrees with intuition.   

The parameter space of Eqn.\ \ref{eqn:2pop} provides an opportunity to ask many interesting questions about the exploratory causal analysis.  For example, an instance of Eqn.\ \ref{eqn:2pop} with $L=500$, $\beta_{xy} = \beta_{yx} = 1.0$, $r_x = r_y = 3.5$ and $x_0 = y_0 = 0.4$ leads to an ECA guess vector of $\vec{g}=(2,2,2,2,2)$ (given $g_4$ (leaning) and $g_5$ (lagged cross-correlation) calculated in the same fashion as the previous example, i.e., Figure \ref{fig:nonxyplot}).  The intuitive causal inference for this instance of Eqn.\ \ref{eqn:nonlinearEX} is not obvious and the undefined ECA guess seems to imply this confusion is not remedied by the exploratory causal analysis approach.  Changing the system parameters slightly to $L=500$, $\beta_{xy} = \beta_{yx} = 1.0$, $r_x = 3.6$, $r_y = 3.4$ and $x_0 = y_0 = 0.4$ leads to an ECA guess vector of $\vec{g}=(1,2,1,0,0)$.  It may be argued that the intuitive causal inference in this case is $\mathbf{X}\rightarrow\mathbf{Y}$ because $r_x>r_y$ with all the other systems parameters being equal.  This intuition, however, is not reflected by the ECA guess vector, where only two of the time series causality tools imply that intuitive inference, $g_4$ (leaning) and $g_5$ (lagged cross-correlation).  Consider instead $L=500$, $\beta_{xy} = 1.1$, $\beta_{yx} = 0.9$, $r_x = r_y = 3.5$ and $x_0 = y_0 = 0.4$, which leads to an ECA guess vector of $\vec{g}=(0,2,2,0,1)$.  The intuitive causal inference in this case might be $\mathbf{Y}\rightarrow\mathbf{X}$ because $\beta_{xy}>\beta_{yx}$ with all the other systems parameters being equal, but only one tool, $g_5$ (lagged cross-correlation), implies this inference in the ECA guess vector.  The initial conditions of the system also affect the ECA guess, e.g., $L=500$, $\beta_{xy} = \beta_{yx} = 1.0$, $r_x = r_y = 3.5$, $x_0 = 0.3$ and $y_0 = 0.5$ leads to $\vec{g}=(1,2,2,1,0)$.  The ECA guess does, however, seem to agree with intuition when such intuitions are straightforward for a given instance of Eqn.\ \ref{eqn:nonlinearEX}; e.g., $L=500$, $\beta_{xy} = \beta_{yx} = 0.5$, $r_x = 3.0$ , $r_y = 3.8$, and $x_0 = y_0 = 0.4$ leads to $\vec{g}=(1,1,0,1,1)$ (which implies $\mathbf{Y}\rightarrow\mathbf{X}$, as expected, for all $g_i$ except $g_3$ (PAI)) and $L=500$, $\beta_{xy} = 0.5$, $\beta_{yx} = 2.0$, $r_x = r_y = 3.5$, and $x_0 = y_0 = 0.4$ leads to $\vec{g}=(0,2,2,0,0)$ (which implies $\mathbf{X}\rightarrow\mathbf{Y}$, as expected, for a majority of the $g_i$).

\subsubsection{Impulse with multiple linear responses}
\label{sec:3var}
Consider the multivariate system of
\begin{eqnarray}
\label{eqn:3var}
\left\{\mathbf{X},\mathbf{Y},\mathbf{Z}\right\} = \left\{\{x_t\},\{y_t\},\{z_t\}\right\}
\end{eqnarray}
where $t=0,1,\ldots,L$,
\begin{equation*}
x_t = \left\{
  \begin{array}{lr}
    2 & t = 1\\
    A\eta_t & \forall\; t\in\{t\;|\;t\neq 1 \;\mathrm{and}\; t\bmod 5 \neq 0\}\\
    2 & \forall\; t\in\{t\;|\;t\bmod 5 = 0\}
  \end{array}
\right.
\end{equation*}
and
\begin{equation*}
y_t = x_{t-1} + B\eta_t\;\;,
\end{equation*}
and either (case 1)
\begin{equation}
z_t = y_{t-1}
\end{equation}
or (case 2)
\begin{equation}
z_t^\prime = y_{t-1} + y_t = y_{t-1} + x_{t-1} + B\eta_t
\end{equation}
or (case 3)
\begin{equation}
z_t^{\prime\prime} = y_{t-1} + x_{t-1} + z_{t-1}^{\prime\prime}
\end{equation}
with $y_0 = 0$, $B\in\mathbb{R}\ge 0$, $\eta_t\sim\mathcal{N}\left(0,1\right)$, and $L=500$.

In case 1, $\mathbf{Z}$ depends directly on $\mathbf{Y}$ and indirectly on $\mathbf{X}$ (through $\mathbf{Y}$, which depends directly on $\mathbf{X}$).  The intuitive causal inference is then $\mathbf{Y}\rightarrow\mathbf{Z}$ and $\mathbf{X}\rightarrow\mathbf{Z}$.  Case 2, despite the additional $\mathbf{Y}$ dependence in $\mathbf{Z}$, has the same intuitive causal inference as case 1.  In case 3, $\mathbf{Z}$ depends directly on itself and both $\mathbf{Y}$ and $\mathbf{X}$.  Case 3 also has the same intuitive causal inference.

Consider the instance of Eqn.\ \ref{eqn:IReqn} with $L=500$, $A=0.4$, and $B=0.6$ shown in Figure \ref{fig:3varxyplot}.  The leaning calculation will use $(1/4)$-width tolerance domains.  Histograms of these data are shown in Figure \ref{fig:3varxyhist}.  Figure \ref{fig:3varxyautocorr} shows strong autocorrelations for $\mathbf{X}$, $\mathbf{Y}$, and $\mathbf{Z}$ (for cases 1 and 2) at $l=6,12,18,\ldots,48$, which is expected given the similar forms of Eqn.\ \ref{eqn:3var} and \ref{eqn:IReqn} (see Section \ref{sec:IR}).  The leaning (using the $l$-standard assignment) and lagged cross-correlation calculations will use lags $l=1,2,\ldots,6$.  

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyMultiResponseExample_X.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_Y.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$ \\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_z1.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_z2.eps} \\
(c) $\mathbf{Z} = \{z_t\}$ (case 1)& (d) $\mathbf{Z} = \{z_t^\prime\}$ (case 2) \\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_z3.eps} &  \\
(e) $\mathbf{Z} = \{z_t^{\prime\prime}\}$ (case 3)& 
\end{tabular}
\caption{An instance of Eqn.\ \ref{eqn:3var} for $L=500$, $A=0.4$, and $B=0.6$.}
\label{fig:3varxyplot}
\end{figure}
\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{NoisyMultiResponseExample_Xhist.eps} & \includegraphics[scale=0.5]{NoisyMultiResponseExample_Yhist.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$ \\
\includegraphics[scale=0.5]{NoisyMultiResponseExample_Z1hist.eps} & \includegraphics[scale=0.5]{NoisyMultiResponseExample_Z2hist.eps} \\
(c) $\mathbf{Z} = \{z_t\}$ (case 1)& (d) $\mathbf{Z} = \{z_t^\prime\}$ (case 2)\\
\includegraphics[scale=0.5]{NoisyMultiResponseExample_Z3hist.eps} & \\
(e) $\mathbf{Z} = \{z_t^{\prime\prime}\}$ (case 3)& 
\end{tabular}
\caption{Histograms of the instance of Eqn.\ \ref{eqn:3var} shown in Figure \ref{fig:3varxyplot}.}
\label{fig:3varxyhist}
\end{figure}

Figure \ref{fig:3varxyLandLCC} shows both the weighted mean observed leaning, $\langle \lambda_l\rangle$, and the lagged cross-correlation differences, $\Delta_l$, for each of the seven time series pairs in this example, $(\mathbf{X},\mathbf{Y})$, $(\mathbf{X},\mathbf{Z})$ (for all three cases), and $(\mathbf{Y},\mathbf{Z})$ (for all three cases).  Table \ref{tab:3varEx} shows the values of each of the five time series causality tools used in this exploratory causal analysis for each of the time series pairs in this example with the mean leaning across all the lags labeled ``L'', the mean lagged cross-correlation difference labeled ``LCC'', Granger causality log-likelihood statistics difference (i.e., $F_{X\rightarrow Y}-F_{Y\rightarrow X}$, calculated by the MVGC toolbox) labeled ``GC'', the transfer entropy difference (i.e., $T_{X\rightarrow Y}-T_{Y\rightarrow X}$, calculated with the JIDT) labeled ``TE'', and the PAI correlation difference labeled ``PAI''.  Table \ref{tab:3varEx} also shows the ECA guess and vector for each pair.
\begin{table}
\begin{center}
\begin{tabular}{lccccccc}
  & TE & GC & PAI & L & LCC & $\vec{g}$ & ECA guess\\
\midrule
$(\mathbf{X},\mathbf{Y})$ & $5.9\times 10^{-1}$ & $8.0\times 10^{-1}$ & $-6.7\times 10^{-3}$ & $2.3\times 10^{-2}$ & $-1.4\times 10^{-2}$ & $(0,0,0,0,0)$ & $\mathbf{X}\rightarrow\mathbf{Y}$\\
$(\mathbf{X},\mathbf{Z})$ (case 1) & $2.7\times 10^{-2}$ & $7.9\times 10^{-1}$ & $-1.2\times 10^{-2}$ & $2.2\times 10^{-2}$ & $-1.6\times 10^{-2}$ & $(0,0,0,0,0)$ & $\mathbf{X}\rightarrow\mathbf{Z}$\\
$(\mathbf{X},\mathbf{Z})$ (case 2) & $2.8\times 10^{-1}$ & $6.5\times 10^{-1}$ & $-6.8\times 10^{-3}$ & $2.5\times 10^{-2}$ & $-3.7\times 10^{-2}$ & $(0,0,0,0,0)$ & $\mathbf{X}\rightarrow\mathbf{Z}$\\
$(\mathbf{X},\mathbf{Z})$ (case 3) & $-2.7\times 10^{-2}$ & n/a & $4.1\times 10^{-3}$ & $5.9\times 10^{-4}$ & $1.9\times 10^{-3}$ & $(1,2,1,0,1)$ & undefined\\
$(\mathbf{Y},\mathbf{Z})$ (case 1) & 1.8 & n/a & $-5.3\times 10^{-3}$ & $1.2\times 10^{-1}$ & $-7.7\times 10^{-2}$ & $(0,2,0,0,0)$ & undefined\\
$(\mathbf{Y},\mathbf{Z})$ (case 2) & $3.2\times 10^{-1}$ & n/a & $-6.9\times 10^{-5}$ & $3.6\times 10^{-2}$ & $-6.0\times 10^{-2}$ & $(0,2,0,0,0)$ & undefined\\
$(\mathbf{Y},\mathbf{Z})$ (case 3) & $-4.6\times 10^{-2}$ & n/a & $1.1\times 10^{-2}$ & $4.1\times 10^{-4}$ & $7.5\times 10^{-3}$ & $(1,2,1,0,1)$ & undefined\\
\end{tabular}
\caption{The values of each of the five time series causality tools used in this exploratory causal analysis for each of the time series pairs shown in Figure \ref{fig:3varxyplot} with the mean leaning across all the lags labeled ``L'', the mean lagged cross-correlation difference labeled ``LCC'', Granger causality log-likelihood statistics difference (i.e., $F_{X\rightarrow Y}-F_{Y\rightarrow X}$, calculated by the MVGC toolbox) labeled ``GC'', the transfer entropy difference (i.e., $T_{X\rightarrow Y}-T_{Y\rightarrow X}$, calculated with the JIDT) labeled ``TE'', and the PAI correlation difference labeled ``PAI''.  An entry of ``n/a'' in the GC column indicates the the MVGC toolbox failed to fit a VAR model to the data with the maximum request model parameters and/or within the maximum allotted computation time.}
\label{tab:3varEx}
\end{center}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{lccc}
  & ECA guess & Majority-vote inference & Intuitive inference\\
\midrule
$(\mathbf{X},\mathbf{Y})$ & $\mathbf{X}\rightarrow\mathbf{Y}$ & $\mathbf{X}\rightarrow\mathbf{Y}$ & $\mathbf{X}\rightarrow\mathbf{Y}$\\
$(\mathbf{X},\mathbf{Z})$ (case 1) & $\mathbf{X}\rightarrow\mathbf{Z}$ & $\mathbf{X}\rightarrow\mathbf{Z}$ & $\mathbf{X}\rightarrow\mathbf{Z}$\\
$(\mathbf{X},\mathbf{Z})$ (case 2) & $\mathbf{X}\rightarrow\mathbf{Z}$ & $\mathbf{X}\rightarrow\mathbf{Z}$ & $\mathbf{X}\rightarrow\mathbf{Z}$\\
$(\mathbf{X},\mathbf{Z})$ (case 3) & undefined & $\mathbf{Z}\rightarrow\mathbf{X}$ & $\mathbf{X}\rightarrow\mathbf{Z}$\\
$(\mathbf{Y},\mathbf{Z})$ (case 1) & undefined & $\mathbf{Y}\rightarrow\mathbf{Z}$ & $\mathbf{Y}\rightarrow\mathbf{Z}$\\
$(\mathbf{Y},\mathbf{Z})$ (case 2) & undefined & $\mathbf{Y}\rightarrow\mathbf{Z}$ & $\mathbf{Y}\rightarrow\mathbf{Z}$\\
$(\mathbf{Y},\mathbf{Z})$ (case 3) & undefined & $\mathbf{Z}\rightarrow\mathbf{Y}$ & $\mathbf{Y}\rightarrow\mathbf{Z}$\\
\end{tabular}
\caption{Comparisons of the ECA guesses for each of the time series pairs shown in Figure \ref{fig:3varxyplot} with the intuitive inferences and the ``majority-vote'' inference, i.e., the causal inference implied by the majority of the times series causality tools used during the exploratory causal analysis.}
\label{tab:3varExECAguess}
\end{center}
\end{table}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyMultiResponseExample_autocorrX.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$ \\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_autocorrZ1.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_autocorrZ2.eps} \\
(c) $\mathbf{Z} = \{z_t\}$ (case 1)& (d) $\mathbf{Z} = \{z_t^\prime\}$ (case 2)\\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_autocorrZ3.eps} &  \\
(e) $\mathbf{Z} = \{z_t^{\prime\prime}\}$ (case 3)& 
\end{tabular}
\caption{Autocorrelations of the instances of $\mathbf{X}$, $\mathbf{Y}$, and $\mathbf{Z}$ of Eqn.\ \ref{eqn:3var} shown in Figure \ref{fig:3varxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:3varxyautocorr}
\end{figure}
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_XY.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_XZ1.eps} \\
(a) $(\mathbf{X},\mathbf{Y})$ & (b) $(\mathbf{X},\mathbf{Z})$ (case 1)\\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_XZ2.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_XZ3.eps} \\
(c) $(\mathbf{X},\mathbf{Z})$ (case 2) & (d) $(\mathbf{X},\mathbf{Z})$ (case 3)\\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_YZ1.eps} & \includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_YZ2.eps} \\
(e) $(\mathbf{Y},\mathbf{Z})$ (case 1) & (f) $(\mathbf{Y},\mathbf{Z})$ (case 2)\\
\includegraphics[scale=0.48]{NoisyMultiResponseExample_LandLCC_YZ3.eps} &  \\
(e) $(\mathbf{Y},\mathbf{Z})$ (case 3) & 
\end{tabular}
\end{center}
\caption{Lagged cross-correlation differences, $\Delta_l$, and weighted mean observed leanings, $\langle\lambda_l\rangle$, (given an $l$-standard cause-effect assignment with $(1/4)$-width tolerance domains) for the instances of Eqn.\ \ref{eqn:3var} shown in Figure \ref{fig:3varxyplot} given lags of $l=1,2,\ldots,6$.}
\label{fig:3varxyLandLCC}
\end{figure}

Table \ref{tab:3varEx} shows the individual values for each tool used during the exploratory analysis along with the ECA guess vector.  Table \ref{tab:3varExECAguess} shows how these ECA guesses compare both the the intuitive causal inferences for each case and to the majority-vote inference, i.e, the causal inference implied by the majority of the times series causality tools used during the analysis.  The ECA guess of $\mathbf{X}\rightarrow\mathbf{Y}$, and its agreement with the intuitive inference, may have been expected given the similarity of this example to the one discussed in Section \ref{sec:IR}, but the only two other ECA guesses that agree with the intuitive inferences are for case 1 and 2 of the pair $(\mathbf{X},\mathbf{Z})$.  The ECA guess is undefined for every other time series pair.  The ECA guess was undefined for case 1 and 2 of the pair $(\mathbf{Y},\mathbf{Z})$ because $g_2$ (Granger) was undefined.  In these scenarios, along with case 3 of both pairs, the MVGC toolbox failed to fit a VAR model to the data with the maximum request model parameters and/or within the maximum allotted computation time.  However, the majority-vote inference agrees with intuition for case 1 and 2 of the pair $(\mathbf{Y},\mathbf{Z})$.  Interestingly, the majority-vote inference for case 3 of both time series pairs in counter-intuitive.  Only $g_4$ (leaning) agrees with intuition for the case 3 pairs.  These counter-intuitive majority-vote inferences may imply case 3 of $\mathbf{Z}$ has some property that makes time series causality particularly unreliable.  Case 3 of $\mathbf{Z}$ is, e.g., apparently non-stationary\footnote{The phrase ``apparently'' is used here in indicate that the approximate stationarity of the data is drawn from visual inspections of Figure \ref{fig:3varxyplot} rather than formal tests.}.  The autoregressive term in $z_t^{\prime\prime}$ of Eqn.\ \ref{eqn:3var} is unique among all the cases of $\mathbf{Z}$ in this example.  These properties may lead to unreliable exploratory causal analysis with the time series causality tools being used in this work.  This idea might be explored by focusing on more synthetic data examples with response signals similar to case 3 of $\mathbf{Z}$, i.e., with autoregessive terms and/or non-stationary.  In this example, however, the counter-intuitive inferences illustrate that exploratory causal analysis inferences may be unreliable in the presence of confounding.  Although, if an analyst only had access to $\mathbf{Y}$ and $\mathbf{Z}$ in this example, then the majority-vote inferences would still imply the intuitive causal inference in every case except case 3, as seen in Table \ref{tab:3varExECAguess}.

\subsection{Empirical data examples}
\label{sec:emp}
Empirical data sets with known (or assumed) causal relationships may be used to understand how exploratory causal inference using leanings might be done if the system dynamics are unknown (or sufficiently complicated to make first principle numerical comparisons cumbersome).

\subsubsection{Snowfall data}
Figure \ref{fig:WhistSnowxyplot} shows a time series pair with causal ``truth'' from the UCI Machine Learning Repository (MLR) \cite{bache2013}.  This data repository is a collection of data sets (some of which are time series) with known, intuitive, or assumed causal relationships meant for use in the testing of causal discovery algorithms in machine learning \cite{bache2013}.

Figure \ref{fig:WhistSnowxyplot}(a) and (b)  are times series of the daily snowfall (the expected response) and mean temperature (the expected driver) from July 1, 1972 to December 31, 2009 at Whistler, BC, Canada (Latitude: 50$^\circ$04$^\prime$04.000$^{\prime\prime}$ N, Longitude: 122$^\circ$56$^\prime$50.000$^{\prime\prime}$ W, Elevation: 1835.00 meters).  From \cite{bache2013}, ``Common sense tells us that X [mean temperature] causes Y [snow fall] (with maybe very small feedback of Y on X). Confounders are present (e.g., day of the year).''  These time series correspond to data set 87 of the MLR \cite{bache2013}.  Thus, following the notation of Figure \ref{fig:WhistSnowxyplot}, the intuitive causal inference for this example is $\mathbf{X}\rightarrow\mathbf{Y}$. 

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{WhistlerDailyExample_X.eps} & \includegraphics[scale=0.48]{WhistlerDailyExample_Y.eps} \\
(a) mean temperature $\mathbf{X}$ & (b) daily snowfall $\mathbf{Y}$
\end{tabular}
\caption{Daily snowfall (the expected response) and mean temperature (the expected driver) from July 1 1972 to December 31 2009 at Whistler, BC, Canada (Latitude: 50$^\circ$04$^\prime$04.000$^{\prime\prime}$ N, Longitude: 122$^\circ$56$^\prime$50.000$^{\prime\prime}$ W, Elevation: 1835.00 meters).}
\label{fig:WhistSnowxyplot}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{WhistlerDailyExample_Xhist.eps} & \includegraphics[scale=0.5]{WhistlerDailyExample_Yhist.eps} \\
(a) mean temperature $\mathbf{X}$ & (b) daily snowfall $\mathbf{Y}$
\end{tabular}
\caption{Histograms of the data shown in Figure \ref{fig:WhistSnowxyplot}.}
\label{fig:WhistSnowxyhist}
\end{figure}

Figure \ref{fig:WhistSnowxyautocorr} shows the autocorrelations for the data shown Figure \ref{fig:WhistSnowxyplot}, and Figure \ref{fig:WhistSnowxyhist} shows the $100$-bin histograms of the data.  The autocorrelations do not appear cyclic (within the 50 lags that were calculated) but, for the snowfall time series (i.e., $\mathbf{Y}$), the autocorrelations approach zero for $l>20$.  This observation will be used to set the lags for the leaning (with the $l$-standard assignment) and lagged cross-correlation calculations as $l=1,2,\ldots,20$.  The tolerance domains for the leaning calculation with be the $(1/4)$-width domains.

The mean leaning across all the lags, $\langle\langle\lambda_l\rangle\rangle_l=3.7\times 10^{-2}$, which implies the intuitive causal inference.  The mean lagged cross-correlation across all the lags, $\langle\Delta_l\rangle_l=2.3\times 10^{-2}$, which implies the counter-intuitive causal inference.  The MVGC toolbox returns Granger causality log-likelihood statistics of $F_{X\rightarrow Y}-F_{Y\rightarrow X}=-2.6\times 10^{-3}$, which also implies the counter-intuitive causal inference.  The JIDT transfer entropy calculation returns $T_{X\rightarrow Y}-T_{Y\rightarrow X}=2.1\times 10^{-2}$, and the PAI correlation difference\footnote{For this example, the embedding dimension was set as $E=100$, rather than $E=3$, which was the embedding dimension in every previous example.  The larger embedding dimension was not set with any formal procedure (see, e.g., \cite{Ma2006,Kennel1992,Small2004,Ataei2003,Kugiumtzis1996}).  Instead, the PAI correlation difference was calculated with $E=100$ once it was discovered that the algorithm failed with $E=3$ (See footnote in Section \ref{sec:rlcirc} for a discussion of failures of the PAI algorithm).  The time delay used in this example was the same as every other example, i.e., $\tau=1$.} is $-3.4\times 10^{-2}$, both of which imply the intuitive causal inference.  If the leaning and lagged cross-correlation difference contributions to the ECA guess vector are defined as the mean across all the tested lags, then the ECA guess vector for this example is $\vec{g} = (0,1,0,0,1)$, which implies the ECA guess is undefined.  The majority-vote causal inference, however, implies $\mathbf{X}\rightarrow\mathbf{Y}$, which agrees with intuition.  

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{WhistlerDailyExample_autocorrX.eps} & \includegraphics[scale=0.48]{WhistlerDailyExample_autocorrY.eps} \\
(a) $\mathbf{X}$ & (b) $\mathbf{Y}$
\end{tabular}
\caption{Autocorrelations of the data shown in Figure \ref{fig:WhistSnowxyplot} given lags of $l=1,2,\ldots,50$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:WhistSnowxyautocorr}
\end{figure}

This example illustrates the benefit of using multiple times series causality tools.  Consider $g_4$ (leaning), which implied an intuitive causal inference, and $g_5$ (cross-correlation), which implied a counter-intuitive causal inference.  If those tools are calculated as the means across all tested lags with $l=1,2,\ldots,l_{max}$, then as seen above, $l_{max}=20\Rightarrow g_4=0,\;g_5=1$.  It is also true that any $l_{max}=2,3,\ldots,20\Rightarrow g_4=0,\;g_5=1$.  The lagged cross-correlation difference with the maximum absolute value across all the tested lags is positive, which also implies the counter-intuitive inference.  The majority of the lagged cross-correlation differences implied the counter-intuitive inference (16 of the 20 calculated lags).  So, it seems most reasonable approaches to determine $g_5$ from the set of lagged cross-correlation differences would lead to $g_5=1$, which does not agree with intuition.  Likewise, $g_2$ (Granger) implies the counter-intuitive causal inference; i.e., $g_2=1$.  It may be argued that the MVGC log-likelihood of $F_{X\rightarrow Y}-F_{Y\rightarrow X}=-2.6\times 10^{-3}$ is better interpreted as $g_2=2$ because the value is two orders of magnitude closer to zero than any other MVGC log-likelihood differences calculated in this work.  But, neither conclusion, $g_2=1$ or $g_2=2$, agrees with the intuitive causal inference.  The use of either of these time series causality tools alone (i.e., $g_2$ or $g_5$) may lead an analyst to draw a counter-intuitive causal inference.  The use of these tools as part of a set, however, allows the analyst to compare and contrast the different tools.  The analyst may decide to use a majority-vote inference, which agrees with intuition for this example, or an analyst may use outside assumptions to determine certain tools, e.g., $g_5$ or $g_2$, are unreliable for the type of data being analyzed.  At a minimum, the different implications of the tools strongly suggests the analyst should consider applying each tool more careful, e.g., by changing the model parameters for $g_2$.

\subsubsection{OMNI data}
The NASA OMNI data set consists of hourly-averaged time series measurements of several different space weather parameters from 1963 to present, collected from more than twenty different satellites, along with sunspot number and several different geomagnetic indices, including $D_{st}$, collected from the NOAA National Geophysical Data Center \cite{King2005}.  The disturbance storm time, $D_{st}$, is a measure of geomagnetic activity \cite{IAGA}.  The magnetic field measurements in the OMNI data sets, specifically $B_z$ in GSE coordinates \cite{Hapgood1992}, is believed to be a driver of $D_{st}$ \cite{Gonz1994}.

Consider the available measurements for the magnetic field, $B_z$ (in nanoTesla, nT), and the disturbance storm time, $D_{st}$.  The collection and aggregation procedures used to get this data into the OMNI data set can be found in \cite{King2005}\footnote{The data itself, along with discussions of format, units, and origin, among other things, can also be found at \url{http://omniweb.gsfc.nasa.gov/}.}.  The time series pair $(\mathbf{B},\mathbf{D})$ consists of all the available measurements $\mathbf{B} =\{B_z(t)\}$ and $\mathbf{D}=\{D_{st}(t)\}$ where $\Delta t=t_{n+1}-t_n=1$ hour $\forall n=1,2,\ldots,N-1$ (with $N=438312$), the first time step $t_0=0$ represents 00:30:00 January 1, 1963 UTC, and the last time step $t_N = 438312$ represents 23:30:00 December 31, 2012 UTC.  These hourly data sets are shown in Figure \ref{fig:BzDstHOURLYxyplot}.  The 1000-bin histograms of these times series are shown in Figure \ref{fig:BzDstHOURLYxyhist}.  It is standard practice to ``rectify'' the magnetic field component $B_z$ as $B_z^\prime$ where $B_z^\prime(t) = B_z(t)$ if $B_z(t)\le 0$ and $B_z^\prime(t) = 0$ if $B_z(t)>0$ \cite{Burton1975,Dungey1961}.  This treatment leads to a second times series pair $(\mathbf{B}_r,\mathbf{D})$ with $\mathbf{B}_r = \{B_z^\prime (t)\}$.  Figure \ref{fig:BzDstHOURLYrecxyplot} shows both the times series and 1000-bin histogram of $\mathbf{B}_r$.

The time series $\mathbf{B}$, $\mathbf{B}_r$, and $\mathbf{D}$ are long, with approximately 440,000 data points each, and each contains missing data (i.e., time stamps for which no measurements are present in the data set).  Both of these properties are practical concerns for the data analyst.  The length may make the calculation of certain time series causality tools computationally infeasible, and the missing data may lead to erroneous results, if the algorithm used to calculate a given time series causality tool can even handle missing data.  The magnetic field data, $\mathbf{B}$, contains 131,928 missing data points, and the storm index, $D_{st}$, contains 7,736 missing data points.  Some, but not all, of the missing data coincide within the time series pair.  Creating a new time series from the defined points of $\mathbf{B}$ and $\mathbf{D}$ will lead to nonuniform time intervals for subsequent time steps in the series, which will make causal interpretations more difficult\footnote{Consider the leaning calculated using the 1-standard cause-effect assignment for a given time series pair $(\mathbf{A},\mathbf{B})$.  If the time intervals of the time steps of $\mathbf{A}$ and $\mathbf{B}$ are not uniform, an analyst must be certain to understand the leaning is comparing time steps, not physical time intervals.  Thus, $\{C,E\}=\{a_{t-1},b_t\}$ would not be an assumption of, e.g., an hour in the past of $\mathbf{A}$ drives the present of $\mathbf{B}$ as it would be if $\Delta t = t_{n} - t_{n-1} = 1$ hour $\forall t_n$ in $\mathbf{A}$ and $\mathbf{B}$.}.  The length of the time series may be addressed by only considering contiguous subsets of the series, but there is a risk that data associated with interesting physical phenomena captured during one subset may not be present in another.  This work will address these practical issue with two different approaches, averaging and sampling.

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.52]{SolarExample_Bzhourly.eps} & \includegraphics[scale=0.52]{SolarExample_Dhourly.eps} \\
(a) $\mathbf{B}$ & (b) $\mathbf{D}$
\end{tabular}
\caption{Hourly measurements of the magnetic field component, $B_z$, and disturbance storm time index, $D_{st}$ from the beginning of January 1, 1963 until the end of December 31, 2012, taken from the NASA OMNI data set.}
\label{fig:BzDstHOURLYxyplot}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{SolarExample_Bzhourlyhist.eps} & \includegraphics[scale=0.48]{SolarExample_Dhourlyhist.eps} \\
(a) $\mathbf{B}$ & (b) $\mathbf{D}$
\end{tabular}
\caption{Histograms of the data shown in Figure \ref{fig:BzDstHOURLYxyplot}.}
\label{fig:BzDstHOURLYxyhist}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.51]{SolarExample_Bzhourlyrec.eps} & \includegraphics[scale=0.51]{SolarExample_Bzhourlyrechist.eps} \\
(a) $\mathbf{B}_r$ (time series) & (b) $\mathbf{B}_r$ (histogram)
\end{tabular}
\caption{Hourly measurements of the rectified magnetic field, $B_z^\prime$ from the beginning of January 1, 1963 until the end of December 31, 2012, and the 1000-bin histogram of that data.}
\label{fig:BzDstHOURLYrecxyplot}
\end{figure}

There is no missing data in $\mathbf{D}$ between 00:30:00 January 1, 1997 UTC and 23:30:00 December 31, 2001 UTC.  This same time period contains 185 missing data points in $\mathbf{B}$, which can all be ``averaged out'' by finding the average value for each set of 24 points while ignoring any missing data (i.e., there are no sets of 24 consecutive missing data points in $\mathbf{B}$ within this time period).  Let $\bar{\mathbf{D}}$, $\bar{\mathbf{B}}$, and $\bar{\mathbf{B}}_r$ be the daily (i.e., 24 hour) averages of $\mathbf{D}$, $\mathbf{B}$, and $\mathbf{B}_r$, respectively, within this time period.  Each of the new time series, $\bar{\mathbf{D}}$, $\bar{\mathbf{B}}$, and $\bar{\mathbf{B}}_r$, contains 1,826 data points with no missing points.  Figures \ref{fig:BzDstDAILYxyplot}, \ref{fig:BzDstDAILYxyhist}, and \ref{fig:BzDstDAILYrecxyplot} show both the times series and the 100-bin histograms of these averaged data sets.  

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{SolarExample_Bzdaily.eps} & \includegraphics[scale=0.48]{SolarExample_Ddaily.eps} \\
(a) $\bar{\mathbf{B}}$ & (b) $\bar{\mathbf{D}}$
\end{tabular}
\caption{Daily averages of the hourly measurements of the magnetic field, $B_z$, and disturbance storm time index, $D_{st}$ from the beginning of January 1, 1997 until the end of December 31, 2001, taken from the NASA OMNI data set.}
\label{fig:BzDstDAILYxyplot}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.5]{SolarExample_Bzdailyhist.eps} & \includegraphics[scale=0.5]{SolarExample_Ddailyhist.eps} \\
(a) $\bar{\mathbf{B}}$ & (b) $\bar{\mathbf{D}}$
\end{tabular}
\caption{Histograms of the data shown in Figure \ref{fig:BzDstDAILYxyplot}.}
\label{fig:BzDstDAILYxyhist}
\end{figure}

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{SolarExample_Bzdailyrec.eps} & \includegraphics[scale=0.48]{SolarExample_Bzdailyrechist.eps} \\
(a) $\bar{\mathbf{B}}_r$ (time series) & (b) $\mathbf{\mathbf{B}}_r$ (histogram)
\end{tabular}
\caption{Daily averages of the hourly measurements of the rectified magnetic field, $B_z^\prime$ from the beginning of January 1, 1997 until the end of December 31, 2001, and the 100-bin histogram of that data.}
\label{fig:BzDstDAILYrecxyplot}
\end{figure}

The autocorrelations of $\bar{\mathbf{D}}$ and $\bar{\mathbf{B}}$ are shown in Figure \ref{fig:BzDstDAILYxyautocorr}, from which the lags for the leaning (using the $l$-standard cause-effect assignment) and lagged cross-correlation difference calculations are set as $l=1,2,\ldots,30$.  The leaning calculation will use the $(1/4)$ tolerance domains.  The PAI correlation differences are calculated with $E=100$ and $\tau = 1$.  ECA guess vectors can be constructed for the two time series pairs $(\bar{\mathbf{B}},\bar{\mathbf{D}})$ and $(\bar{\mathbf{B}}_r,\bar{\mathbf{D}})$, which are shown in Tables \ref{tab:SolEx} and \ref{tab:SolExECAguess}.  The majority-vote inference agrees with intuition for both pairs, but the ECA guess only agrees with intuition for the pair $(\bar{\mathbf{B}}_r,\bar{\mathbf{D}})$.  The ECA guess for the pair $(\bar{\mathbf{B}},\bar{\mathbf{D}})$ is undefined because $g_2$ (Granger) implies $\bar{\mathbf{B}}\leftarrow\bar{\mathbf{D}}$ while every other time series causality tool implies the intuitively correct $\bar{\mathbf{B}}\rightarrow\bar{\mathbf{D}}$.  The question of whether or not $g_2$ might imply the intuitive causal inference for different VAR modeling parameters was not explored in this work.

\begin{figure}[ht]
\begin{tabular}{cc}
\includegraphics[scale=0.48]{SolarExample_autocorrBzdaily.eps} & \includegraphics[scale=0.48]{SolarExample_autocorrDdaily.eps} \\
(a) $\bar{\mathbf{B}}$ & (b) $\bar{\mathbf{D}}$
\end{tabular}
\caption{Autocorrelations of the data shown in Figure \ref{fig:BzDstDAILYxyplot} given lags of $l=1,2,\ldots,100$.  The autocorrelations are $|r(b_{t-l},b_t)|^2$ where $r(\cdot)$ is the Pearson correlation coefficient between the lagged $l$ series $\{b_{t-l}\}$ and the time series $\{b_{t}\}$.}
\label{fig:BzDstDAILYxyautocorr}
\end{figure}

\begin{table}
\begin{center}
\begin{tabular}{lccccccc}
  & TE & GC & PAI & L & LCC & $\vec{g}$ & ECA guess\\
\midrule
$(\bar{\mathbf{B}},\bar{\mathbf{D}})$ & $3.6\times 10^{-3}$ & $-4.6\times 10^{-3}$ & $-1.2\times 10^{-1}$ & $5.0\times 10^{-3}$ & $-1.2\times 10^{-2}$ & $(0,1,0,0,0)$ & undefined\\
$(\bar{\mathbf{B}}_r,\bar{\mathbf{D}})$ & $2.7\times 10^{-2}$ & $4.6\times 10^{-3}$ & $-1.3\times 10^{-1}$ & $7.6\times 10^{-3}$ & $-2.5\times 10^{-2}$ & $(0,0,0,0,0)$ & $\bar{\mathbf{B}}_r\rightarrow\bar{\mathbf{D}}$
\end{tabular}
\caption{The values of each of the five time series causality tools used in the exploratory causal analysis for each of the time series pairs shown in Figures \ref{fig:BzDstDAILYxyplot} and \ref{fig:BzDstDAILYrecxyplot} with the mean leaning across all the lags labeled ``L'', the mean lagged cross-correlation difference labeled ``LCC'', Granger causality log-likelihood statistics difference (i.e., $F_{X\rightarrow Y}-F_{Y\rightarrow X}$, calculated by the MVGC toolbox) labeled ``GC'', the transfer entropy difference (i.e., $T_{X\rightarrow Y}-T_{Y\rightarrow X}$, calculated with the JIDT) labeled ``TE'', and the PAI correlation difference labeled ``PAI''.  An entry of ``n/a'' in the GC column indicates the the MVGC toolbox failed to fit a VAR model to the data with the maximum request model parameters and/or within the maximum allotted computation time.}
\label{tab:SolEx}
\end{center}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{lccc}
  & ECA guess & Majority-vote inference & Intuitive inference\\
\midrule
$(\bar{\mathbf{B}},\bar{\mathbf{D}})$ & undefined & $\bar{\mathbf{B}}\rightarrow\bar{\mathbf{D}}$ & $\bar{\mathbf{B}}\rightarrow\bar{\mathbf{D}}$\\
$(\bar{\mathbf{B}}_r,\bar{\mathbf{D}})$ & $\bar{\mathbf{B}}_r\rightarrow\bar{\mathbf{D}}$ & $\bar{\mathbf{B}}_r\rightarrow\bar{\mathbf{D}}$ & $\bar{\mathbf{B}}_r\rightarrow\bar{\mathbf{D}}$
\end{tabular}
\caption{Comparisons of the ECA guesses for each of the time series pairs shown in Figures \ref{fig:BzDstDAILYxyplot} and \ref{fig:BzDstDAILYrecxyplot} with the intuitive inferences and the ``majority-vote'' inference, i.e., the causal inference implied by the majority of the times series causality tools used during the exploratory causal analysis.}
\label{tab:SolExECAguess}
\end{center}
\end{table}

Another approach to the practical issues discussed above is to sample smaller contiguous subsets of $\mathbf{D}$, $\mathbf{B}$, and $\mathbf{B}_r$.  Let $\hat{\mathbf{D}}^L=\{\{D_{st}(t^\prime)\}$, $\hat{\mathbf{B}}^L=\{\{B_{z}(t^\prime)\}$, and $\hat{\mathbf{B}}^L_r=\{\{B_{z}^\prime(t^\prime)\}$ with $t^\prime=t^\prime_0,t^\prime_1,t^\prime_2,\ldots,L$ be an ordered subset of $\mathbf{D}$, $\mathbf{B}$, and $\mathbf{B}_r$.  An ECA guess vector could be constructed for each sampled pair $(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ and $(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$.  A set of $n$ sampled pairs, each with a different $t^\prime_0$,  would produce a set of $n$ values for each time series causality tool.  These sets of values can then be used to develop a mean ECA guess vector to draw causal inferences.  

Let $L=500$ and $n=10^4$.  The starting points for each time series are sampled from a uniform distribution over $[0,N-L]$.  The leaning calculation uses the $(1/4)$-width tolerance domains and the $l$-standard assignment where $l$ is set as $l=1,\ldots,l_a$, where $l_a$ is the lag for which the lagged autocorrelation of $\hat{\mathbf{D}}^L$ is minimum in a set of autocorrelations calculated with lags from 1 to $L/2$.  The same $l$ used in the leaning calculation will be used in the lagged cross-correlation difference calculations.  The PAI correlation differences are calculated with $E=50$ and $\tau = 1$.  Table \ref{tab:SolExSamp} shows the mean value across the $n$ calculated values of each time series causality tools, and Table \ref{tab:SolExSampECAguess} shows a comparison of the implied causal inferences of these mean values and the intuitive inferences.  Table \ref{tab:SolExSampCI} shows the 90\% confidence intervals across the $n$ calculated values of each time series causality tools, and Table \ref{tab:SolExSampECAguessCI} shows a comparison of the implied causal inferences of these confidence intervals and the intuitive inferences.  The 90\% confidence interval is defined as $[p_5,p_{95}]$ where $p_i$ is the $i$th percentile of the data; i.e., the lower bound of the 90\% confidence interval is the value that is above 5\% of the data and the upper bound of the 90\% confidence interval is the value that is above 95\% of the data.  A bootstrapping \cite{Efron1994} procedure can be set up with the sample of $n$ values for each of the time series causality tool calculations, whereby $10^5$ means are calculated from new sets (of the same size as the original set) of values that have been sampled (with replacement) from the original set.  The $90\%$ confidence interval for the mean of these bootstrapped samples, and the comparisons of the implied causal inference with intuition, are shown in Tables \ref{tab:SolExSampCIboot} and \ref{tab:SolExSampECAguessCIboot}.

\begin{table}
\begin{center}
\begin{tabular}{lccccccc}
  & TE & GC & PAI & L & LCC & $\vec{g}$ & ECA guess\\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & $-2.9\times 10^{-2}$ & $1.9\times 10^{-1}$ & $1.2\times 10^{-1}$ & $1.2\times 10^{-1}$ & $-1.7\times 10^{-1}$ & $(1,0,1,0,0)$ & undefined\\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & $-5.3\times 10^{-3}$ & $2.2\times 10^{-1}$ & $9.8\times 10^{-2}$ & $1.1\times 10^{-1}$ & $-1.9\times 10^{-1}$ & $(1,0,1,0,0)$ & undefined
\end{tabular}
\caption{The average values of each of the five time series causality tools used in this exploratory causal analysis for each of the time series pairs $(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ and $(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ with the mean leaning across all the lags labeled ``L'', the mean lagged cross-correlation difference labeled ``LCC'', Granger causality log-likelihood statistics difference (i.e., $F_{X\rightarrow Y}-F_{Y\rightarrow X}$, calculated by the MVGC toolbox) labeled ``GC'', the transfer entropy difference (i.e., $T_{X\rightarrow Y}-T_{Y\rightarrow X}$, calculated with the JIDT) labeled ``TE'', and the PAI correlation difference labeled ``PAI''.  An entry of ``n/a'' in the GC column indicates the the MVGC toolbox failed to fit a VAR model to the data with the maximum request model parameters and/or within the maximum allotted computation time.}
\label{tab:SolExSamp}
\end{center}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{lccc}
  & ECA guess & Majority-vote inference & Intuitive inference\\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & undefined & $\hat{\mathbf{B}}^L\rightarrow\hat{\mathbf{D}}^L$ & $\hat{\mathbf{B}}^L\rightarrow\hat{\mathbf{D}}^L$\\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & undefined & $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ & $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$
\end{tabular}
\caption{Comparisons of the ECA guesses for each of the time series pairs shown in Table \ref{tab:SolExSamp} with the intuitive inferences and the ``majority-vote'' inference, i.e., the causal inference implied by the majority of the times series causality tools used during the exploratory causal analysis.}
\label{tab:SolExSampECAguess}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{lcccc}
  & TE & GC & PAI & L \\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & $[-9.7,4.1]\times 10^{-2}$ & $[7.8\times 10^{-2},3.5\times 10^{-1}]$ & $[4.1\times 10^{-2},2.1\times 10^{-1}]$ & $[-8.3\times 10^{-3},3.4\times 10^{-1}]$ \\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & $[-6.5,5.5]\times 10^{-2}$ & $[6.8\times 10^{-2},4.2\times 10^{-1}]$ & $[1.8\times 10^{-2},1.8\times 10^{-1}]$ & $[-9.2\times 10^{-3},3.6\times 10^{-1}]$  \\
\bottomrule \\
  & LCC & $\vec{g}$ & ECA guess & \\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & $[-2.6\times 10^{-1},-3.9\times 10^{-2}]$ & $(2,0,1,2,0)$ & undefined & \\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & $[-2.9\times 10^{-1},-7.8\times 10^{-2}]$ & $(2,0,1,2,0)$ & undefined & 
\end{tabular}
\caption{The 90\% confidence intervals of the average values shown in Table \ref{tab:SolExSamp}.}
\label{tab:SolExSampCI}
\end{center}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{lccc}
  & ECA guess & Majority-vote inference & Intuitive inference\\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & undefined & undefined & $\hat{\mathbf{B}}^L\rightarrow\hat{\mathbf{D}}^L$\\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & undefined & undefined & $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$
\end{tabular}
\caption{Comparisons of the ECA guesses for each of the time series pairs shown in Table \ref{tab:SolExSampCI}.}
\label{tab:SolExSampECAguessCI}
\end{center}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{lcccc}
  & TE & GC & PAI & L \\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & $[-3.0,-2.9]\times 10^{-2}$ & $[1.9,2.0]\times 10^{-1}$ & $[1.2,1.2]\times 10^{-1}$ & $[1.2,1.2]\times 10^{-1}$ \\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & $[-5.5,-5.2]\times 10^{-3}$ & $[2.2,2.2]\times 10^{-1}$ & $[9.8,9.9]\times 10^{-2}$ & $[1.1,1.1]\times 10^{-1}$ \\
\bottomrule \\
  & LCC & $\vec{g}$ & ECA guess & \\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & $[-1.6,-1.6]\times 10^{-1}$ & $(1,0,1,0,0)$ & undefined & \\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & $[-1.9,-1.9]\times 10^{-1}$ & $(1,0,1,0,0)$ & undefined & 
\end{tabular}
\caption{The 90\% confidence intervals for the set of $10^5$ bootstrap calculations of the means shown in Table \ref{tab:SolExSamp}.}
\label{tab:SolExSampCIboot}
\end{center}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{lccc}
  & ECA guess & Majority-vote inference & Intuitive inference\\
\midrule
$(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ & undefined & $\hat{\mathbf{B}}^L\rightarrow\hat{\mathbf{D}}^L$ & $\hat{\mathbf{B}}^L\rightarrow\hat{\mathbf{D}}^L$\\
$(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ & undefined & $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ & $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$
\end{tabular}
\caption{Comparisons of the ECA guesses for each of the time series pairs shown in Table \ref{tab:SolExSampCIboot}.}
\label{tab:SolExSampECAguessCIboot}
\end{center}
\end{table}

This sampling procedure resulted in five sets of 3,025 values, one set for each of the time series causality tool calculations.  Only approximately 3,000 of the approximately $10^4$ sampled times series subsets $\hat{\mathbf{D}}^L$, $\hat{\mathbf{B}}^L$, and $\hat{\mathbf{B}}^L_r$ (with $L=500$) contained no missing data.  These were the only subsets for which the time series causality tools were calculated.  The means of these sets, shown in Table \ref{tab:SolExSamp}, lead to undefined ECA guesses but majority-vote inferences that agree with intuition for both pairs. The 90\% confidence intervals of these sets, however, imply neither the intuitive nor the counter-intuitive causal inference, as shown in Table \ref{tab:SolExSampCI}.  The bootstrapped 90\% confidence intervals, shown in Table \ref{tab:SolExSampCIboot}, imply ECA guess vectors that agree with Table \ref{tab:SolExSamp}.  In both cases, $g_1$ (transfer entropy) and $g_3$ (PAI) both imply the counter-intuitive causal inference, while every other element of the ECA guess vector implies the intuitive causal inference. 

The exploratory causal analysis of this data, like any exploratory analysis \cite{Tukey1977}, is dependent on the framework within which the causal inferences are drawn.  The inferences of Table \ref{tab:SolEx} were drawn from an averaged times series subset of the available data.  The averaging procedure implies the majority-inference of $\bar{\mathbf{B}}\rightarrow\bar{\mathbf{D}}$ or the ECA guess of $\bar{\mathbf{B}}_r\rightarrow\bar{\mathbf{D}}$ are statements of daily averages only during the time period of 1997 to 2001.  These are not statements about the hourly data during the available time period of 1963 to 2012.  It may be that the five years used during the averaging procedure are not representative of other five year subsets of the 50 years of available data.  Trends in the hourly time series may not be present in the daily time series.  For example, $g_1$ (transfer entropy) and $g_3$ (PAI) imply the intuitive causal inference for the daily time series (Table \ref{tab:SolEx}) and the counter-intuitive causal inference for the sampled hourly times series (Table \ref{tab:SolExSamp}).  However, the majority-vote inferences for both the daily and sampled hourly time series pairs agree with intuition.  The sampling procedure sampled times series of length $L=500$, which corresponds to approximately 20 days of hourly data.  It follows that the majority-vote inferences of $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ and $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ are not statements about the time series pairs $(\mathbf{B},\mathbf{D})$ and $(\mathbf{B}_r,\mathbf{D})$.  The causal inferences drawn from the 20-day sampled times series may be the same causal inference that would be drawn from an exploratory causal analysis of the entire time series pairs $(\mathbf{B},\mathbf{D})$ and $(\mathbf{B}_r,\mathbf{D})$ but such assumptions would need theoretical (or analytical) support that has not be explored in this example.  For example, if the sampling procedure is performed again but with $L=1000$ (i.e., approximately 40 days of data), then the ECA vector\footnote{The ECA vector here is found by using the mean value of each time series causality tool to find the implied causal inference, as was done in Table \ref{tab:SolExSamp}.} for the pair $(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ is $\vec{g}=(1,0,1,0,0)$, which is the same as the $L=500$ case.  However, the ECA vector for the pair $(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ is $\vec{g}=(0,0,1,0,0)$, which is different from the $L=500$ case.  Both ECA vectors for the longer sampled subset time series have majority-vote inferences that agree with intuition, just as was found for the $L=500$ case.  But, $g_1$ (transfer entropy) for $(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ implies the intuitive inference of $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ for $L=1000$, which differs both from the $g_1$ inference for $(\hat{\mathbf{B}}^L,\hat{\mathbf{D}}^L)$ with $L=1000$ and from the $g_1$ inference for either pair with $L=500$.  Changing only the length of the sampled time series subsets can change the causal inference implied by $g_1$ for $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$.

The missing data points have also affected both the daily averaging procedure and the sampling procedure.  The averaging procedure involves the arithmetic mean of 24 hours of data where missing data within that 24 hour period was ignored; i.e., if, e.g., only 20 hours of data are available for a given 24 hour period, then the reported daily mean for that period is the arithmetic mean of only 20 data points rather than the expected 24.  This process may or may not have have led to daily averages that are representative of the physical system, i.e., the calculated daily averages may be significantly different from the daily averages that might have been calculated if the data was not missing.  Such counter-factual concerns, however, are not (and perhaps cannot) be addressed in this example.  The missing data also biases the sampling procedure.  The sampling procedure involves the random selection of 500 contiguous data points within the time series $\mathbf{B}$, $\mathbf{B}_r$, and $\mathbf{D}$.  If any of the subset time series are missing data, then the exploratory causal analysis is not performed and different subset time series are selected.  This is why there are only 3,025 samples of each time series causality tool calculation in the attempted sampling of $10^4$ time series subsets\footnote{Only 1,366 samples were found in 5,800 attempts when the sampling procedure was run with $L=1000$.}.  It may be that 500 contiguous data points containing no missing data across all three time series are relatively rare within the data, which may cause the sampling procedure to over-represent certain 20-day time periods in the analysis.  This issue was also not addressed in this example.  

The majority-vote inferences of both the daily average and sampling procedures used in this example agree with intuition.  This analysis, however, is exploratory causal analysis and should not be confused with confirmatory causal analysis.  The issues discussed in the previous two paragraphs help illustrate the distinction between the two.  The results presented in this section do not confirm any theory that posits $\mathbf{B}\rightarrow\mathbf{D}$.  Rather, the results show $\bar{\mathbf{B}}\rightarrow\bar{\mathbf{D}}$ and $\hat{\mathbf{B}}^L_r\rightarrow\hat{\mathbf{D}}^L$ (for $L=500$) are potential causal structures of the time series pairs $(\bar{\mathbf{B}},\bar{\mathbf{D}})$ and $(\hat{\mathbf{B}}^L_r,\hat{\mathbf{D}}^L)$ (for $L=500$), respectively.  These results may be useful for the confirmatory causal analysis of $\mathbf{B}\rightarrow\mathbf{D}$ but would require, as stated previously, outside theoretical (or analytical) support.

\section{Conclusions}
The exploratory causal analysis of some of the synthetic data examples, e.g., Section \ref{sec:IR}, led to ECA guesses that agree with intuition without much effort on the part of the analyst, i.e., the times series causality tools could be applied naively and the results were straightforward to interpret.  The exploratory causal analysis of other examples, e.g., Section \ref{sec:2Pop}, was more subtle, requiring careful interpretation of the results, especially given conflicting causal inference implications from different tools and determination of ``intuitive'' causal inferences from system parameters.  The ECA guess agreed with intuition for some examples, and in other examples only the majority-vote inference agreed with intuition.  In some examples, e.g., Section \ref{sec:3var}, neither agreed with intuition and may have implied counter-intuitive causal inferences.  In every example, however, the exploratory causal analysis provided insight into the data that was potentially useful (or, at least, interesting) to an analyst.

This work has posited that exploratory causal analysis should be a part of the exploratory data analysis of time series data sets.  Such analysis may be considered particularly useful with data collected from systems for which more traditional physics experiments are not possible, including space weather data sets used for geomagnetic storm forecasting.  This work has not explored the detailed exploratory causal analysis that may guide a confirmatory data analysis of such data sets.  For example, testing different cause-effect assignments for the leaning calculations of Section \ref{sec:emp} may help guide the development of structural models (i.e., SEM) that might be used during the confirmatory data analysis of that data (e.g., using SCM)\footnote{See Section \ref{sec:studies} for discussions of SEM and SCM}.  Broadening the scope of the exploratory causal analysis for the example of Section \ref{sec:emp}, e.g., by calculating ECA guess for every times series pair available in the NASA OMNI data set, may also be fruitful in guiding theoretical or confirmatory causal analysis of the system.

Several examples of exploratory causal analysis have been shown, some with successful naive ECA guesses and some that required individual time series analysis tools to be applied in different ways.  Overall, the theme of using more than one tool to draw exploratory causal inferences proved to be useful both in understanding the potential causal structure of the system and in understanding any failures of particular tools (i.e., disagreements with intuition and/or disagreements with the majority of the other tools).  This approach potentially helps prevent errant causal inferences at the cost of (potentially) redundant calculations.  This work, however, has not explored these ideas formally.  What properties of the system dynamics consistently lead to counter-intuitive causal inferences from one time series causality tool but not another?  Are there such properties?  These types of research questions may help an analyst better understand the time series causality tools, but may also help guide the system modeling (e.g., if a given Granger causality tool is known to always fail if the time series data is generated by non-linear dynamics, then the failure of such a tool may guide the analyst to eliminate linear approaches during the system modeling effort).  This work briefly noted in Section \ref{sec:nonli} that a given Granger causality tool (i.e., the MVGC implementation of the Granger log-likelihood statistic) consistently implied the intuitive causal inference for synthetic data sets generated by non-linear dynamics, despite the expectation to not do so (which also happened for the example shown in Section \ref{sec:2Pop}).  The exploration of such research questions, however, may require more than computational testing.  It may be fruitful to formally explore, e.g., how a given cause-effect assignment in the leaning calculation might appear in the VAR forecast model used by a given Granger causality tool.

The synthetic data example of Section \ref{sec:2Pop} is the only example in this work of exploratory causal analysis on coupled system dynamics.  There is a history of studying such systems in non-linear and chaotic time series analysis (see, e.g., \cite{ITbook_placeholder}).  Such systems, however, do not always provide clear causal intuitions, so this work did not explore them in detail (i.e., beyond what is done in Section \ref{sec:2Pop}).  These systems may provide an intriguing study of the exploratory causal analysis approach.  Is it possible for multiple time series analysis tools to imply the same causal inference for such systems?  If so, how are the tools that agree related, e.g., formally or computationally?  Exploratory causal analysis of well-studied chaotic dynamics may help guide analysts in applying such techniques to, e.g., building forecast models, which is known to be difficult for data generated from non-linear and/or chaotic dynamics \cite{Tong1993}.

The leaning was introduced in Section \ref{sec:lean} and used throughout this work as the penchant causality tool.  All leaning calculations rely on cause-effect assignment and tolerance domains, which, given empirical data, must be set with some reasonable data analysis.  This work use the $(1/4)$-width tolerances domains extensively, which are straightforward to define for a given data set.  The $l$-standard cause-effect assignments were used exclusively in this work with $l$ set as a function of the autocorrelation lengths of one or both times series.  Section \ref{sec:IR} discussed one possible method for setting $l$ algorithmically.  There was no discussion, however, of determining a reasonable cause-effect assignment algorithmically in general.  The $l$-standard assignment is a straightforward choice but an analyst may be limiting the usefulness of the leaning calculation by not trying other possible cause-effect assignments.  Consider, for example, a system for which one signal $\mathbf{D}$ is a steady impulse representing the times at which a grain of stand is dropped into a pile, i.e., $\mathbf{D} = \{d_t = 1\; \forall t\in\mathcal{D}, d_t = 0\; \forall t\not\in\mathcal{D}\}$ where $\mathcal{D}$ is the set of times at which the grain of sand is dropped, and the other signal $\mathbf{H}$ is the maximum height of the pile, i.e., $\mathbf{H} = \{h_t = f(d_i)\; |i=1,2,\ldots,t\}$ where the maximum height of the pile at time $t$ is a function $f$ of all the previously dropped grains of sand $d_i$.  It is expected that $f$ is sufficiently complex to represent both the height increases due to each additional grain of sand and the occasional height decreases due to sand avalanches when the pile meets certain physical requirements.  The intuitive causal inference for this scenario is $\mathbf{D}\rightarrow\mathbf{H}$ but the leaning may not be able to imply such an inference using only the $l$-standard assignment because of the occasional avalanches.  Instead, the leaning may require an ``autoregressive'' cause-effect assignment of $\{C,E\} = \{d_{t-l}\mathrm{\ and\ }h_{t-k},h_t\}$, i.e., the assumed cause is defined using both the $l$ lagged time steps of the impulse signal $\mathbf{D}$ and the $k$ lagged time steps of the response signal $\mathbf{H}$, to return the intuitive causal inference.  Perhaps instead there is some fixed value $h_0$ of $h_t$ that should be used in the cause-effect assignment somehow, e.g., $\{C,E\} = \{d_{t-l}\mathrm{\ and\ }(h_{t-1}<h_0),h_t\}$.  It would be useful to algorithmically determine which cause-effect assignments might be useful for the leaning calculation.  This task may be prohibitively difficult\footnote{The leaning calculation is, as discussed in Section \ref{sec:lean}, essentially a structured counting of features in the time series pairs.  So, algorithmically setting a cause-effect assignment for the leaning calculation may be equivalent to pattern finding and matching within and between the two series, and then calculating the leaning for all potential cause-effect assignments.}, but it may allow the leaning to provide more detailed causal inference, e.g., by identifying which cause-effect assignment leads to a higher leaning than another.  Likewise, it may be useful to algorithmically set the embedding dimension and time delay in the PAI correlation difference calculation,e.g., by finding the embedding dimension and time delay that maximum the SSR correlation (i.e., the correlation between a given time series and the estimation of that time series calculated using the shadow manifold of itself).  If all the time series causality tool parameters were set algorithmically, directly from the data being analyzed, then the exploratory causal analysis may become significantly automated. 

Section \ref{sec:whatisECA} emphasized that exploratory causal analysis of bi-variate time series data was focused on answering the question ``Given $(\mathbf{A},\mathbf{B})$, is the potential driving relationship $\mathbf{A}\rightarrow\mathbf{B}$ or $\mathbf{B}\rightarrow\mathbf{A}$, or can no conclusion be drawn with the tools being used?''  This focus may be a myopic use of the time series tools.  The actual values calculated with each tool was only used for comparison to another value and was distilled into a ternary (yes-no-unknown) answer.  A fruitful extension of this work may be to explore how the actual values calculated with each of these tools compare to each other and to the causal intuitions drawn from system parameter values in the synthetic data examples.  Consider, for example, an instance of Eqn.\ \ref{eqn:2pop} with some fixed $x_0=y_0$, $r_x>r_y$ and $\beta_{yx}>\beta_{xy}$.  It was shown in Section \ref{sec:2Pop} that such an instance of Eqn.\ \ref{eqn:2pop} can lead to an ECA guess that agrees with the intuitive causal inference of $\mathbf{X}\rightarrow\mathbf{Y}$.  If a second instance of Eqn.\ \ref{eqn:2pop} is generated with all the same system parameters expect $\beta_{yx}$, which is increased by some amount $\Delta$, do the individual values of the times series causality tools also change appropriately by some amount related to $\Delta$.  Does, for example, the transfer entropy difference become more positive by some amount related to $\Delta$ and/or related to the amount by which the PAI correlation difference becomes more negative?  These types of research questions may lead to a deeper understanding of both the time series causality tool themselves and what type of ``causality'' is actually being investigated by these tools.

Finally, this work has also purposefully ignored the philosophical foundations of the time series causality tools being used.  Some of these tools have been discussed in the philosophical literature (e.g., Granger causality and information-theoretic causality tools; see \cite{Illari2014}) but others, particularly the leaning, have not.  The penchant is derived from probabilistic causality notions and is related to quantities that have been discussed philosophically, including Kleinberg's causal significance, for which the foundational causality issues are discussed at length in \cite{Kleinberg2012}.  The derivation of the leaning from the penchants and the penchants relationship to the causal significance may imply that the leaning has an interpretation within Kleinberg's causal framework.  

\bibliographystyle{plain}
\bibliography{main}

\end{document}